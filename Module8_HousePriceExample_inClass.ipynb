{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/ML_656/blob/main/Module8_HousePriceExample_inClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vCC-SQb7VRR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "import pydot\n",
        "from io import StringIO\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRIewfHHQt-u"
      },
      "source": [
        "# HOUSE PRICE EXAMPLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oczDAE4wjt4"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joqrQm2gSDdZ",
        "outputId": "b3ace90a-9031-429d-c960-267c84a56266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/ML_656.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML_656'...\n",
            "remote: Enumerating objects: 322, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 322 (delta 116), reused 123 (delta 76), pack-reused 117\u001b[K\n",
            "Receiving objects: 100% (322/322), 26.58 MiB | 18.93 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jILOaSki7VRX",
        "outputId": "2a8cc96a-4004-41e5-c240-fe878701b46f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "house = pd.read_csv('ML_656/HouseData.csv')\n",
        "house.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-005ea722-fe62-4c8c-a5f2-b486c5fe3eb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-005ea722-fe62-4c8c-a5f2-b486c5fe3eb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-005ea722-fe62-4c8c-a5f2-b486c5fe3eb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-005ea722-fe62-4c8c-a5f2-b486c5fe3eb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ead3f1c-c33d-4012-8cf7-9fbe0938a899\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ead3f1c-c33d-4012-8cf7-9fbe0938a899')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ead3f1c-c33d-4012-8cf7-9fbe0938a899 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWBCjNh2woDd"
      },
      "source": [
        "## Prep Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abomVqWFlxVo",
        "outputId": "cd418830-0877-4e25-98ab-96e7cfd78fcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None)\n",
        "house.isnull().sum(axis = 0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                  0\n",
              "MSSubClass          0\n",
              "MSZoning            0\n",
              "LotFrontage       259\n",
              "LotArea             0\n",
              "Street              0\n",
              "Alley            1369\n",
              "LotShape            0\n",
              "LandContour         0\n",
              "Utilities           0\n",
              "LotConfig           0\n",
              "LandSlope           0\n",
              "Neighborhood        0\n",
              "Condition1          0\n",
              "Condition2          0\n",
              "BldgType            0\n",
              "HouseStyle          0\n",
              "OverallQual         0\n",
              "OverallCond         0\n",
              "YearBuilt           0\n",
              "YearRemodAdd        0\n",
              "RoofStyle           0\n",
              "RoofMatl            0\n",
              "Exterior1st         0\n",
              "Exterior2nd         0\n",
              "MasVnrType          8\n",
              "MasVnrArea          8\n",
              "ExterQual           0\n",
              "ExterCond           0\n",
              "Foundation          0\n",
              "BsmtQual           37\n",
              "BsmtCond           37\n",
              "BsmtExposure       38\n",
              "BsmtFinType1       37\n",
              "BsmtFinSF1          0\n",
              "BsmtFinType2       38\n",
              "BsmtFinSF2          0\n",
              "BsmtUnfSF           0\n",
              "TotalBsmtSF         0\n",
              "Heating             0\n",
              "HeatingQC           0\n",
              "CentralAir          0\n",
              "Electrical          1\n",
              "1stFlrSF            0\n",
              "2ndFlrSF            0\n",
              "LowQualFinSF        0\n",
              "GrLivArea           0\n",
              "BsmtFullBath        0\n",
              "BsmtHalfBath        0\n",
              "FullBath            0\n",
              "HalfBath            0\n",
              "BedroomAbvGr        0\n",
              "KitchenAbvGr        0\n",
              "KitchenQual         0\n",
              "TotRmsAbvGrd        0\n",
              "Functional          0\n",
              "Fireplaces          0\n",
              "FireplaceQu       690\n",
              "GarageType         81\n",
              "GarageYrBlt        81\n",
              "GarageFinish       81\n",
              "GarageCars          0\n",
              "GarageArea          0\n",
              "GarageQual         81\n",
              "GarageCond         81\n",
              "PavedDrive          0\n",
              "WoodDeckSF          0\n",
              "OpenPorchSF         0\n",
              "EnclosedPorch       0\n",
              "3SsnPorch           0\n",
              "ScreenPorch         0\n",
              "PoolArea            0\n",
              "PoolQC           1453\n",
              "Fence            1179\n",
              "MiscFeature      1406\n",
              "MiscVal             0\n",
              "MoSold              0\n",
              "YrSold              0\n",
              "SaleType            0\n",
              "SaleCondition       0\n",
              "SalePrice           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house.describe()"
      ],
      "metadata": {
        "id": "Dg7pbMsbyJoy",
        "outputId": "8e6c8558-4bc2-40bc-cfd1-bb834e1ac71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
              "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
              "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
              "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
              "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
              "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
              "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
              "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
              "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
              "\n",
              "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
              "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
              "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
              "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
              "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
              "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
              "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
              "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
              "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
              "\n",
              "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
              "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
              "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
              "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
              "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
              "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
              "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
              "\n",
              "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
              "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
              "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
              "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
              "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
              "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
              "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
              "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
              "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
              "\n",
              "[8 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48f1bc58-f1b8-44d6-b1e7-ceb152671488\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>...</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>...</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48f1bc58-f1b8-44d6-b1e7-ceb152671488')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48f1bc58-f1b8-44d6-b1e7-ceb152671488 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48f1bc58-f1b8-44d6-b1e7-ceb152671488');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-de16b22d-b721-4158-a57c-0ce297dd1ce6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de16b22d-b721-4158-a57c-0ce297dd1ce6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-de16b22d-b721-4158-a57c-0ce297dd1ce6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuUNldN6nzFE"
      },
      "source": [
        "house = house.drop(columns=['Id','LotFrontage','Alley', 'BsmtQual', 'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6FzvzLRrYmx",
        "outputId": "567a2165-53ac-4b13-d8bc-00a3d24e2be2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "house = house.dropna()\n",
        "house.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1451 entries, 0 to 1459\n",
            "Data columns (total 64 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   MSSubClass     1451 non-null   int64  \n",
            " 1   MSZoning       1451 non-null   object \n",
            " 2   LotArea        1451 non-null   int64  \n",
            " 3   Street         1451 non-null   object \n",
            " 4   LotShape       1451 non-null   object \n",
            " 5   LandContour    1451 non-null   object \n",
            " 6   Utilities      1451 non-null   object \n",
            " 7   LotConfig      1451 non-null   object \n",
            " 8   LandSlope      1451 non-null   object \n",
            " 9   Neighborhood   1451 non-null   object \n",
            " 10  Condition1     1451 non-null   object \n",
            " 11  Condition2     1451 non-null   object \n",
            " 12  BldgType       1451 non-null   object \n",
            " 13  HouseStyle     1451 non-null   object \n",
            " 14  OverallQual    1451 non-null   int64  \n",
            " 15  OverallCond    1451 non-null   int64  \n",
            " 16  YearBuilt      1451 non-null   int64  \n",
            " 17  YearRemodAdd   1451 non-null   int64  \n",
            " 18  RoofStyle      1451 non-null   object \n",
            " 19  RoofMatl       1451 non-null   object \n",
            " 20  Exterior1st    1451 non-null   object \n",
            " 21  Exterior2nd    1451 non-null   object \n",
            " 22  MasVnrType     1451 non-null   object \n",
            " 23  MasVnrArea     1451 non-null   float64\n",
            " 24  ExterQual      1451 non-null   object \n",
            " 25  ExterCond      1451 non-null   object \n",
            " 26  Foundation     1451 non-null   object \n",
            " 27  BsmtFinSF1     1451 non-null   int64  \n",
            " 28  BsmtFinSF2     1451 non-null   int64  \n",
            " 29  BsmtUnfSF      1451 non-null   int64  \n",
            " 30  TotalBsmtSF    1451 non-null   int64  \n",
            " 31  Heating        1451 non-null   object \n",
            " 32  HeatingQC      1451 non-null   object \n",
            " 33  CentralAir     1451 non-null   object \n",
            " 34  Electrical     1451 non-null   object \n",
            " 35  1stFlrSF       1451 non-null   int64  \n",
            " 36  2ndFlrSF       1451 non-null   int64  \n",
            " 37  LowQualFinSF   1451 non-null   int64  \n",
            " 38  GrLivArea      1451 non-null   int64  \n",
            " 39  BsmtFullBath   1451 non-null   int64  \n",
            " 40  BsmtHalfBath   1451 non-null   int64  \n",
            " 41  FullBath       1451 non-null   int64  \n",
            " 42  HalfBath       1451 non-null   int64  \n",
            " 43  BedroomAbvGr   1451 non-null   int64  \n",
            " 44  KitchenAbvGr   1451 non-null   int64  \n",
            " 45  KitchenQual    1451 non-null   object \n",
            " 46  TotRmsAbvGrd   1451 non-null   int64  \n",
            " 47  Functional     1451 non-null   object \n",
            " 48  Fireplaces     1451 non-null   int64  \n",
            " 49  GarageCars     1451 non-null   int64  \n",
            " 50  GarageArea     1451 non-null   int64  \n",
            " 51  PavedDrive     1451 non-null   object \n",
            " 52  WoodDeckSF     1451 non-null   int64  \n",
            " 53  OpenPorchSF    1451 non-null   int64  \n",
            " 54  EnclosedPorch  1451 non-null   int64  \n",
            " 55  3SsnPorch      1451 non-null   int64  \n",
            " 56  ScreenPorch    1451 non-null   int64  \n",
            " 57  PoolArea       1451 non-null   int64  \n",
            " 58  MiscVal        1451 non-null   int64  \n",
            " 59  MoSold         1451 non-null   int64  \n",
            " 60  YrSold         1451 non-null   int64  \n",
            " 61  SaleType       1451 non-null   object \n",
            " 62  SaleCondition  1451 non-null   object \n",
            " 63  SalePrice      1451 non-null   int64  \n",
            "dtypes: float64(1), int64(34), object(29)\n",
            "memory usage: 736.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ77WRKus_Xc"
      },
      "source": [
        "col_types = house.columns.to_series().groupby(house.dtypes).groups\n",
        "numerics = list(house.select_dtypes(include=['int64']).columns)\n",
        "factors = list(house.select_dtypes(include=['object']).columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSHiS4cbrBDD",
        "outputId": "34d946b2-b7ec-4d88-81ae-2137f7309881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "house_numcols = house[numerics].drop(columns = ['SalePrice'])\n",
        "house_faccols = house[factors]\n",
        "dummies = pd.get_dummies(house_faccols, drop_first=True)\n",
        "house_numcols_sc_0 = scale(house_numcols)\n",
        "house_numcols_sc = pd.DataFrame(data=house_numcols_sc_0, columns = house_numcols.columns, index = dummies.index)\n",
        "house_sc = pd.concat([house_numcols_sc, dummies], axis = 1)\n",
        "house_sc = pd.concat([house_sc, house['SalePrice']], axis =1)\n",
        "house_sc = house_sc.rename(columns={\"SalePrice\":\"Y\"})\n",
        "house_sc.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MSSubClass   LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
              "0    0.072441 -0.205996     0.656247    -0.520740   1.057250      0.883532   \n",
              "1   -0.872386 -0.090876    -0.067870     2.174601   0.162613     -0.424340   \n",
              "2    0.072441  0.074297     0.656247    -0.520740   0.990980      0.835093   \n",
              "3    0.308648 -0.095881     0.656247    -0.520740  -1.858602     -0.714978   \n",
              "4    0.072441  0.375612     1.380365    -0.520740   0.957846      0.738213   \n",
              "\n",
              "   BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  ...  SaleType_ConLw  \\\n",
              "0    0.579345   -0.289621  -0.943764    -0.457576  ...               0   \n",
              "1    1.176868   -0.289621  -0.640635     0.469865  ...               0   \n",
              "2    0.096054   -0.289621  -0.301312    -0.311378  ...               0   \n",
              "3   -0.497076   -0.289621  -0.061524    -0.686010  ...               0   \n",
              "4    0.467309   -0.289621  -0.174632     0.202598  ...               0   \n",
              "\n",
              "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  \\\n",
              "0             0             0            1                      0   \n",
              "1             0             0            1                      0   \n",
              "2             0             0            1                      0   \n",
              "3             0             0            1                      0   \n",
              "4             0             0            1                      0   \n",
              "\n",
              "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
              "0                     0                     0                     1   \n",
              "1                     0                     0                     1   \n",
              "2                     0                     0                     1   \n",
              "3                     0                     0                     0   \n",
              "4                     0                     0                     1   \n",
              "\n",
              "   SaleCondition_Partial       Y  \n",
              "0                      0  208500  \n",
              "1                      0  181500  \n",
              "2                      0  223500  \n",
              "3                      0  140000  \n",
              "4                      0  250000  \n",
              "\n",
              "[5 rows x 196 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72910646-6009-4ac0-bb80-9948c683ddcb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.072441</td>\n",
              "      <td>-0.205996</td>\n",
              "      <td>0.656247</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>1.057250</td>\n",
              "      <td>0.883532</td>\n",
              "      <td>0.579345</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.943764</td>\n",
              "      <td>-0.457576</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.872386</td>\n",
              "      <td>-0.090876</td>\n",
              "      <td>-0.067870</td>\n",
              "      <td>2.174601</td>\n",
              "      <td>0.162613</td>\n",
              "      <td>-0.424340</td>\n",
              "      <td>1.176868</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.640635</td>\n",
              "      <td>0.469865</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.072441</td>\n",
              "      <td>0.074297</td>\n",
              "      <td>0.656247</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>0.990980</td>\n",
              "      <td>0.835093</td>\n",
              "      <td>0.096054</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.301312</td>\n",
              "      <td>-0.311378</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.308648</td>\n",
              "      <td>-0.095881</td>\n",
              "      <td>0.656247</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>-1.858602</td>\n",
              "      <td>-0.714978</td>\n",
              "      <td>-0.497076</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.061524</td>\n",
              "      <td>-0.686010</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.072441</td>\n",
              "      <td>0.375612</td>\n",
              "      <td>1.380365</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>0.957846</td>\n",
              "      <td>0.738213</td>\n",
              "      <td>0.467309</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.174632</td>\n",
              "      <td>0.202598</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 196 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72910646-6009-4ac0-bb80-9948c683ddcb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72910646-6009-4ac0-bb80-9948c683ddcb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72910646-6009-4ac0-bb80-9948c683ddcb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f27e4d44-64a1-4034-8624-c1ede1bfbec0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f27e4d44-64a1-4034-8624-c1ede1bfbec0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f27e4d44-64a1-4034-8624-c1ede1bfbec0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALiq7uTFwvZ7"
      },
      "source": [
        "## Explore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahz5pTT-xodx",
        "outputId": "cc8f97b8-d6ec-4554-9749-b2813e44486d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        }
      },
      "source": [
        "#From https://towardsdatascience.com/machine-learning-with-python-regression-complete-tutorial-47268e546cea\n",
        "x = \"Y\"\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2,  sharex=False, sharey=False)\n",
        "fig.suptitle(x, fontsize=20)\n",
        "### distribution\n",
        "ax[0].title.set_text('distribution')\n",
        "variable = house_sc[x].fillna(house_sc[x].mean())\n",
        "breaks = np.quantile(variable, q=np.linspace(0, 1, 11))\n",
        "variable = variable[ (variable > breaks[0]) & (variable <\n",
        "                    breaks[10]) ]\n",
        "sns.distplot(variable, hist=True, kde=True, kde_kws={\"shade\": True}, ax=ax[0])\n",
        "des = house_sc[x].describe()\n",
        "ax[0].axvline(des[\"25%\"], ls='--')\n",
        "ax[0].axvline(des[\"mean\"], ls='--')\n",
        "ax[0].axvline(des[\"75%\"], ls='--')\n",
        "ax[0].grid(True)\n",
        "des = round(des, 2).apply(lambda x: str(x))\n",
        "box = '\\n'.join((\"min: \"+des[\"min\"], \"25%: \"+des[\"25%\"], \"mean: \"+des[\"mean\"], \"75%: \"+des[\"75%\"], \"max: \"+des[\"max\"]))\n",
        "ax[0].text(0.95, 0.95, box, transform=ax[0].transAxes, fontsize=10, va='top', ha=\"right\", bbox=dict(boxstyle='round', facecolor='white', alpha=1))\n",
        "### boxplot\n",
        "ax[1].title.set_text('outliers (log scale)')\n",
        "tmp_dtf = pd.DataFrame(house_sc[x])\n",
        "tmp_dtf[x] = np.log(tmp_dtf[x])\n",
        "tmp_dtf.boxplot(column=x, ax=ax[1])\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-92fc8dd032f8>:11: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(variable, hist=True, kde=True, kde_kws={\"shade\": True}, ax=ax[0])\n",
            "/usr/local/lib/python3.10/dist-packages/seaborn/distributions.py:2511: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  kdeplot(**{axis: a}, ax=ax, color=kde_color, **kde_kws)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55xSsRHJLUuu",
        "outputId": "18f3e7b1-e143-429f-a21f-1f21c75b4c81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.random.seed(42)\n",
        "train, test = train_test_split(house_sc, test_size = 0.25)\n",
        "X_train = train.drop(columns = ['Y']).values\n",
        "y_train = train['Y'].values\n",
        "X_test = test.drop(columns = ['Y']).values\n",
        "y_test = test['Y'].values\n",
        "X_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1088, 195)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "3J1jPEOq2wsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_rf = RandomForestRegressor(random_state=1)\n",
        "house_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "uYSatFjo2v2E",
        "outputId": "34ae38df-8458-444e-d396-fac682f963c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house_rf_test_pred = house_rf.predict(X_test)"
      ],
      "metadata": {
        "id": "TM6yaPNi3Xj7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, house_rf_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-house_rf_test_pred)/house_rf_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, house_rf_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, house_rf_test_pred))))"
      ],
      "metadata": {
        "id": "3VqeIG8O3bZW",
        "outputId": "ec45f4df-65c8-435e-de89-8d8bb4f45b13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 (explained variance): 0.9\n",
            "Mean Absolute Perc Error (Σ(|y-pred|/y)/n): 0.09\n",
            "Mean Absolute Error (Σ|y-pred|/n): 15,485\n",
            "Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)): 22,399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "5TNaAgjLRAf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50, input_shape=(195, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(25, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "#https://keras.io/api/models/model_training_apis/\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "n8aW_lMbQ_s5",
        "outputId": "eda14c2a-073a-46c3-a475-ccbb4dea5ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 50)                9800      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11101 (43.36 KB)\n",
            "Trainable params: 11101 (43.36 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=750, validation_split=0.25)"
      ],
      "metadata": {
        "id": "id3GR3gNT6t8",
        "outputId": "62f94403-52f4-4668-d773-bd121f084f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "26/26 [==============================] - 4s 36ms/step - loss: 39684988928.0000 - mae: 181681.0469 - val_loss: 39713652736.0000 - val_mae: 182001.2656\n",
            "Epoch 2/750\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 39681806336.0000 - mae: 181672.7188 - val_loss: 39708389376.0000 - val_mae: 181987.9531\n",
            "Epoch 3/750\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 39673421824.0000 - mae: 181651.4375 - val_loss: 39695740928.0000 - val_mae: 181956.3594\n",
            "Epoch 4/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 39654981632.0000 - mae: 181605.5938 - val_loss: 39670403072.0000 - val_mae: 181893.3906\n",
            "Epoch 5/750\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 39621509120.0000 - mae: 181521.6094 - val_loss: 39626522624.0000 - val_mae: 181785.1250\n",
            "Epoch 6/750\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 39566643200.0000 - mae: 181385.1719 - val_loss: 39559438336.0000 - val_mae: 181618.7344\n",
            "Epoch 7/750\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 39485698048.0000 - mae: 181181.9062 - val_loss: 39461031936.0000 - val_mae: 181374.9844\n",
            "Epoch 8/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 39368974336.0000 - mae: 180892.3750 - val_loss: 39326273536.0000 - val_mae: 181040.1719\n",
            "Epoch 9/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 39212924928.0000 - mae: 180502.1250 - val_loss: 39146819584.0000 - val_mae: 180594.8125\n",
            "Epoch 10/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 39009329152.0000 - mae: 179991.2344 - val_loss: 38916038656.0000 - val_mae: 180021.1250\n",
            "Epoch 11/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 38752587776.0000 - mae: 179340.2500 - val_loss: 38625570816.0000 - val_mae: 179298.0000\n",
            "Epoch 12/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 38433267712.0000 - mae: 178538.2812 - val_loss: 38276952064.0000 - val_mae: 178423.0000\n",
            "Epoch 13/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 38048362496.0000 - mae: 177567.5312 - val_loss: 37858324480.0000 - val_mae: 177369.4688\n",
            "Epoch 14/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 37597421568.0000 - mae: 176406.1562 - val_loss: 37362098176.0000 - val_mae: 176116.0000\n",
            "Epoch 15/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 37061099520.0000 - mae: 175059.3125 - val_loss: 36803719168.0000 - val_mae: 174689.6719\n",
            "Epoch 16/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 36461903872.0000 - mae: 173499.3281 - val_loss: 36156260352.0000 - val_mae: 173029.1719\n",
            "Epoch 17/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 35783008256.0000 - mae: 171719.5938 - val_loss: 35436163072.0000 - val_mae: 171162.8438\n",
            "Epoch 18/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 35029823488.0000 - mae: 169738.6250 - val_loss: 34646876160.0000 - val_mae: 169088.3906\n",
            "Epoch 19/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 34202091520.0000 - mae: 167531.9062 - val_loss: 33776726016.0000 - val_mae: 166779.8750\n",
            "Epoch 20/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 33292531712.0000 - mae: 165097.6875 - val_loss: 32848400384.0000 - val_mae: 164269.9062\n",
            "Epoch 21/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 32331327488.0000 - mae: 162419.8906 - val_loss: 31829733376.0000 - val_mae: 161485.1406\n",
            "Epoch 22/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 31282221056.0000 - mae: 159512.4844 - val_loss: 30762117120.0000 - val_mae: 158507.4062\n",
            "Epoch 23/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 30179641344.0000 - mae: 156378.0469 - val_loss: 29621882880.0000 - val_mae: 155271.1250\n",
            "Epoch 24/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 29000941568.0000 - mae: 152997.0625 - val_loss: 28437422080.0000 - val_mae: 151830.9844\n",
            "Epoch 25/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 27790655488.0000 - mae: 149356.8906 - val_loss: 27162863616.0000 - val_mae: 148071.7656\n",
            "Epoch 26/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 26500435968.0000 - mae: 145487.0312 - val_loss: 25889019904.0000 - val_mae: 144187.9531\n",
            "Epoch 27/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 25203220480.0000 - mae: 141429.8750 - val_loss: 24560404480.0000 - val_mae: 140040.6250\n",
            "Epoch 28/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 23871602688.0000 - mae: 137115.6875 - val_loss: 23190841344.0000 - val_mae: 135647.7500\n",
            "Epoch 29/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 22494050304.0000 - mae: 132608.5156 - val_loss: 21844264960.0000 - val_mae: 131164.4375\n",
            "Epoch 30/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 21130668032.0000 - mae: 127945.2266 - val_loss: 20450725888.0000 - val_mae: 126389.8984\n",
            "Epoch 31/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 19750031360.0000 - mae: 123013.7266 - val_loss: 19056750592.0000 - val_mae: 121436.2969\n",
            "Epoch 32/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 18371944448.0000 - mae: 118042.0781 - val_loss: 17710901248.0000 - val_mae: 116437.2656\n",
            "Epoch 33/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 17035894784.0000 - mae: 112863.0312 - val_loss: 16352693248.0000 - val_mae: 111195.5859\n",
            "Epoch 34/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 15697187840.0000 - mae: 107571.8359 - val_loss: 15050022912.0000 - val_mae: 105916.8594\n",
            "Epoch 35/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 14426090496.0000 - mae: 102218.7188 - val_loss: 13780689920.0000 - val_mae: 100520.3594\n",
            "Epoch 36/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 13190144000.0000 - mae: 96764.1250 - val_loss: 12568144896.0000 - val_mae: 95099.7812\n",
            "Epoch 37/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 12017422336.0000 - mae: 91246.0078 - val_loss: 11375190016.0000 - val_mae: 89490.6797\n",
            "Epoch 38/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 10887610368.0000 - mae: 85739.0859 - val_loss: 10276322304.0000 - val_mae: 83980.1016\n",
            "Epoch 39/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9834896384.0000 - mae: 80252.7969 - val_loss: 9238349824.0000 - val_mae: 78479.0312\n",
            "Epoch 40/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 8845350912.0000 - mae: 74809.2734 - val_loss: 8292995072.0000 - val_mae: 73168.0625\n",
            "Epoch 41/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 7934682624.0000 - mae: 69526.3438 - val_loss: 7418801152.0000 - val_mae: 67966.6641\n",
            "Epoch 42/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 7120376320.0000 - mae: 64235.6992 - val_loss: 6572515840.0000 - val_mae: 62693.5430\n",
            "Epoch 43/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 6348561408.0000 - mae: 59207.3867 - val_loss: 5860580864.0000 - val_mae: 57888.3438\n",
            "Epoch 44/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5690741248.0000 - mae: 54520.3086 - val_loss: 5204856832.0000 - val_mae: 53204.0898\n",
            "Epoch 45/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5092674560.0000 - mae: 50088.7383 - val_loss: 4645904896.0000 - val_mae: 48867.5312\n",
            "Epoch 46/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4577333760.0000 - mae: 45976.7305 - val_loss: 4139656704.0000 - val_mae: 44699.5078\n",
            "Epoch 47/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 4137299456.0000 - mae: 42232.2695 - val_loss: 3697711104.0000 - val_mae: 40832.7656\n",
            "Epoch 48/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 3751638784.0000 - mae: 38956.4961 - val_loss: 3346704640.0000 - val_mae: 37586.3398\n",
            "Epoch 49/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3440303360.0000 - mae: 36177.1055 - val_loss: 3038091520.0000 - val_mae: 34822.1641\n",
            "Epoch 50/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3171094272.0000 - mae: 33855.1289 - val_loss: 2791642368.0000 - val_mae: 32643.3086\n",
            "Epoch 51/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2959776256.0000 - mae: 31909.3809 - val_loss: 2566117376.0000 - val_mae: 30803.5195\n",
            "Epoch 52/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2776112128.0000 - mae: 30492.3945 - val_loss: 2392665600.0000 - val_mae: 29402.8340\n",
            "Epoch 53/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2635359744.0000 - mae: 29450.5293 - val_loss: 2242126080.0000 - val_mae: 28251.1855\n",
            "Epoch 54/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2514957056.0000 - mae: 28673.2578 - val_loss: 2128119424.0000 - val_mae: 27434.2148\n",
            "Epoch 55/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2415703296.0000 - mae: 28128.6328 - val_loss: 2040739200.0000 - val_mae: 26879.6973\n",
            "Epoch 56/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2340381952.0000 - mae: 27804.4199 - val_loss: 1954616832.0000 - val_mae: 26465.0527\n",
            "Epoch 57/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2276396288.0000 - mae: 27555.1426 - val_loss: 1887590656.0000 - val_mae: 26168.0645\n",
            "Epoch 58/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2226336256.0000 - mae: 27371.8848 - val_loss: 1837163520.0000 - val_mae: 26018.3848\n",
            "Epoch 59/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2186985216.0000 - mae: 27260.2480 - val_loss: 1790239232.0000 - val_mae: 25927.9980\n",
            "Epoch 60/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2152856576.0000 - mae: 27206.0508 - val_loss: 1751145472.0000 - val_mae: 25906.7715\n",
            "Epoch 61/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2124167936.0000 - mae: 27160.9805 - val_loss: 1718942464.0000 - val_mae: 25911.7246\n",
            "Epoch 62/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2101062272.0000 - mae: 27126.8809 - val_loss: 1687932928.0000 - val_mae: 25938.7910\n",
            "Epoch 63/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2077670400.0000 - mae: 27086.7598 - val_loss: 1665598592.0000 - val_mae: 25950.8809\n",
            "Epoch 64/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2061427968.0000 - mae: 27042.9590 - val_loss: 1642818304.0000 - val_mae: 25972.8945\n",
            "Epoch 65/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2043919232.0000 - mae: 27024.8945 - val_loss: 1625780864.0000 - val_mae: 25976.6895\n",
            "Epoch 66/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2029368832.0000 - mae: 26987.1133 - val_loss: 1609701376.0000 - val_mae: 25978.7969\n",
            "Epoch 67/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2015402368.0000 - mae: 26945.7715 - val_loss: 1596006144.0000 - val_mae: 25964.7734\n",
            "Epoch 68/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2003388672.0000 - mae: 26869.4395 - val_loss: 1580550016.0000 - val_mae: 25943.1660\n",
            "Epoch 69/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1991328768.0000 - mae: 26852.3633 - val_loss: 1567030784.0000 - val_mae: 25961.8711\n",
            "Epoch 70/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1978769920.0000 - mae: 26777.5742 - val_loss: 1556043904.0000 - val_mae: 25922.6660\n",
            "Epoch 71/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1968101376.0000 - mae: 26718.0078 - val_loss: 1541804928.0000 - val_mae: 25924.7578\n",
            "Epoch 72/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1957131392.0000 - mae: 26665.5938 - val_loss: 1531113600.0000 - val_mae: 25894.9082\n",
            "Epoch 73/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1947866240.0000 - mae: 26602.2695 - val_loss: 1520537088.0000 - val_mae: 25853.3574\n",
            "Epoch 74/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1937368320.0000 - mae: 26505.2012 - val_loss: 1513105152.0000 - val_mae: 25806.4941\n",
            "Epoch 75/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1927757056.0000 - mae: 26423.3926 - val_loss: 1505313664.0000 - val_mae: 25740.9980\n",
            "Epoch 76/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1918316672.0000 - mae: 26351.3145 - val_loss: 1494328832.0000 - val_mae: 25727.2656\n",
            "Epoch 77/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1909252096.0000 - mae: 26292.5195 - val_loss: 1485712384.0000 - val_mae: 25698.3730\n",
            "Epoch 78/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1902658688.0000 - mae: 26278.0449 - val_loss: 1473582080.0000 - val_mae: 25713.9043\n",
            "Epoch 79/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1891498112.0000 - mae: 26184.5156 - val_loss: 1468278400.0000 - val_mae: 25630.6484\n",
            "Epoch 80/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1885333888.0000 - mae: 26127.5664 - val_loss: 1459173760.0000 - val_mae: 25590.5254\n",
            "Epoch 81/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1876169856.0000 - mae: 26011.5938 - val_loss: 1454494720.0000 - val_mae: 25520.0645\n",
            "Epoch 82/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1868379648.0000 - mae: 25933.4355 - val_loss: 1447799552.0000 - val_mae: 25454.6035\n",
            "Epoch 83/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1860077824.0000 - mae: 25828.6133 - val_loss: 1441457920.0000 - val_mae: 25409.8223\n",
            "Epoch 84/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1853178624.0000 - mae: 25763.6816 - val_loss: 1435180032.0000 - val_mae: 25372.7930\n",
            "Epoch 85/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1844914688.0000 - mae: 25725.4844 - val_loss: 1427040128.0000 - val_mae: 25381.7051\n",
            "Epoch 86/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1839105280.0000 - mae: 25675.7285 - val_loss: 1418613120.0000 - val_mae: 25358.3906\n",
            "Epoch 87/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1831694208.0000 - mae: 25609.2012 - val_loss: 1414833280.0000 - val_mae: 25308.8145\n",
            "Epoch 88/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1824552704.0000 - mae: 25529.8867 - val_loss: 1411680256.0000 - val_mae: 25250.5684\n",
            "Epoch 89/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1818079744.0000 - mae: 25450.4414 - val_loss: 1405631872.0000 - val_mae: 25211.2363\n",
            "Epoch 90/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1812284416.0000 - mae: 25419.7949 - val_loss: 1399331840.0000 - val_mae: 25202.9102\n",
            "Epoch 91/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1804816128.0000 - mae: 25329.6719 - val_loss: 1394375552.0000 - val_mae: 25145.1602\n",
            "Epoch 92/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1800479744.0000 - mae: 25306.7559 - val_loss: 1386270464.0000 - val_mae: 25156.8125\n",
            "Epoch 93/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1794325248.0000 - mae: 25148.5977 - val_loss: 1388095488.0000 - val_mae: 25009.3281\n",
            "Epoch 94/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1787720832.0000 - mae: 25100.2891 - val_loss: 1377838336.0000 - val_mae: 25052.8750\n",
            "Epoch 95/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1779146240.0000 - mae: 25064.6895 - val_loss: 1374895104.0000 - val_mae: 24992.0449\n",
            "Epoch 96/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1773234432.0000 - mae: 24985.6641 - val_loss: 1369420672.0000 - val_mae: 24969.0430\n",
            "Epoch 97/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1767572608.0000 - mae: 24915.6836 - val_loss: 1365309184.0000 - val_mae: 24931.1523\n",
            "Epoch 98/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1760286080.0000 - mae: 24876.8535 - val_loss: 1359654784.0000 - val_mae: 24929.3965\n",
            "Epoch 99/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1756001664.0000 - mae: 24876.8047 - val_loss: 1351355264.0000 - val_mae: 24958.9844\n",
            "Epoch 100/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1749724032.0000 - mae: 24801.4922 - val_loss: 1350648832.0000 - val_mae: 24855.0156\n",
            "Epoch 101/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1745467520.0000 - mae: 24737.3848 - val_loss: 1345564544.0000 - val_mae: 24842.3438\n",
            "Epoch 102/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1738815616.0000 - mae: 24658.3164 - val_loss: 1341770752.0000 - val_mae: 24789.0137\n",
            "Epoch 103/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1733167488.0000 - mae: 24563.9688 - val_loss: 1339823744.0000 - val_mae: 24721.1133\n",
            "Epoch 104/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1728581504.0000 - mae: 24465.3633 - val_loss: 1336724352.0000 - val_mae: 24662.0312\n",
            "Epoch 105/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1723094400.0000 - mae: 24438.6816 - val_loss: 1329532032.0000 - val_mae: 24699.8965\n",
            "Epoch 106/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1718026880.0000 - mae: 24402.3691 - val_loss: 1324034304.0000 - val_mae: 24680.9297\n",
            "Epoch 107/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1713404160.0000 - mae: 24300.4414 - val_loss: 1323860992.0000 - val_mae: 24601.0020\n",
            "Epoch 108/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1708265344.0000 - mae: 24281.6348 - val_loss: 1319432320.0000 - val_mae: 24580.7598\n",
            "Epoch 109/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1701565952.0000 - mae: 24197.3770 - val_loss: 1315666560.0000 - val_mae: 24558.9922\n",
            "Epoch 110/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1698578816.0000 - mae: 24116.9922 - val_loss: 1314093184.0000 - val_mae: 24479.9062\n",
            "Epoch 111/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1691393664.0000 - mae: 24070.9004 - val_loss: 1307094400.0000 - val_mae: 24516.4062\n",
            "Epoch 112/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1688078592.0000 - mae: 24088.9199 - val_loss: 1302710912.0000 - val_mae: 24512.9473\n",
            "Epoch 113/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1682168192.0000 - mae: 24003.7422 - val_loss: 1300149376.0000 - val_mae: 24457.4219\n",
            "Epoch 114/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1676788992.0000 - mae: 23958.7598 - val_loss: 1295554048.0000 - val_mae: 24444.0430\n",
            "Epoch 115/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1675645056.0000 - mae: 23980.5371 - val_loss: 1290854912.0000 - val_mae: 24460.6133\n",
            "Epoch 116/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1673541248.0000 - mae: 23821.1426 - val_loss: 1294900864.0000 - val_mae: 24258.4863\n",
            "Epoch 117/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1660584320.0000 - mae: 23747.5879 - val_loss: 1285775616.0000 - val_mae: 24370.0098\n",
            "Epoch 118/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1657421312.0000 - mae: 23799.9805 - val_loss: 1280074112.0000 - val_mae: 24411.8301\n",
            "Epoch 119/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1653574656.0000 - mae: 23745.0879 - val_loss: 1278479104.0000 - val_mae: 24318.8457\n",
            "Epoch 120/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1648835840.0000 - mae: 23693.6309 - val_loss: 1274490112.0000 - val_mae: 24317.6836\n",
            "Epoch 121/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1645288832.0000 - mae: 23635.0273 - val_loss: 1270240768.0000 - val_mae: 24295.0977\n",
            "Epoch 122/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1639375232.0000 - mae: 23574.3652 - val_loss: 1269089408.0000 - val_mae: 24215.3281\n",
            "Epoch 123/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1635135872.0000 - mae: 23498.7910 - val_loss: 1266894336.0000 - val_mae: 24179.5996\n",
            "Epoch 124/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1631081856.0000 - mae: 23428.9805 - val_loss: 1264629376.0000 - val_mae: 24127.6270\n",
            "Epoch 125/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1627780864.0000 - mae: 23417.1953 - val_loss: 1260108544.0000 - val_mae: 24137.4023\n",
            "Epoch 126/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1622670848.0000 - mae: 23369.4219 - val_loss: 1257840128.0000 - val_mae: 24101.1719\n",
            "Epoch 127/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1619235072.0000 - mae: 23287.4160 - val_loss: 1257141376.0000 - val_mae: 24032.8301\n",
            "Epoch 128/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1616673664.0000 - mae: 23289.7344 - val_loss: 1251300352.0000 - val_mae: 24072.2168\n",
            "Epoch 129/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1609901312.0000 - mae: 23221.2598 - val_loss: 1251010944.0000 - val_mae: 23986.7754\n",
            "Epoch 130/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1606599040.0000 - mae: 23148.1562 - val_loss: 1249257728.0000 - val_mae: 23946.0898\n",
            "Epoch 131/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1602804480.0000 - mae: 23073.0938 - val_loss: 1246546304.0000 - val_mae: 23905.3398\n",
            "Epoch 132/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1598508544.0000 - mae: 23046.9746 - val_loss: 1243276160.0000 - val_mae: 23890.1738\n",
            "Epoch 133/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1594777728.0000 - mae: 23011.0781 - val_loss: 1239266688.0000 - val_mae: 23890.4219\n",
            "Epoch 134/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1590883200.0000 - mae: 22982.7246 - val_loss: 1237750400.0000 - val_mae: 23856.3809\n",
            "Epoch 135/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1587894272.0000 - mae: 22994.1250 - val_loss: 1233055232.0000 - val_mae: 23880.6875\n",
            "Epoch 136/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1584168832.0000 - mae: 22899.5898 - val_loss: 1234902400.0000 - val_mae: 23751.8945\n",
            "Epoch 137/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1580594944.0000 - mae: 22855.4824 - val_loss: 1230636672.0000 - val_mae: 23754.5977\n",
            "Epoch 138/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1575887488.0000 - mae: 22807.2656 - val_loss: 1229032832.0000 - val_mae: 23729.1680\n",
            "Epoch 139/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1571848192.0000 - mae: 22786.9160 - val_loss: 1224523904.0000 - val_mae: 23754.3281\n",
            "Epoch 140/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1567419392.0000 - mae: 22756.1699 - val_loss: 1222183296.0000 - val_mae: 23728.4375\n",
            "Epoch 141/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1564081408.0000 - mae: 22690.4043 - val_loss: 1220387968.0000 - val_mae: 23680.2070\n",
            "Epoch 142/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1560479744.0000 - mae: 22680.7715 - val_loss: 1216783872.0000 - val_mae: 23683.9141\n",
            "Epoch 143/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1557765632.0000 - mae: 22638.7207 - val_loss: 1216394752.0000 - val_mae: 23617.2207\n",
            "Epoch 144/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1553607296.0000 - mae: 22549.0703 - val_loss: 1214478464.0000 - val_mae: 23593.4746\n",
            "Epoch 145/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1549862656.0000 - mae: 22541.4727 - val_loss: 1210263296.0000 - val_mae: 23588.3828\n",
            "Epoch 146/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1547527296.0000 - mae: 22464.5781 - val_loss: 1210897408.0000 - val_mae: 23511.6465\n",
            "Epoch 147/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1544535552.0000 - mae: 22491.6816 - val_loss: 1204664320.0000 - val_mae: 23582.0039\n",
            "Epoch 148/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1538624384.0000 - mae: 22442.6914 - val_loss: 1203790464.0000 - val_mae: 23525.3496\n",
            "Epoch 149/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1535719808.0000 - mae: 22350.4902 - val_loss: 1204049152.0000 - val_mae: 23437.4375\n",
            "Epoch 150/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1533130496.0000 - mae: 22337.8945 - val_loss: 1198159872.0000 - val_mae: 23485.9707\n",
            "Epoch 151/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1529374080.0000 - mae: 22318.2324 - val_loss: 1196290432.0000 - val_mae: 23463.5059\n",
            "Epoch 152/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1525675520.0000 - mae: 22272.3848 - val_loss: 1196632192.0000 - val_mae: 23388.6387\n",
            "Epoch 153/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1522208512.0000 - mae: 22192.6172 - val_loss: 1195008768.0000 - val_mae: 23360.8242\n",
            "Epoch 154/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1519877120.0000 - mae: 22150.0859 - val_loss: 1193558144.0000 - val_mae: 23318.1758\n",
            "Epoch 155/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1517620992.0000 - mae: 22098.5391 - val_loss: 1190733056.0000 - val_mae: 23318.0254\n",
            "Epoch 156/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1512395648.0000 - mae: 22121.3848 - val_loss: 1188027904.0000 - val_mae: 23297.0039\n",
            "Epoch 157/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1509799552.0000 - mae: 22095.8281 - val_loss: 1184595968.0000 - val_mae: 23329.7715\n",
            "Epoch 158/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1505371264.0000 - mae: 22072.9824 - val_loss: 1183041152.0000 - val_mae: 23269.0918\n",
            "Epoch 159/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1503922560.0000 - mae: 22045.4512 - val_loss: 1181726336.0000 - val_mae: 23236.0156\n",
            "Epoch 160/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1501409152.0000 - mae: 22059.1445 - val_loss: 1175098240.0000 - val_mae: 23321.5938\n",
            "Epoch 161/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1495836416.0000 - mae: 22012.6250 - val_loss: 1176007168.0000 - val_mae: 23207.6582\n",
            "Epoch 162/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1492713856.0000 - mae: 21920.0664 - val_loss: 1175008512.0000 - val_mae: 23189.4082\n",
            "Epoch 163/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1490261504.0000 - mae: 21862.8535 - val_loss: 1173703168.0000 - val_mae: 23141.4785\n",
            "Epoch 164/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1487828480.0000 - mae: 21870.9453 - val_loss: 1170527872.0000 - val_mae: 23142.6582\n",
            "Epoch 165/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1483646208.0000 - mae: 21816.4824 - val_loss: 1169528192.0000 - val_mae: 23115.4844\n",
            "Epoch 166/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1481221376.0000 - mae: 21763.3496 - val_loss: 1168687616.0000 - val_mae: 23062.2520\n",
            "Epoch 167/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1477544320.0000 - mae: 21739.5547 - val_loss: 1164550400.0000 - val_mae: 23071.6348\n",
            "Epoch 168/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1473962624.0000 - mae: 21736.6934 - val_loss: 1162037248.0000 - val_mae: 23079.5781\n",
            "Epoch 169/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1473113216.0000 - mae: 21685.8848 - val_loss: 1161917568.0000 - val_mae: 23024.4629\n",
            "Epoch 170/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1467995136.0000 - mae: 21664.4902 - val_loss: 1158328320.0000 - val_mae: 23036.0723\n",
            "Epoch 171/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1465146112.0000 - mae: 21643.3105 - val_loss: 1156754688.0000 - val_mae: 23012.9062\n",
            "Epoch 172/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1463010432.0000 - mae: 21631.4727 - val_loss: 1154052096.0000 - val_mae: 22989.2578\n",
            "Epoch 173/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1459549952.0000 - mae: 21569.5020 - val_loss: 1153162112.0000 - val_mae: 22960.7305\n",
            "Epoch 174/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1457366144.0000 - mae: 21510.5059 - val_loss: 1152703104.0000 - val_mae: 22905.1250\n",
            "Epoch 175/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1455014656.0000 - mae: 21485.3594 - val_loss: 1150575488.0000 - val_mae: 22891.8242\n",
            "Epoch 176/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1453067136.0000 - mae: 21508.0098 - val_loss: 1144877952.0000 - val_mae: 22946.1738\n",
            "Epoch 177/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1449868288.0000 - mae: 21433.4922 - val_loss: 1150069120.0000 - val_mae: 22804.6641\n",
            "Epoch 178/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1445484544.0000 - mae: 21393.8750 - val_loss: 1145409408.0000 - val_mae: 22831.5410\n",
            "Epoch 179/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1442507264.0000 - mae: 21395.7402 - val_loss: 1142045696.0000 - val_mae: 22838.4004\n",
            "Epoch 180/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1440017920.0000 - mae: 21346.6641 - val_loss: 1141710080.0000 - val_mae: 22780.7148\n",
            "Epoch 181/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1437033216.0000 - mae: 21314.1953 - val_loss: 1140027008.0000 - val_mae: 22757.9609\n",
            "Epoch 182/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1433464448.0000 - mae: 21288.7715 - val_loss: 1136710400.0000 - val_mae: 22752.9668\n",
            "Epoch 183/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1430794624.0000 - mae: 21276.1094 - val_loss: 1134886144.0000 - val_mae: 22738.4355\n",
            "Epoch 184/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1431181568.0000 - mae: 21288.3496 - val_loss: 1129860992.0000 - val_mae: 22779.4902\n",
            "Epoch 185/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1424922368.0000 - mae: 21226.1660 - val_loss: 1131977728.0000 - val_mae: 22678.1895\n",
            "Epoch 186/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1423608320.0000 - mae: 21133.0215 - val_loss: 1132156672.0000 - val_mae: 22630.7578\n",
            "Epoch 187/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1423069440.0000 - mae: 21171.9785 - val_loss: 1125783808.0000 - val_mae: 22683.9727\n",
            "Epoch 188/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1417548032.0000 - mae: 21108.8691 - val_loss: 1126371328.0000 - val_mae: 22603.6855\n",
            "Epoch 189/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1415160832.0000 - mae: 21085.7969 - val_loss: 1124428160.0000 - val_mae: 22589.8496\n",
            "Epoch 190/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1412125056.0000 - mae: 21034.2227 - val_loss: 1124014848.0000 - val_mae: 22556.2266\n",
            "Epoch 191/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1410278016.0000 - mae: 20987.8926 - val_loss: 1123473664.0000 - val_mae: 22505.8359\n",
            "Epoch 192/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1407003904.0000 - mae: 20978.2773 - val_loss: 1120364544.0000 - val_mae: 22514.2148\n",
            "Epoch 193/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1407821440.0000 - mae: 21037.0371 - val_loss: 1114818432.0000 - val_mae: 22578.8008\n",
            "Epoch 194/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1402213120.0000 - mae: 20960.5371 - val_loss: 1115688448.0000 - val_mae: 22472.0410\n",
            "Epoch 195/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1399629184.0000 - mae: 20881.0840 - val_loss: 1114689536.0000 - val_mae: 22455.0996\n",
            "Epoch 196/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1396822528.0000 - mae: 20898.5312 - val_loss: 1111304064.0000 - val_mae: 22459.2773\n",
            "Epoch 197/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1393644544.0000 - mae: 20857.3184 - val_loss: 1109281792.0000 - val_mae: 22438.5488\n",
            "Epoch 198/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1391632000.0000 - mae: 20839.2676 - val_loss: 1108382080.0000 - val_mae: 22398.4805\n",
            "Epoch 199/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1389621504.0000 - mae: 20765.9492 - val_loss: 1108550912.0000 - val_mae: 22341.0918\n",
            "Epoch 200/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1387944320.0000 - mae: 20757.3867 - val_loss: 1106101760.0000 - val_mae: 22343.2090\n",
            "Epoch 201/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1383822208.0000 - mae: 20755.0938 - val_loss: 1102317824.0000 - val_mae: 22351.7363\n",
            "Epoch 202/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1382147200.0000 - mae: 20733.5664 - val_loss: 1100545024.0000 - val_mae: 22349.0645\n",
            "Epoch 203/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1379210624.0000 - mae: 20738.6719 - val_loss: 1096625024.0000 - val_mae: 22358.9785\n",
            "Epoch 204/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1376688128.0000 - mae: 20654.4023 - val_loss: 1101011968.0000 - val_mae: 22248.4531\n",
            "Epoch 205/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1375329024.0000 - mae: 20640.3477 - val_loss: 1099391744.0000 - val_mae: 22224.4414\n",
            "Epoch 206/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1370987264.0000 - mae: 20581.5586 - val_loss: 1097610240.0000 - val_mae: 22218.4629\n",
            "Epoch 207/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1368971264.0000 - mae: 20634.1738 - val_loss: 1091752064.0000 - val_mae: 22279.8496\n",
            "Epoch 208/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1366223488.0000 - mae: 20590.8555 - val_loss: 1091357440.0000 - val_mae: 22220.3789\n",
            "Epoch 209/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1363949312.0000 - mae: 20574.7402 - val_loss: 1088536576.0000 - val_mae: 22223.4414\n",
            "Epoch 210/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1361591040.0000 - mae: 20559.4922 - val_loss: 1086519552.0000 - val_mae: 22192.4336\n",
            "Epoch 211/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1359047168.0000 - mae: 20494.5898 - val_loss: 1085823872.0000 - val_mae: 22152.5938\n",
            "Epoch 212/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1356648064.0000 - mae: 20486.0801 - val_loss: 1083387776.0000 - val_mae: 22155.1465\n",
            "Epoch 213/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1353699840.0000 - mae: 20443.6875 - val_loss: 1082845312.0000 - val_mae: 22099.8672\n",
            "Epoch 214/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1351536896.0000 - mae: 20435.2812 - val_loss: 1079383680.0000 - val_mae: 22126.4531\n",
            "Epoch 215/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1350072448.0000 - mae: 20432.8047 - val_loss: 1075942912.0000 - val_mae: 22125.7910\n",
            "Epoch 216/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1346157440.0000 - mae: 20403.1230 - val_loss: 1075663104.0000 - val_mae: 22066.6309\n",
            "Epoch 217/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1345615872.0000 - mae: 20386.2129 - val_loss: 1072710464.0000 - val_mae: 22066.0645\n",
            "Epoch 218/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1341715584.0000 - mae: 20302.9609 - val_loss: 1074347520.0000 - val_mae: 21981.6289\n",
            "Epoch 219/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1339677568.0000 - mae: 20268.2969 - val_loss: 1071825152.0000 - val_mae: 21986.9707\n",
            "Epoch 220/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1338029696.0000 - mae: 20253.3652 - val_loss: 1072169920.0000 - val_mae: 21945.9297\n",
            "Epoch 221/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1335408000.0000 - mae: 20251.2734 - val_loss: 1067982016.0000 - val_mae: 21972.4922\n",
            "Epoch 222/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1333276928.0000 - mae: 20259.5059 - val_loss: 1065540416.0000 - val_mae: 21968.6621\n",
            "Epoch 223/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1332697728.0000 - mae: 20182.4531 - val_loss: 1067880704.0000 - val_mae: 21860.5332\n",
            "Epoch 224/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1327643520.0000 - mae: 20149.0391 - val_loss: 1063702144.0000 - val_mae: 21895.7344\n",
            "Epoch 225/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1325822976.0000 - mae: 20152.3242 - val_loss: 1061964480.0000 - val_mae: 21872.3008\n",
            "Epoch 226/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1325547008.0000 - mae: 20188.3105 - val_loss: 1058590016.0000 - val_mae: 21905.0586\n",
            "Epoch 227/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1321616000.0000 - mae: 20119.5625 - val_loss: 1058788032.0000 - val_mae: 21844.3574\n",
            "Epoch 228/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1319794944.0000 - mae: 20091.4980 - val_loss: 1056918464.0000 - val_mae: 21822.9043\n",
            "Epoch 229/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1320347392.0000 - mae: 20039.5996 - val_loss: 1057570816.0000 - val_mae: 21781.8594\n",
            "Epoch 230/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1316479872.0000 - mae: 20014.5293 - val_loss: 1054183424.0000 - val_mae: 21807.6445\n",
            "Epoch 231/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1313683456.0000 - mae: 20056.7520 - val_loss: 1051380288.0000 - val_mae: 21805.4922\n",
            "Epoch 232/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1312375936.0000 - mae: 20040.3066 - val_loss: 1048692608.0000 - val_mae: 21804.2637\n",
            "Epoch 233/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1310630656.0000 - mae: 19997.7188 - val_loss: 1049366144.0000 - val_mae: 21745.8242\n",
            "Epoch 234/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1306857344.0000 - mae: 19957.6719 - val_loss: 1047885248.0000 - val_mae: 21716.7188\n",
            "Epoch 235/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1304367488.0000 - mae: 19948.7422 - val_loss: 1044549120.0000 - val_mae: 21733.8789\n",
            "Epoch 236/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1305494272.0000 - mae: 20003.6934 - val_loss: 1041084992.0000 - val_mae: 21766.4746\n",
            "Epoch 237/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1301721984.0000 - mae: 19925.6406 - val_loss: 1043665408.0000 - val_mae: 21657.7031\n",
            "Epoch 238/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1298174720.0000 - mae: 19877.4082 - val_loss: 1040992000.0000 - val_mae: 21660.3281\n",
            "Epoch 239/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1297053440.0000 - mae: 19891.2266 - val_loss: 1038171776.0000 - val_mae: 21665.5371\n",
            "Epoch 240/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1295341312.0000 - mae: 19862.9102 - val_loss: 1038350336.0000 - val_mae: 21609.4609\n",
            "Epoch 241/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1292764160.0000 - mae: 19840.4121 - val_loss: 1035198592.0000 - val_mae: 21633.9023\n",
            "Epoch 242/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1293537408.0000 - mae: 19796.1172 - val_loss: 1035947200.0000 - val_mae: 21580.1602\n",
            "Epoch 243/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1288660864.0000 - mae: 19774.6445 - val_loss: 1033339584.0000 - val_mae: 21599.4375\n",
            "Epoch 244/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1291077632.0000 - mae: 19851.7676 - val_loss: 1029134848.0000 - val_mae: 21631.4375\n",
            "Epoch 245/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1284060928.0000 - mae: 19776.9746 - val_loss: 1030922240.0000 - val_mae: 21543.7832\n",
            "Epoch 246/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1284408064.0000 - mae: 19733.8633 - val_loss: 1028103360.0000 - val_mae: 21550.6406\n",
            "Epoch 247/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1281059968.0000 - mae: 19706.0410 - val_loss: 1027099008.0000 - val_mae: 21522.7305\n",
            "Epoch 248/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1278536960.0000 - mae: 19643.7090 - val_loss: 1031552320.0000 - val_mae: 21419.4980\n",
            "Epoch 249/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1281179136.0000 - mae: 19607.3555 - val_loss: 1031837440.0000 - val_mae: 21397.1836\n",
            "Epoch 250/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1274548352.0000 - mae: 19620.2246 - val_loss: 1025755264.0000 - val_mae: 21490.6504\n",
            "Epoch 251/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1275509632.0000 - mae: 19636.5215 - val_loss: 1024248512.0000 - val_mae: 21482.3828\n",
            "Epoch 252/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1272728448.0000 - mae: 19678.5996 - val_loss: 1020432512.0000 - val_mae: 21514.5898\n",
            "Epoch 253/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1270535808.0000 - mae: 19656.3398 - val_loss: 1020068416.0000 - val_mae: 21454.1836\n",
            "Epoch 254/750\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1268153344.0000 - mae: 19584.1406 - val_loss: 1019150592.0000 - val_mae: 21422.9414\n",
            "Epoch 255/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1268319104.0000 - mae: 19594.1562 - val_loss: 1015164096.0000 - val_mae: 21463.1973\n",
            "Epoch 256/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1263665536.0000 - mae: 19578.6562 - val_loss: 1015509696.0000 - val_mae: 21431.3887\n",
            "Epoch 257/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1263318400.0000 - mae: 19523.4883 - val_loss: 1015683328.0000 - val_mae: 21386.4121\n",
            "Epoch 258/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1261568512.0000 - mae: 19515.6348 - val_loss: 1011762496.0000 - val_mae: 21410.4004\n",
            "Epoch 259/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1258341888.0000 - mae: 19504.6406 - val_loss: 1012532544.0000 - val_mae: 21354.4453\n",
            "Epoch 260/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1257713152.0000 - mae: 19466.2285 - val_loss: 1012325312.0000 - val_mae: 21340.0430\n",
            "Epoch 261/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1262478848.0000 - mae: 19440.0430 - val_loss: 1017046912.0000 - val_mae: 21221.5703\n",
            "Epoch 262/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1255005824.0000 - mae: 19421.6777 - val_loss: 1011003392.0000 - val_mae: 21313.6992\n",
            "Epoch 263/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1250855808.0000 - mae: 19444.0312 - val_loss: 1007390016.0000 - val_mae: 21361.9219\n",
            "Epoch 264/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1251324928.0000 - mae: 19460.7715 - val_loss: 1005979904.0000 - val_mae: 21326.3633\n",
            "Epoch 265/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1252818816.0000 - mae: 19558.4355 - val_loss: 999959104.0000 - val_mae: 21475.4863\n",
            "Epoch 266/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1246362368.0000 - mae: 19471.1680 - val_loss: 1000228416.0000 - val_mae: 21343.7617\n",
            "Epoch 267/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1244720512.0000 - mae: 19409.9414 - val_loss: 999748864.0000 - val_mae: 21313.4043\n",
            "Epoch 268/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1245954560.0000 - mae: 19478.5801 - val_loss: 995764608.0000 - val_mae: 21383.0781\n",
            "Epoch 269/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1241220096.0000 - mae: 19415.2012 - val_loss: 995478016.0000 - val_mae: 21298.9004\n",
            "Epoch 270/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1239267968.0000 - mae: 19356.7578 - val_loss: 995786304.0000 - val_mae: 21257.5566\n",
            "Epoch 271/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1237919104.0000 - mae: 19333.5801 - val_loss: 994463104.0000 - val_mae: 21242.8184\n",
            "Epoch 272/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1237165440.0000 - mae: 19314.8398 - val_loss: 994690752.0000 - val_mae: 21197.8789\n",
            "Epoch 273/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1235206912.0000 - mae: 19311.9062 - val_loss: 990005888.0000 - val_mae: 21291.3906\n",
            "Epoch 274/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1232884736.0000 - mae: 19312.1758 - val_loss: 989761024.0000 - val_mae: 21231.3125\n",
            "Epoch 275/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1231333632.0000 - mae: 19282.7812 - val_loss: 988507584.0000 - val_mae: 21198.5508\n",
            "Epoch 276/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1231800704.0000 - mae: 19254.0215 - val_loss: 989750784.0000 - val_mae: 21161.3008\n",
            "Epoch 277/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1228583680.0000 - mae: 19235.2266 - val_loss: 987116928.0000 - val_mae: 21188.0371\n",
            "Epoch 278/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1228370048.0000 - mae: 19229.2031 - val_loss: 987460992.0000 - val_mae: 21141.2129\n",
            "Epoch 279/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1225010176.0000 - mae: 19208.7129 - val_loss: 983914560.0000 - val_mae: 21189.2734\n",
            "Epoch 280/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1225999744.0000 - mae: 19207.4141 - val_loss: 983615424.0000 - val_mae: 21150.6816\n",
            "Epoch 281/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1223362816.0000 - mae: 19224.6582 - val_loss: 981449216.0000 - val_mae: 21167.2793\n",
            "Epoch 282/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1221203712.0000 - mae: 19204.7500 - val_loss: 978876672.0000 - val_mae: 21164.2402\n",
            "Epoch 283/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1220965120.0000 - mae: 19194.7949 - val_loss: 977532160.0000 - val_mae: 21166.6094\n",
            "Epoch 284/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1219443968.0000 - mae: 19204.5742 - val_loss: 976467968.0000 - val_mae: 21132.6445\n",
            "Epoch 285/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1216761088.0000 - mae: 19131.2617 - val_loss: 978195072.0000 - val_mae: 21072.5137\n",
            "Epoch 286/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1214926720.0000 - mae: 19096.1074 - val_loss: 976900032.0000 - val_mae: 21049.1055\n",
            "Epoch 287/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1212576896.0000 - mae: 19112.8984 - val_loss: 974568512.0000 - val_mae: 21077.1895\n",
            "Epoch 288/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1211688064.0000 - mae: 19119.9160 - val_loss: 971805696.0000 - val_mae: 21088.3457\n",
            "Epoch 289/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1213634304.0000 - mae: 19087.1035 - val_loss: 972815680.0000 - val_mae: 21038.4531\n",
            "Epoch 290/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1209255040.0000 - mae: 19091.3574 - val_loss: 969384512.0000 - val_mae: 21078.4238\n",
            "Epoch 291/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1210492544.0000 - mae: 19077.1680 - val_loss: 970447616.0000 - val_mae: 21006.0781\n",
            "Epoch 292/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1206776192.0000 - mae: 19090.9277 - val_loss: 966252032.0000 - val_mae: 21058.3359\n",
            "Epoch 293/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1204437632.0000 - mae: 19053.9043 - val_loss: 967199936.0000 - val_mae: 21004.3887\n",
            "Epoch 294/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1202762496.0000 - mae: 19038.0273 - val_loss: 964834688.0000 - val_mae: 21009.6289\n",
            "Epoch 295/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1202271744.0000 - mae: 19040.6211 - val_loss: 963233280.0000 - val_mae: 20987.9941\n",
            "Epoch 296/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1200126208.0000 - mae: 19050.1934 - val_loss: 960147968.0000 - val_mae: 21028.0215\n",
            "Epoch 297/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1199011200.0000 - mae: 19001.7773 - val_loss: 961187648.0000 - val_mae: 20959.0137\n",
            "Epoch 298/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1197635840.0000 - mae: 19007.4688 - val_loss: 958933120.0000 - val_mae: 20972.8691\n",
            "Epoch 299/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1196682240.0000 - mae: 18968.5000 - val_loss: 958439936.0000 - val_mae: 20941.3184\n",
            "Epoch 300/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1195762816.0000 - mae: 18938.8691 - val_loss: 958722176.0000 - val_mae: 20912.8281\n",
            "Epoch 301/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1192920064.0000 - mae: 18945.9688 - val_loss: 957041984.0000 - val_mae: 20916.2656\n",
            "Epoch 302/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1193780224.0000 - mae: 19008.4453 - val_loss: 951933632.0000 - val_mae: 20991.8594\n",
            "Epoch 303/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1191440000.0000 - mae: 18939.5449 - val_loss: 954460480.0000 - val_mae: 20887.7812\n",
            "Epoch 304/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1189520640.0000 - mae: 18937.1133 - val_loss: 952172032.0000 - val_mae: 20912.4883\n",
            "Epoch 305/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1189657216.0000 - mae: 18886.1699 - val_loss: 952699968.0000 - val_mae: 20866.2344\n",
            "Epoch 306/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1186256896.0000 - mae: 18888.1426 - val_loss: 950235904.0000 - val_mae: 20893.8867\n",
            "Epoch 307/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1185249792.0000 - mae: 18887.0742 - val_loss: 949179584.0000 - val_mae: 20882.1152\n",
            "Epoch 308/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1184320512.0000 - mae: 18893.1758 - val_loss: 949289856.0000 - val_mae: 20837.3633\n",
            "Epoch 309/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1184090368.0000 - mae: 18840.2070 - val_loss: 948794176.0000 - val_mae: 20804.2734\n",
            "Epoch 310/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1181966080.0000 - mae: 18903.4004 - val_loss: 943339648.0000 - val_mae: 20918.5391\n",
            "Epoch 311/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1180283648.0000 - mae: 18892.4746 - val_loss: 942448896.0000 - val_mae: 20894.5918\n",
            "Epoch 312/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1181193216.0000 - mae: 18809.1992 - val_loss: 945709952.0000 - val_mae: 20786.0215\n",
            "Epoch 313/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1176469120.0000 - mae: 18818.4316 - val_loss: 942284544.0000 - val_mae: 20842.9922\n",
            "Epoch 314/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1176253696.0000 - mae: 18856.4727 - val_loss: 939503104.0000 - val_mae: 20871.8887\n",
            "Epoch 315/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1174707200.0000 - mae: 18828.9277 - val_loss: 939791872.0000 - val_mae: 20804.6875\n",
            "Epoch 316/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1172606848.0000 - mae: 18796.9102 - val_loss: 937928448.0000 - val_mae: 20805.3555\n",
            "Epoch 317/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1173255040.0000 - mae: 18782.6406 - val_loss: 937251200.0000 - val_mae: 20802.6992\n",
            "Epoch 318/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1171171328.0000 - mae: 18748.0820 - val_loss: 937642368.0000 - val_mae: 20752.6367\n",
            "Epoch 319/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1168160512.0000 - mae: 18748.5664 - val_loss: 935449600.0000 - val_mae: 20772.9141\n",
            "Epoch 320/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1168276224.0000 - mae: 18785.8965 - val_loss: 933406336.0000 - val_mae: 20794.9395\n",
            "Epoch 321/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1166550144.0000 - mae: 18750.3535 - val_loss: 932271744.0000 - val_mae: 20773.4082\n",
            "Epoch 322/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1165588224.0000 - mae: 18717.2227 - val_loss: 933360896.0000 - val_mae: 20736.4785\n",
            "Epoch 323/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1166412544.0000 - mae: 18764.5117 - val_loss: 929201280.0000 - val_mae: 20795.6582\n",
            "Epoch 324/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1162023424.0000 - mae: 18717.7285 - val_loss: 930583552.0000 - val_mae: 20721.5957\n",
            "Epoch 325/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1161262848.0000 - mae: 18708.4746 - val_loss: 926528064.0000 - val_mae: 20770.8145\n",
            "Epoch 326/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1161014144.0000 - mae: 18703.7363 - val_loss: 926942912.0000 - val_mae: 20737.5332\n",
            "Epoch 327/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1158823168.0000 - mae: 18701.1719 - val_loss: 926358912.0000 - val_mae: 20726.3633\n",
            "Epoch 328/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1156994176.0000 - mae: 18683.7656 - val_loss: 924747904.0000 - val_mae: 20730.4551\n",
            "Epoch 329/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1156265472.0000 - mae: 18654.2246 - val_loss: 924195072.0000 - val_mae: 20701.8203\n",
            "Epoch 330/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1154817920.0000 - mae: 18657.8906 - val_loss: 922845760.0000 - val_mae: 20708.3359\n",
            "Epoch 331/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1153671296.0000 - mae: 18644.3809 - val_loss: 921384576.0000 - val_mae: 20694.9160\n",
            "Epoch 332/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1152786176.0000 - mae: 18656.3574 - val_loss: 919636864.0000 - val_mae: 20714.3555\n",
            "Epoch 333/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1152995328.0000 - mae: 18626.2422 - val_loss: 918923776.0000 - val_mae: 20698.5664\n",
            "Epoch 334/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1150279296.0000 - mae: 18661.6152 - val_loss: 917098112.0000 - val_mae: 20720.2207\n",
            "Epoch 335/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1150232192.0000 - mae: 18642.2852 - val_loss: 915132672.0000 - val_mae: 20717.7598\n",
            "Epoch 336/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1150163584.0000 - mae: 18590.1660 - val_loss: 917574912.0000 - val_mae: 20643.5527\n",
            "Epoch 337/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1149248384.0000 - mae: 18562.8613 - val_loss: 916270272.0000 - val_mae: 20628.7656\n",
            "Epoch 338/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1146135296.0000 - mae: 18600.3457 - val_loss: 913234880.0000 - val_mae: 20645.9805\n",
            "Epoch 339/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1147006464.0000 - mae: 18621.8945 - val_loss: 910031808.0000 - val_mae: 20699.0684\n",
            "Epoch 340/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1142673536.0000 - mae: 18579.4785 - val_loss: 912178624.0000 - val_mae: 20619.5254\n",
            "Epoch 341/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1143531904.0000 - mae: 18544.9922 - val_loss: 910213824.0000 - val_mae: 20638.8066\n",
            "Epoch 342/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1142359680.0000 - mae: 18510.9258 - val_loss: 913833600.0000 - val_mae: 20543.4902\n",
            "Epoch 343/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1139483264.0000 - mae: 18500.5605 - val_loss: 910644800.0000 - val_mae: 20560.0195\n",
            "Epoch 344/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1138977536.0000 - mae: 18521.3320 - val_loss: 908672448.0000 - val_mae: 20608.3750\n",
            "Epoch 345/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1139388288.0000 - mae: 18547.8848 - val_loss: 908578048.0000 - val_mae: 20562.3945\n",
            "Epoch 346/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1137186816.0000 - mae: 18526.2910 - val_loss: 906094464.0000 - val_mae: 20592.7051\n",
            "Epoch 347/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1137438208.0000 - mae: 18546.5703 - val_loss: 903606592.0000 - val_mae: 20629.3535\n",
            "Epoch 348/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1137142784.0000 - mae: 18476.3145 - val_loss: 907702656.0000 - val_mae: 20511.8398\n",
            "Epoch 349/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1134267392.0000 - mae: 18482.3379 - val_loss: 901935616.0000 - val_mae: 20581.8887\n",
            "Epoch 350/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1132707712.0000 - mae: 18529.2754 - val_loss: 900505088.0000 - val_mae: 20593.2129\n",
            "Epoch 351/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1130331904.0000 - mae: 18482.2188 - val_loss: 902373888.0000 - val_mae: 20534.7480\n",
            "Epoch 352/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1130387584.0000 - mae: 18460.5137 - val_loss: 902328512.0000 - val_mae: 20514.8320\n",
            "Epoch 353/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1129241216.0000 - mae: 18422.8789 - val_loss: 901585600.0000 - val_mae: 20498.6387\n",
            "Epoch 354/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1132285312.0000 - mae: 18525.3848 - val_loss: 895791488.0000 - val_mae: 20623.0078\n",
            "Epoch 355/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1131667072.0000 - mae: 18463.7285 - val_loss: 900105088.0000 - val_mae: 20498.4395\n",
            "Epoch 356/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1126199808.0000 - mae: 18429.1367 - val_loss: 898466304.0000 - val_mae: 20514.2949\n",
            "Epoch 357/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1125575936.0000 - mae: 18483.6914 - val_loss: 895867328.0000 - val_mae: 20526.6992\n",
            "Epoch 358/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1123553536.0000 - mae: 18421.2676 - val_loss: 896267264.0000 - val_mae: 20493.8770\n",
            "Epoch 359/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1122492032.0000 - mae: 18414.7324 - val_loss: 895523392.0000 - val_mae: 20477.0859\n",
            "Epoch 360/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1120372736.0000 - mae: 18433.4629 - val_loss: 892644864.0000 - val_mae: 20524.0234\n",
            "Epoch 361/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1120363648.0000 - mae: 18463.2578 - val_loss: 891098688.0000 - val_mae: 20535.9590\n",
            "Epoch 362/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1119175808.0000 - mae: 18433.9590 - val_loss: 891567488.0000 - val_mae: 20491.6660\n",
            "Epoch 363/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1118783104.0000 - mae: 18437.1641 - val_loss: 889691392.0000 - val_mae: 20505.6523\n",
            "Epoch 364/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1116624000.0000 - mae: 18392.7734 - val_loss: 890145536.0000 - val_mae: 20465.2344\n",
            "Epoch 365/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1115373056.0000 - mae: 18382.9512 - val_loss: 888445312.0000 - val_mae: 20481.4375\n",
            "Epoch 366/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1114464768.0000 - mae: 18369.6816 - val_loss: 888584704.0000 - val_mae: 20439.8730\n",
            "Epoch 367/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1113065728.0000 - mae: 18369.8184 - val_loss: 887371200.0000 - val_mae: 20458.5020\n",
            "Epoch 368/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1115500672.0000 - mae: 18339.6582 - val_loss: 887375616.0000 - val_mae: 20422.1250\n",
            "Epoch 369/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1114100864.0000 - mae: 18402.1797 - val_loss: 883118592.0000 - val_mae: 20500.6133\n",
            "Epoch 370/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1110032256.0000 - mae: 18358.0781 - val_loss: 885144576.0000 - val_mae: 20428.4922\n",
            "Epoch 371/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1109724032.0000 - mae: 18350.0020 - val_loss: 882478016.0000 - val_mae: 20453.9805\n",
            "Epoch 372/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1111233536.0000 - mae: 18285.8750 - val_loss: 888567296.0000 - val_mae: 20350.1523\n",
            "Epoch 373/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1107935104.0000 - mae: 18320.6816 - val_loss: 883114496.0000 - val_mae: 20410.0820\n",
            "Epoch 374/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1107588992.0000 - mae: 18288.2676 - val_loss: 883975872.0000 - val_mae: 20370.6426\n",
            "Epoch 375/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1105265152.0000 - mae: 18330.2988 - val_loss: 881608128.0000 - val_mae: 20412.7852\n",
            "Epoch 376/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1104937856.0000 - mae: 18331.5215 - val_loss: 879455744.0000 - val_mae: 20442.8965\n",
            "Epoch 377/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1103263488.0000 - mae: 18344.0469 - val_loss: 878274368.0000 - val_mae: 20440.7656\n",
            "Epoch 378/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1102418176.0000 - mae: 18300.3203 - val_loss: 879743680.0000 - val_mae: 20366.5586\n",
            "Epoch 379/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1103047168.0000 - mae: 18281.1152 - val_loss: 878668480.0000 - val_mae: 20360.3730\n",
            "Epoch 380/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1100635008.0000 - mae: 18285.9062 - val_loss: 876861568.0000 - val_mae: 20383.0645\n",
            "Epoch 381/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1101622272.0000 - mae: 18271.8438 - val_loss: 878287744.0000 - val_mae: 20335.0078\n",
            "Epoch 382/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1098574976.0000 - mae: 18271.0312 - val_loss: 876301184.0000 - val_mae: 20359.4062\n",
            "Epoch 383/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1097307520.0000 - mae: 18275.5176 - val_loss: 874880704.0000 - val_mae: 20372.5137\n",
            "Epoch 384/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1095700736.0000 - mae: 18279.8730 - val_loss: 872328256.0000 - val_mae: 20407.2402\n",
            "Epoch 385/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1096747264.0000 - mae: 18291.2246 - val_loss: 873459392.0000 - val_mae: 20344.2422\n",
            "Epoch 386/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1094785408.0000 - mae: 18259.3926 - val_loss: 870933824.0000 - val_mae: 20381.0215\n",
            "Epoch 387/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1094395008.0000 - mae: 18273.9121 - val_loss: 869768640.0000 - val_mae: 20380.4668\n",
            "Epoch 388/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1093166592.0000 - mae: 18257.5293 - val_loss: 870482048.0000 - val_mae: 20339.9551\n",
            "Epoch 389/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1097088896.0000 - mae: 18308.0371 - val_loss: 866808704.0000 - val_mae: 20412.1660\n",
            "Epoch 390/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1090034816.0000 - mae: 18204.3867 - val_loss: 871008576.0000 - val_mae: 20288.4805\n",
            "Epoch 391/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1089468032.0000 - mae: 18214.6387 - val_loss: 867597824.0000 - val_mae: 20337.1074\n",
            "Epoch 392/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1090830592.0000 - mae: 18185.8965 - val_loss: 868102784.0000 - val_mae: 20311.5781\n",
            "Epoch 393/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1089600768.0000 - mae: 18266.9531 - val_loss: 864749248.0000 - val_mae: 20363.5723\n",
            "Epoch 394/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1087731072.0000 - mae: 18186.1660 - val_loss: 867379328.0000 - val_mae: 20289.2988\n",
            "Epoch 395/750\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1086200192.0000 - mae: 18208.1504 - val_loss: 865332032.0000 - val_mae: 20308.8145\n",
            "Epoch 396/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1086912000.0000 - mae: 18160.6816 - val_loss: 865686016.0000 - val_mae: 20270.2910\n",
            "Epoch 397/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1087418112.0000 - mae: 18209.9219 - val_loss: 862035584.0000 - val_mae: 20329.2617\n",
            "Epoch 398/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1083334784.0000 - mae: 18221.5449 - val_loss: 862862144.0000 - val_mae: 20299.1504\n",
            "Epoch 399/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1082989440.0000 - mae: 18170.6328 - val_loss: 861256192.0000 - val_mae: 20296.3574\n",
            "Epoch 400/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1081051648.0000 - mae: 18147.3672 - val_loss: 862368640.0000 - val_mae: 20242.9941\n",
            "Epoch 401/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1082494592.0000 - mae: 18105.9648 - val_loss: 863299264.0000 - val_mae: 20222.4102\n",
            "Epoch 402/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1079243264.0000 - mae: 18142.7031 - val_loss: 860445120.0000 - val_mae: 20280.4961\n",
            "Epoch 403/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1077923456.0000 - mae: 18165.3809 - val_loss: 859128704.0000 - val_mae: 20272.2578\n",
            "Epoch 404/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1077784064.0000 - mae: 18150.8984 - val_loss: 859758912.0000 - val_mae: 20246.9414\n",
            "Epoch 405/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1077187968.0000 - mae: 18129.8223 - val_loss: 857211392.0000 - val_mae: 20261.0898\n",
            "Epoch 406/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1075745920.0000 - mae: 18121.6426 - val_loss: 857623744.0000 - val_mae: 20247.3496\n",
            "Epoch 407/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1075105792.0000 - mae: 18112.6582 - val_loss: 856491008.0000 - val_mae: 20253.7656\n",
            "Epoch 408/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1074150784.0000 - mae: 18137.7031 - val_loss: 855150080.0000 - val_mae: 20264.9902\n",
            "Epoch 409/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1075897856.0000 - mae: 18098.7891 - val_loss: 856028544.0000 - val_mae: 20219.7266\n",
            "Epoch 410/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1072268864.0000 - mae: 18103.0605 - val_loss: 855281152.0000 - val_mae: 20223.6055\n",
            "Epoch 411/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1073010112.0000 - mae: 18156.6523 - val_loss: 853140352.0000 - val_mae: 20264.6289\n",
            "Epoch 412/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1070402240.0000 - mae: 18101.7773 - val_loss: 853966336.0000 - val_mae: 20206.5254\n",
            "Epoch 413/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1070053888.0000 - mae: 18090.5977 - val_loss: 852050944.0000 - val_mae: 20219.9492\n",
            "Epoch 414/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1069343872.0000 - mae: 18064.7441 - val_loss: 853783104.0000 - val_mae: 20171.1719\n",
            "Epoch 415/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1069601728.0000 - mae: 18105.3047 - val_loss: 851450816.0000 - val_mae: 20197.0996\n",
            "Epoch 416/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1067552576.0000 - mae: 18051.2207 - val_loss: 852005440.0000 - val_mae: 20171.7832\n",
            "Epoch 417/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1068389504.0000 - mae: 18107.1484 - val_loss: 849224640.0000 - val_mae: 20225.4883\n",
            "Epoch 418/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1066533824.0000 - mae: 18067.0781 - val_loss: 850966912.0000 - val_mae: 20160.1055\n",
            "Epoch 419/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1065126016.0000 - mae: 18069.1035 - val_loss: 849093056.0000 - val_mae: 20176.9824\n",
            "Epoch 420/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1066060928.0000 - mae: 18108.7402 - val_loss: 847435328.0000 - val_mae: 20203.8125\n",
            "Epoch 421/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1062543040.0000 - mae: 18049.2812 - val_loss: 849055232.0000 - val_mae: 20148.1035\n",
            "Epoch 422/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1064756992.0000 - mae: 18073.7480 - val_loss: 844913856.0000 - val_mae: 20220.1816\n",
            "Epoch 423/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1064616256.0000 - mae: 18015.1074 - val_loss: 847675648.0000 - val_mae: 20123.0488\n",
            "Epoch 424/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1060095104.0000 - mae: 18035.2520 - val_loss: 845416768.0000 - val_mae: 20166.0898\n",
            "Epoch 425/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1059073216.0000 - mae: 18061.7773 - val_loss: 844856128.0000 - val_mae: 20171.7715\n",
            "Epoch 426/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1057908160.0000 - mae: 18052.9121 - val_loss: 843934016.0000 - val_mae: 20169.7871\n",
            "Epoch 427/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1058846848.0000 - mae: 18044.0781 - val_loss: 843187264.0000 - val_mae: 20161.3867\n",
            "Epoch 428/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1057398080.0000 - mae: 18033.3301 - val_loss: 843072960.0000 - val_mae: 20138.0703\n",
            "Epoch 429/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1056115840.0000 - mae: 17999.3828 - val_loss: 843376448.0000 - val_mae: 20109.2402\n",
            "Epoch 430/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1056182528.0000 - mae: 17968.7207 - val_loss: 843850880.0000 - val_mae: 20080.1230\n",
            "Epoch 431/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1055426816.0000 - mae: 18033.5742 - val_loss: 839946368.0000 - val_mae: 20151.2461\n",
            "Epoch 432/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1053656512.0000 - mae: 18015.4219 - val_loss: 841056640.0000 - val_mae: 20101.1582\n",
            "Epoch 433/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1055149568.0000 - mae: 18079.8223 - val_loss: 839306048.0000 - val_mae: 20140.2207\n",
            "Epoch 434/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1053047488.0000 - mae: 17986.8340 - val_loss: 840019968.0000 - val_mae: 20087.9375\n",
            "Epoch 435/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1051633728.0000 - mae: 17970.8438 - val_loss: 839455296.0000 - val_mae: 20079.2363\n",
            "Epoch 436/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1050749824.0000 - mae: 17995.8008 - val_loss: 837812736.0000 - val_mae: 20100.1172\n",
            "Epoch 437/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1049718208.0000 - mae: 17989.8008 - val_loss: 836980352.0000 - val_mae: 20097.8477\n",
            "Epoch 438/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1048709376.0000 - mae: 18001.9590 - val_loss: 837338496.0000 - val_mae: 20080.7930\n",
            "Epoch 439/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1048979584.0000 - mae: 17960.9727 - val_loss: 835674240.0000 - val_mae: 20084.8242\n",
            "Epoch 440/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1048807360.0000 - mae: 17939.3340 - val_loss: 837622400.0000 - val_mae: 20022.0371\n",
            "Epoch 441/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1046142080.0000 - mae: 17964.1504 - val_loss: 835017472.0000 - val_mae: 20078.0938\n",
            "Epoch 442/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1046043456.0000 - mae: 17962.1270 - val_loss: 834662912.0000 - val_mae: 20080.4805\n",
            "Epoch 443/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1045618048.0000 - mae: 17921.8809 - val_loss: 837981248.0000 - val_mae: 19987.6934\n",
            "Epoch 444/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1044579328.0000 - mae: 17924.6016 - val_loss: 835984384.0000 - val_mae: 20029.7617\n",
            "Epoch 445/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1043130880.0000 - mae: 17957.2363 - val_loss: 834492160.0000 - val_mae: 20040.4531\n",
            "Epoch 446/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1043308160.0000 - mae: 17921.7676 - val_loss: 834587264.0000 - val_mae: 20020.7852\n",
            "Epoch 447/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1044284096.0000 - mae: 17982.1016 - val_loss: 832868032.0000 - val_mae: 20070.3398\n",
            "Epoch 448/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1041113088.0000 - mae: 17935.9199 - val_loss: 833631104.0000 - val_mae: 20017.4297\n",
            "Epoch 449/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1042016704.0000 - mae: 17992.3887 - val_loss: 830894784.0000 - val_mae: 20077.7559\n",
            "Epoch 450/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1040443456.0000 - mae: 17903.4863 - val_loss: 833412288.0000 - val_mae: 19976.5156\n",
            "Epoch 451/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1039120512.0000 - mae: 17869.0371 - val_loss: 834409600.0000 - val_mae: 19954.0879\n",
            "Epoch 452/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1038493440.0000 - mae: 17945.1172 - val_loss: 830063616.0000 - val_mae: 20058.5938\n",
            "Epoch 453/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1037497664.0000 - mae: 17963.7598 - val_loss: 828357120.0000 - val_mae: 20068.7031\n",
            "Epoch 454/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1036278016.0000 - mae: 17977.0879 - val_loss: 828372480.0000 - val_mae: 20073.8906\n",
            "Epoch 455/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1035574080.0000 - mae: 17914.0723 - val_loss: 829412352.0000 - val_mae: 20036.2031\n",
            "Epoch 456/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1034532160.0000 - mae: 17890.3613 - val_loss: 828790656.0000 - val_mae: 20015.6270\n",
            "Epoch 457/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1034610560.0000 - mae: 17907.7480 - val_loss: 829420032.0000 - val_mae: 19983.9941\n",
            "Epoch 458/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1033884544.0000 - mae: 17891.8516 - val_loss: 828975296.0000 - val_mae: 19978.5645\n",
            "Epoch 459/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1032468992.0000 - mae: 17912.2969 - val_loss: 826393472.0000 - val_mae: 20050.8789\n",
            "Epoch 460/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1031936192.0000 - mae: 17961.4434 - val_loss: 824628736.0000 - val_mae: 20069.1465\n",
            "Epoch 461/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1034967744.0000 - mae: 17882.5684 - val_loss: 827084800.0000 - val_mae: 19982.4688\n",
            "Epoch 462/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1029711680.0000 - mae: 17877.6016 - val_loss: 825867072.0000 - val_mae: 20000.7422\n",
            "Epoch 463/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1029264192.0000 - mae: 17864.9980 - val_loss: 826158720.0000 - val_mae: 19976.8398\n",
            "Epoch 464/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1030810816.0000 - mae: 17930.2246 - val_loss: 821685248.0000 - val_mae: 20092.4062\n",
            "Epoch 465/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1037457216.0000 - mae: 17885.3594 - val_loss: 827924928.0000 - val_mae: 19925.4297\n",
            "Epoch 466/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1028161792.0000 - mae: 17864.9004 - val_loss: 823503360.0000 - val_mae: 20040.5195\n",
            "Epoch 467/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1026296384.0000 - mae: 17891.6270 - val_loss: 825140928.0000 - val_mae: 19981.2402\n",
            "Epoch 468/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1025325952.0000 - mae: 17869.7969 - val_loss: 825267392.0000 - val_mae: 19945.4434\n",
            "Epoch 469/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1025307776.0000 - mae: 17822.0938 - val_loss: 826324480.0000 - val_mae: 19917.8262\n",
            "Epoch 470/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1023045632.0000 - mae: 17818.7617 - val_loss: 823822848.0000 - val_mae: 19960.0996\n",
            "Epoch 471/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1024487808.0000 - mae: 17903.6309 - val_loss: 822942208.0000 - val_mae: 19993.5371\n",
            "Epoch 472/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1023604928.0000 - mae: 17850.9961 - val_loss: 821483328.0000 - val_mae: 19994.3496\n",
            "Epoch 473/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1024220224.0000 - mae: 17896.9043 - val_loss: 820568384.0000 - val_mae: 20002.5957\n",
            "Epoch 474/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1020456128.0000 - mae: 17834.5410 - val_loss: 823189120.0000 - val_mae: 19912.9473\n",
            "Epoch 475/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1022555648.0000 - mae: 17867.5176 - val_loss: 819917504.0000 - val_mae: 19992.8652\n",
            "Epoch 476/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1019917824.0000 - mae: 17810.6387 - val_loss: 822926656.0000 - val_mae: 19877.8184\n",
            "Epoch 477/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1020864320.0000 - mae: 17841.1816 - val_loss: 819074240.0000 - val_mae: 19987.2363\n",
            "Epoch 478/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1018784256.0000 - mae: 17870.9922 - val_loss: 817770048.0000 - val_mae: 19994.7754\n",
            "Epoch 479/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1017351040.0000 - mae: 17823.0605 - val_loss: 819301248.0000 - val_mae: 19916.7285\n",
            "Epoch 480/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1017125888.0000 - mae: 17814.0957 - val_loss: 817487040.0000 - val_mae: 19956.4082\n",
            "Epoch 481/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1016244928.0000 - mae: 17799.6211 - val_loss: 818954176.0000 - val_mae: 19907.2129\n",
            "Epoch 482/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1017098496.0000 - mae: 17836.5039 - val_loss: 815357824.0000 - val_mae: 19981.8828\n",
            "Epoch 483/750\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1014119552.0000 - mae: 17807.8438 - val_loss: 818342208.0000 - val_mae: 19887.9453\n",
            "Epoch 484/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1017443968.0000 - mae: 17762.5684 - val_loss: 819034816.0000 - val_mae: 19877.2852\n",
            "Epoch 485/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1014406848.0000 - mae: 17878.4219 - val_loss: 815036992.0000 - val_mae: 19990.9434\n",
            "Epoch 486/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1012631936.0000 - mae: 17873.3770 - val_loss: 814304384.0000 - val_mae: 19973.3281\n",
            "Epoch 487/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1013642368.0000 - mae: 17827.5918 - val_loss: 816159680.0000 - val_mae: 19890.2578\n",
            "Epoch 488/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1013052544.0000 - mae: 17822.3984 - val_loss: 813099456.0000 - val_mae: 19968.2598\n",
            "Epoch 489/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1010205504.0000 - mae: 17811.2109 - val_loss: 814145856.0000 - val_mae: 19924.3652\n",
            "Epoch 490/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1009476096.0000 - mae: 17800.3691 - val_loss: 813451328.0000 - val_mae: 19925.0059\n",
            "Epoch 491/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1008462400.0000 - mae: 17799.8574 - val_loss: 812548672.0000 - val_mae: 19935.7207\n",
            "Epoch 492/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1009706880.0000 - mae: 17804.4102 - val_loss: 813179200.0000 - val_mae: 19908.2266\n",
            "Epoch 493/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1007006336.0000 - mae: 17769.1836 - val_loss: 811701888.0000 - val_mae: 19937.3926\n",
            "Epoch 494/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1007832512.0000 - mae: 17841.4102 - val_loss: 811152704.0000 - val_mae: 19956.6719\n",
            "Epoch 495/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1007062976.0000 - mae: 17763.3691 - val_loss: 811995328.0000 - val_mae: 19883.8613\n",
            "Epoch 496/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1006502400.0000 - mae: 17765.8848 - val_loss: 812457728.0000 - val_mae: 19868.0938\n",
            "Epoch 497/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1006537728.0000 - mae: 17798.6758 - val_loss: 810615616.0000 - val_mae: 19902.6738\n",
            "Epoch 498/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1005623552.0000 - mae: 17742.6230 - val_loss: 811258816.0000 - val_mae: 19866.4922\n",
            "Epoch 499/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1004284160.0000 - mae: 17792.4414 - val_loss: 809595840.0000 - val_mae: 19906.4238\n",
            "Epoch 500/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1002575744.0000 - mae: 17750.3594 - val_loss: 809937728.0000 - val_mae: 19872.2266\n",
            "Epoch 501/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1002904384.0000 - mae: 17772.8828 - val_loss: 808458944.0000 - val_mae: 19908.3789\n",
            "Epoch 502/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1002220864.0000 - mae: 17770.4590 - val_loss: 808003072.0000 - val_mae: 19894.8105\n",
            "Epoch 503/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1001037888.0000 - mae: 17735.3496 - val_loss: 809327168.0000 - val_mae: 19857.3242\n",
            "Epoch 504/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1000391168.0000 - mae: 17715.6758 - val_loss: 808341376.0000 - val_mae: 19849.0918\n",
            "Epoch 505/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 999249728.0000 - mae: 17714.7871 - val_loss: 808527040.0000 - val_mae: 19836.9590\n",
            "Epoch 506/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1000974400.0000 - mae: 17770.9258 - val_loss: 806848960.0000 - val_mae: 19898.2480\n",
            "Epoch 507/750\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1002041152.0000 - mae: 17660.8945 - val_loss: 812475840.0000 - val_mae: 19735.8223\n",
            "Epoch 508/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 998001856.0000 - mae: 17679.0371 - val_loss: 810167872.0000 - val_mae: 19790.9570\n",
            "Epoch 509/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 998873344.0000 - mae: 17726.9395 - val_loss: 807285824.0000 - val_mae: 19874.4160\n",
            "Epoch 510/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 996403584.0000 - mae: 17681.7559 - val_loss: 811665728.0000 - val_mae: 19758.0391\n",
            "Epoch 511/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 995832768.0000 - mae: 17659.8281 - val_loss: 810430592.0000 - val_mae: 19778.8555\n",
            "Epoch 512/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 994805568.0000 - mae: 17689.5957 - val_loss: 809429568.0000 - val_mae: 19799.8984\n",
            "Epoch 513/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 995385984.0000 - mae: 17722.7559 - val_loss: 806948416.0000 - val_mae: 19824.5332\n",
            "Epoch 514/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 993531392.0000 - mae: 17716.7188 - val_loss: 808118976.0000 - val_mae: 19783.2969\n",
            "Epoch 515/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 996267328.0000 - mae: 17750.2383 - val_loss: 804646848.0000 - val_mae: 19876.3672\n",
            "Epoch 516/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 991805120.0000 - mae: 17682.2637 - val_loss: 807833152.0000 - val_mae: 19763.8730\n",
            "Epoch 517/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 992239360.0000 - mae: 17654.5156 - val_loss: 806900800.0000 - val_mae: 19775.7168\n",
            "Epoch 518/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 990867840.0000 - mae: 17681.7324 - val_loss: 805964864.0000 - val_mae: 19807.4590\n",
            "Epoch 519/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 989799104.0000 - mae: 17708.2773 - val_loss: 804528384.0000 - val_mae: 19818.8008\n",
            "Epoch 520/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 990842304.0000 - mae: 17704.8770 - val_loss: 804331008.0000 - val_mae: 19830.8340\n",
            "Epoch 521/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 989484864.0000 - mae: 17689.8691 - val_loss: 804684544.0000 - val_mae: 19808.8359\n",
            "Epoch 522/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 989132864.0000 - mae: 17660.6289 - val_loss: 805518400.0000 - val_mae: 19757.2246\n",
            "Epoch 523/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 987932096.0000 - mae: 17674.7227 - val_loss: 803532096.0000 - val_mae: 19792.8027\n",
            "Epoch 524/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 988013696.0000 - mae: 17715.6113 - val_loss: 803110848.0000 - val_mae: 19805.5332\n",
            "Epoch 525/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 987798912.0000 - mae: 17685.2402 - val_loss: 804267200.0000 - val_mae: 19752.9961\n",
            "Epoch 526/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 986199808.0000 - mae: 17668.5391 - val_loss: 802959488.0000 - val_mae: 19777.3223\n",
            "Epoch 527/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 985192640.0000 - mae: 17662.0625 - val_loss: 803315712.0000 - val_mae: 19735.2422\n",
            "Epoch 528/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 985899968.0000 - mae: 17639.2070 - val_loss: 804168640.0000 - val_mae: 19717.3965\n",
            "Epoch 529/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 985298240.0000 - mae: 17679.4727 - val_loss: 801566336.0000 - val_mae: 19790.0078\n",
            "Epoch 530/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 983222400.0000 - mae: 17658.7500 - val_loss: 802046976.0000 - val_mae: 19754.4941\n",
            "Epoch 531/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 984582400.0000 - mae: 17710.7871 - val_loss: 800833536.0000 - val_mae: 19778.3848\n",
            "Epoch 532/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 984050368.0000 - mae: 17619.2773 - val_loss: 803507968.0000 - val_mae: 19687.8965\n",
            "Epoch 533/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 981559808.0000 - mae: 17628.7363 - val_loss: 800624064.0000 - val_mae: 19758.5059\n",
            "Epoch 534/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 980988608.0000 - mae: 17662.4219 - val_loss: 800643008.0000 - val_mae: 19749.3203\n",
            "Epoch 535/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 979865408.0000 - mae: 17637.4395 - val_loss: 800247104.0000 - val_mae: 19739.0703\n",
            "Epoch 536/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 979976896.0000 - mae: 17640.5586 - val_loss: 800565504.0000 - val_mae: 19724.2070\n",
            "Epoch 537/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 980598784.0000 - mae: 17644.6113 - val_loss: 801314624.0000 - val_mae: 19692.9727\n",
            "Epoch 538/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 979877056.0000 - mae: 17643.2266 - val_loss: 798835072.0000 - val_mae: 19755.5957\n",
            "Epoch 539/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 980153600.0000 - mae: 17612.0781 - val_loss: 800740864.0000 - val_mae: 19672.0332\n",
            "Epoch 540/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 977582912.0000 - mae: 17645.2910 - val_loss: 798045824.0000 - val_mae: 19772.0215\n",
            "Epoch 541/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 976453248.0000 - mae: 17634.4746 - val_loss: 798357120.0000 - val_mae: 19737.1797\n",
            "Epoch 542/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 975895872.0000 - mae: 17644.6562 - val_loss: 797281472.0000 - val_mae: 19730.3184\n",
            "Epoch 543/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 975799936.0000 - mae: 17621.5527 - val_loss: 797473216.0000 - val_mae: 19705.0098\n",
            "Epoch 544/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 977162880.0000 - mae: 17556.8672 - val_loss: 800188480.0000 - val_mae: 19640.8203\n",
            "Epoch 545/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 974081472.0000 - mae: 17615.8047 - val_loss: 797730752.0000 - val_mae: 19736.0996\n",
            "Epoch 546/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 973447104.0000 - mae: 17634.4160 - val_loss: 797476032.0000 - val_mae: 19674.1035\n",
            "Epoch 547/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 973387392.0000 - mae: 17603.4531 - val_loss: 797179136.0000 - val_mae: 19675.1426\n",
            "Epoch 548/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 972081664.0000 - mae: 17598.4219 - val_loss: 796797632.0000 - val_mae: 19685.1582\n",
            "Epoch 549/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 974026496.0000 - mae: 17670.8438 - val_loss: 796022016.0000 - val_mae: 19726.0254\n",
            "Epoch 550/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 971898816.0000 - mae: 17559.5469 - val_loss: 797906432.0000 - val_mae: 19647.2910\n",
            "Epoch 551/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 970476352.0000 - mae: 17550.2031 - val_loss: 797234304.0000 - val_mae: 19660.3125\n",
            "Epoch 552/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 972341504.0000 - mae: 17652.9824 - val_loss: 794982016.0000 - val_mae: 19711.0586\n",
            "Epoch 553/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 970232512.0000 - mae: 17591.0742 - val_loss: 795242432.0000 - val_mae: 19705.5703\n",
            "Epoch 554/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 970453504.0000 - mae: 17632.2617 - val_loss: 794810112.0000 - val_mae: 19687.6836\n",
            "Epoch 555/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 967895104.0000 - mae: 17565.9863 - val_loss: 795421504.0000 - val_mae: 19648.0703\n",
            "Epoch 556/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 967458176.0000 - mae: 17589.7715 - val_loss: 793700544.0000 - val_mae: 19701.1211\n",
            "Epoch 557/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 967015808.0000 - mae: 17593.4102 - val_loss: 794577472.0000 - val_mae: 19655.0215\n",
            "Epoch 558/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 967815808.0000 - mae: 17582.9434 - val_loss: 794292416.0000 - val_mae: 19645.7676\n",
            "Epoch 559/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 965888384.0000 - mae: 17566.8438 - val_loss: 794226688.0000 - val_mae: 19650.2051\n",
            "Epoch 560/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 966911744.0000 - mae: 17627.2227 - val_loss: 792585024.0000 - val_mae: 19707.7949\n",
            "Epoch 561/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 967155328.0000 - mae: 17521.5625 - val_loss: 795092352.0000 - val_mae: 19604.6875\n",
            "Epoch 562/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 964282304.0000 - mae: 17553.1523 - val_loss: 793223872.0000 - val_mae: 19644.0801\n",
            "Epoch 563/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 962921024.0000 - mae: 17544.3574 - val_loss: 793955648.0000 - val_mae: 19616.6191\n",
            "Epoch 564/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 962541504.0000 - mae: 17549.1172 - val_loss: 792970432.0000 - val_mae: 19646.3301\n",
            "Epoch 565/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 963703360.0000 - mae: 17613.6660 - val_loss: 791147008.0000 - val_mae: 19702.5879\n",
            "Epoch 566/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 961582080.0000 - mae: 17556.1602 - val_loss: 792961344.0000 - val_mae: 19603.3613\n",
            "Epoch 567/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 961627584.0000 - mae: 17542.4336 - val_loss: 791590400.0000 - val_mae: 19649.1953\n",
            "Epoch 568/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 959927872.0000 - mae: 17518.4746 - val_loss: 794401984.0000 - val_mae: 19559.4844\n",
            "Epoch 569/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 960251456.0000 - mae: 17486.1094 - val_loss: 795218944.0000 - val_mae: 19541.6152\n",
            "Epoch 570/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 960543936.0000 - mae: 17530.4922 - val_loss: 792098944.0000 - val_mae: 19631.3633\n",
            "Epoch 571/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 958499712.0000 - mae: 17567.8281 - val_loss: 792375680.0000 - val_mae: 19605.8906\n",
            "Epoch 572/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 957541120.0000 - mae: 17533.8438 - val_loss: 792281920.0000 - val_mae: 19601.9453\n",
            "Epoch 573/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 956868992.0000 - mae: 17535.2051 - val_loss: 791821312.0000 - val_mae: 19611.5391\n",
            "Epoch 574/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 957252416.0000 - mae: 17536.4746 - val_loss: 791913472.0000 - val_mae: 19594.8574\n",
            "Epoch 575/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 957277824.0000 - mae: 17507.0410 - val_loss: 792663296.0000 - val_mae: 19534.8496\n",
            "Epoch 576/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 955917632.0000 - mae: 17517.4062 - val_loss: 790888064.0000 - val_mae: 19610.7285\n",
            "Epoch 577/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 955732928.0000 - mae: 17549.4180 - val_loss: 790244736.0000 - val_mae: 19607.0957\n",
            "Epoch 578/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 954959168.0000 - mae: 17548.5254 - val_loss: 790004928.0000 - val_mae: 19600.6289\n",
            "Epoch 579/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 955200768.0000 - mae: 17494.3105 - val_loss: 791565120.0000 - val_mae: 19536.3594\n",
            "Epoch 580/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 953888832.0000 - mae: 17601.4473 - val_loss: 788003008.0000 - val_mae: 19692.9629\n",
            "Epoch 581/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 953457792.0000 - mae: 17601.0605 - val_loss: 788728960.0000 - val_mae: 19616.0586\n",
            "Epoch 582/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 953563008.0000 - mae: 17495.8242 - val_loss: 789876608.0000 - val_mae: 19572.0020\n",
            "Epoch 583/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 951229440.0000 - mae: 17511.0840 - val_loss: 787958912.0000 - val_mae: 19609.2539\n",
            "Epoch 584/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 951276864.0000 - mae: 17542.0801 - val_loss: 787602496.0000 - val_mae: 19622.5742\n",
            "Epoch 585/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 950253376.0000 - mae: 17533.6758 - val_loss: 787523584.0000 - val_mae: 19596.6152\n",
            "Epoch 586/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 950236288.0000 - mae: 17495.8926 - val_loss: 788886976.0000 - val_mae: 19531.2715\n",
            "Epoch 587/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 949330752.0000 - mae: 17515.0977 - val_loss: 786963072.0000 - val_mae: 19606.1133\n",
            "Epoch 588/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 948742528.0000 - mae: 17503.3809 - val_loss: 787903552.0000 - val_mae: 19543.4004\n",
            "Epoch 589/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 948006848.0000 - mae: 17492.0703 - val_loss: 787185216.0000 - val_mae: 19583.4043\n",
            "Epoch 590/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 948416512.0000 - mae: 17500.5469 - val_loss: 787583680.0000 - val_mae: 19552.1309\n",
            "Epoch 591/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 948168128.0000 - mae: 17538.6465 - val_loss: 786220608.0000 - val_mae: 19604.5605\n",
            "Epoch 592/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 946998592.0000 - mae: 17500.0566 - val_loss: 787016512.0000 - val_mae: 19544.2168\n",
            "Epoch 593/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 947334208.0000 - mae: 17522.9512 - val_loss: 786394048.0000 - val_mae: 19579.3125\n",
            "Epoch 594/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 946133888.0000 - mae: 17524.5547 - val_loss: 786293632.0000 - val_mae: 19560.0312\n",
            "Epoch 595/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 944491648.0000 - mae: 17493.9395 - val_loss: 786038912.0000 - val_mae: 19544.7188\n",
            "Epoch 596/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 944026880.0000 - mae: 17485.2520 - val_loss: 787615104.0000 - val_mae: 19496.7090\n",
            "Epoch 597/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 944034368.0000 - mae: 17445.7383 - val_loss: 787965056.0000 - val_mae: 19483.3145\n",
            "Epoch 598/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 943632384.0000 - mae: 17483.5996 - val_loss: 785853696.0000 - val_mae: 19557.7656\n",
            "Epoch 599/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 942649152.0000 - mae: 17498.1641 - val_loss: 786121984.0000 - val_mae: 19512.4375\n",
            "Epoch 600/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 942635456.0000 - mae: 17482.3770 - val_loss: 786762240.0000 - val_mae: 19508.0684\n",
            "Epoch 601/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 941960000.0000 - mae: 17493.8711 - val_loss: 785129280.0000 - val_mae: 19552.7773\n",
            "Epoch 602/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 941373888.0000 - mae: 17438.3809 - val_loss: 789735808.0000 - val_mae: 19427.7051\n",
            "Epoch 603/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 941077120.0000 - mae: 17467.9727 - val_loss: 786560320.0000 - val_mae: 19533.9355\n",
            "Epoch 604/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 940636224.0000 - mae: 17484.5371 - val_loss: 786862464.0000 - val_mae: 19496.5098\n",
            "Epoch 605/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 939382272.0000 - mae: 17500.8477 - val_loss: 785799360.0000 - val_mae: 19530.0938\n",
            "Epoch 606/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 938886592.0000 - mae: 17454.8105 - val_loss: 786305280.0000 - val_mae: 19466.5410\n",
            "Epoch 607/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 938185216.0000 - mae: 17449.7773 - val_loss: 787360128.0000 - val_mae: 19456.0469\n",
            "Epoch 608/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 937826880.0000 - mae: 17434.2305 - val_loss: 787582976.0000 - val_mae: 19454.7969\n",
            "Epoch 609/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 938347904.0000 - mae: 17434.4668 - val_loss: 786892416.0000 - val_mae: 19472.1504\n",
            "Epoch 610/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 936582912.0000 - mae: 17457.5605 - val_loss: 786387072.0000 - val_mae: 19481.4258\n",
            "Epoch 611/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 935817536.0000 - mae: 17472.0879 - val_loss: 785582080.0000 - val_mae: 19495.1484\n",
            "Epoch 612/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 935242432.0000 - mae: 17460.4062 - val_loss: 785738176.0000 - val_mae: 19490.0938\n",
            "Epoch 613/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 935281600.0000 - mae: 17454.5527 - val_loss: 786133248.0000 - val_mae: 19453.5703\n",
            "Epoch 614/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 934184256.0000 - mae: 17446.4043 - val_loss: 785032256.0000 - val_mae: 19502.6914\n",
            "Epoch 615/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 934575424.0000 - mae: 17447.4141 - val_loss: 785307776.0000 - val_mae: 19456.6895\n",
            "Epoch 616/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 936122432.0000 - mae: 17401.4434 - val_loss: 786175680.0000 - val_mae: 19432.1055\n",
            "Epoch 617/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 932340096.0000 - mae: 17450.5332 - val_loss: 783855040.0000 - val_mae: 19526.2109\n",
            "Epoch 618/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 933545600.0000 - mae: 17485.1914 - val_loss: 783627712.0000 - val_mae: 19538.1465\n",
            "Epoch 619/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 932235968.0000 - mae: 17474.7441 - val_loss: 783397184.0000 - val_mae: 19516.7188\n",
            "Epoch 620/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 932836032.0000 - mae: 17427.7715 - val_loss: 784977600.0000 - val_mae: 19440.3418\n",
            "Epoch 621/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 937120576.0000 - mae: 17538.4883 - val_loss: 781276608.0000 - val_mae: 19547.4062\n",
            "Epoch 622/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 929846208.0000 - mae: 17434.2793 - val_loss: 783749760.0000 - val_mae: 19444.0898\n",
            "Epoch 623/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 930777984.0000 - mae: 17397.4395 - val_loss: 783869248.0000 - val_mae: 19433.4785\n",
            "Epoch 624/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 929654976.0000 - mae: 17434.9824 - val_loss: 783635968.0000 - val_mae: 19434.3164\n",
            "Epoch 625/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 929105024.0000 - mae: 17427.9395 - val_loss: 782211200.0000 - val_mae: 19461.9434\n",
            "Epoch 626/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 929191808.0000 - mae: 17485.2188 - val_loss: 781431424.0000 - val_mae: 19521.6309\n",
            "Epoch 627/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 928542464.0000 - mae: 17417.8281 - val_loss: 783101056.0000 - val_mae: 19424.6309\n",
            "Epoch 628/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 927330240.0000 - mae: 17411.0059 - val_loss: 781847744.0000 - val_mae: 19455.3555\n",
            "Epoch 629/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 927348160.0000 - mae: 17402.6250 - val_loss: 782980160.0000 - val_mae: 19422.3789\n",
            "Epoch 630/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 928016768.0000 - mae: 17431.8906 - val_loss: 780427968.0000 - val_mae: 19538.5723\n",
            "Epoch 631/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 925604096.0000 - mae: 17422.0410 - val_loss: 784121600.0000 - val_mae: 19409.3535\n",
            "Epoch 632/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 925159936.0000 - mae: 17386.9453 - val_loss: 782865856.0000 - val_mae: 19414.5840\n",
            "Epoch 633/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 926101696.0000 - mae: 17453.9160 - val_loss: 781388288.0000 - val_mae: 19517.3457\n",
            "Epoch 634/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 924626560.0000 - mae: 17442.9316 - val_loss: 782359232.0000 - val_mae: 19437.3906\n",
            "Epoch 635/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 924163776.0000 - mae: 17404.3105 - val_loss: 782875648.0000 - val_mae: 19404.1914\n",
            "Epoch 636/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 923060672.0000 - mae: 17450.0938 - val_loss: 781151104.0000 - val_mae: 19505.6855\n",
            "Epoch 637/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 923860928.0000 - mae: 17473.4688 - val_loss: 779652608.0000 - val_mae: 19523.6680\n",
            "Epoch 638/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 923206144.0000 - mae: 17398.9043 - val_loss: 783231616.0000 - val_mae: 19409.7949\n",
            "Epoch 639/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 922937408.0000 - mae: 17368.8184 - val_loss: 784911104.0000 - val_mae: 19343.3242\n",
            "Epoch 640/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 921907136.0000 - mae: 17417.5273 - val_loss: 781782336.0000 - val_mae: 19474.5234\n",
            "Epoch 641/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 920048768.0000 - mae: 17422.8652 - val_loss: 782527168.0000 - val_mae: 19434.7207\n",
            "Epoch 642/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 920143744.0000 - mae: 17414.1191 - val_loss: 782321600.0000 - val_mae: 19420.2129\n",
            "Epoch 643/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 919835776.0000 - mae: 17434.1953 - val_loss: 780996800.0000 - val_mae: 19469.4707\n",
            "Epoch 644/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 918652672.0000 - mae: 17425.5781 - val_loss: 780829824.0000 - val_mae: 19456.0176\n",
            "Epoch 645/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 919732224.0000 - mae: 17441.1523 - val_loss: 781145664.0000 - val_mae: 19419.1602\n",
            "Epoch 646/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 917890560.0000 - mae: 17386.7285 - val_loss: 780739520.0000 - val_mae: 19418.7930\n",
            "Epoch 647/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 917741056.0000 - mae: 17397.4629 - val_loss: 780743360.0000 - val_mae: 19414.2988\n",
            "Epoch 648/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 916725440.0000 - mae: 17419.8574 - val_loss: 780239552.0000 - val_mae: 19454.1270\n",
            "Epoch 649/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 916343872.0000 - mae: 17388.3242 - val_loss: 780268480.0000 - val_mae: 19396.4512\n",
            "Epoch 650/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 916801024.0000 - mae: 17366.2031 - val_loss: 780887040.0000 - val_mae: 19400.4961\n",
            "Epoch 651/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 915881408.0000 - mae: 17424.0352 - val_loss: 779575360.0000 - val_mae: 19440.0605\n",
            "Epoch 652/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 916467968.0000 - mae: 17374.8633 - val_loss: 780196096.0000 - val_mae: 19418.9707\n",
            "Epoch 653/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 914811648.0000 - mae: 17410.7598 - val_loss: 778812480.0000 - val_mae: 19491.4258\n",
            "Epoch 654/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 914173568.0000 - mae: 17455.6172 - val_loss: 779188800.0000 - val_mae: 19490.1504\n",
            "Epoch 655/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 913614656.0000 - mae: 17402.6309 - val_loss: 779321728.0000 - val_mae: 19408.3906\n",
            "Epoch 656/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 912850112.0000 - mae: 17370.5449 - val_loss: 779112576.0000 - val_mae: 19404.3887\n",
            "Epoch 657/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 912238400.0000 - mae: 17376.1602 - val_loss: 779519808.0000 - val_mae: 19396.6465\n",
            "Epoch 658/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 912619456.0000 - mae: 17411.1562 - val_loss: 778513728.0000 - val_mae: 19434.5957\n",
            "Epoch 659/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 913081344.0000 - mae: 17366.4102 - val_loss: 779893888.0000 - val_mae: 19371.3418\n",
            "Epoch 660/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 913395072.0000 - mae: 17437.1777 - val_loss: 778419712.0000 - val_mae: 19452.8496\n",
            "Epoch 661/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 910188160.0000 - mae: 17386.4414 - val_loss: 778518720.0000 - val_mae: 19405.5801\n",
            "Epoch 662/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 910489088.0000 - mae: 17378.3574 - val_loss: 779205376.0000 - val_mae: 19400.6797\n",
            "Epoch 663/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 911919552.0000 - mae: 17319.7480 - val_loss: 780411968.0000 - val_mae: 19346.8086\n",
            "Epoch 664/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 909933440.0000 - mae: 17407.5371 - val_loss: 777265472.0000 - val_mae: 19448.4141\n",
            "Epoch 665/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 909383296.0000 - mae: 17398.9590 - val_loss: 775961216.0000 - val_mae: 19456.7344\n",
            "Epoch 666/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 909276160.0000 - mae: 17439.0938 - val_loss: 776328704.0000 - val_mae: 19494.4941\n",
            "Epoch 667/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 907253824.0000 - mae: 17372.3340 - val_loss: 777623424.0000 - val_mae: 19383.7637\n",
            "Epoch 668/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 911566656.0000 - mae: 17324.2559 - val_loss: 778866048.0000 - val_mae: 19337.4434\n",
            "Epoch 669/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 907284672.0000 - mae: 17328.5977 - val_loss: 777325760.0000 - val_mae: 19403.1172\n",
            "Epoch 670/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 906046336.0000 - mae: 17384.5039 - val_loss: 776567680.0000 - val_mae: 19451.0391\n",
            "Epoch 671/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 905573568.0000 - mae: 17389.0977 - val_loss: 777332800.0000 - val_mae: 19403.5781\n",
            "Epoch 672/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 906678208.0000 - mae: 17398.6855 - val_loss: 776094656.0000 - val_mae: 19419.1191\n",
            "Epoch 673/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 905084608.0000 - mae: 17332.3438 - val_loss: 777267200.0000 - val_mae: 19335.8477\n",
            "Epoch 674/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 904683584.0000 - mae: 17337.9160 - val_loss: 775864448.0000 - val_mae: 19398.8340\n",
            "Epoch 675/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 907378112.0000 - mae: 17307.8418 - val_loss: 778904384.0000 - val_mae: 19308.7773\n",
            "Epoch 676/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 905728704.0000 - mae: 17364.6621 - val_loss: 776814016.0000 - val_mae: 19408.3047\n",
            "Epoch 677/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 904233920.0000 - mae: 17361.6641 - val_loss: 776861696.0000 - val_mae: 19355.6621\n",
            "Epoch 678/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 902880704.0000 - mae: 17307.8066 - val_loss: 777955712.0000 - val_mae: 19342.8203\n",
            "Epoch 679/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 903504704.0000 - mae: 17344.6699 - val_loss: 776391936.0000 - val_mae: 19408.0488\n",
            "Epoch 680/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 903165760.0000 - mae: 17338.8809 - val_loss: 777078592.0000 - val_mae: 19349.5820\n",
            "Epoch 681/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 900936576.0000 - mae: 17314.7520 - val_loss: 776741632.0000 - val_mae: 19387.1543\n",
            "Epoch 682/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 901820928.0000 - mae: 17354.3047 - val_loss: 775893312.0000 - val_mae: 19403.4551\n",
            "Epoch 683/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 901484544.0000 - mae: 17346.8945 - val_loss: 775078464.0000 - val_mae: 19421.8887\n",
            "Epoch 684/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 901320384.0000 - mae: 17379.5918 - val_loss: 774669376.0000 - val_mae: 19417.4297\n",
            "Epoch 685/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 899399616.0000 - mae: 17366.9844 - val_loss: 774828544.0000 - val_mae: 19410.7188\n",
            "Epoch 686/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 898593472.0000 - mae: 17310.4492 - val_loss: 775971392.0000 - val_mae: 19343.5312\n",
            "Epoch 687/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 898803456.0000 - mae: 17301.3184 - val_loss: 776297088.0000 - val_mae: 19347.9629\n",
            "Epoch 688/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 898156096.0000 - mae: 17341.2383 - val_loss: 774523456.0000 - val_mae: 19391.5977\n",
            "Epoch 689/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 896605056.0000 - mae: 17329.0430 - val_loss: 776240000.0000 - val_mae: 19362.5469\n",
            "Epoch 690/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 897311104.0000 - mae: 17291.0703 - val_loss: 775606720.0000 - val_mae: 19358.3359\n",
            "Epoch 691/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 896249344.0000 - mae: 17324.9414 - val_loss: 776617472.0000 - val_mae: 19369.5547\n",
            "Epoch 692/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 895836544.0000 - mae: 17297.2422 - val_loss: 777408704.0000 - val_mae: 19327.0215\n",
            "Epoch 693/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 896618176.0000 - mae: 17325.8848 - val_loss: 775462848.0000 - val_mae: 19393.9512\n",
            "Epoch 694/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 894634880.0000 - mae: 17320.9102 - val_loss: 776254528.0000 - val_mae: 19354.6895\n",
            "Epoch 695/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 894998016.0000 - mae: 17295.2832 - val_loss: 776625600.0000 - val_mae: 19363.0156\n",
            "Epoch 696/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 893670528.0000 - mae: 17289.4746 - val_loss: 776648576.0000 - val_mae: 19344.1543\n",
            "Epoch 697/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 894877184.0000 - mae: 17315.9062 - val_loss: 776311168.0000 - val_mae: 19348.2969\n",
            "Epoch 698/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 892958336.0000 - mae: 17304.1367 - val_loss: 775791104.0000 - val_mae: 19348.7871\n",
            "Epoch 699/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 893904960.0000 - mae: 17324.3262 - val_loss: 775776512.0000 - val_mae: 19339.5781\n",
            "Epoch 700/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 892721216.0000 - mae: 17280.3496 - val_loss: 775869056.0000 - val_mae: 19370.1719\n",
            "Epoch 701/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 894932160.0000 - mae: 17355.1348 - val_loss: 774763392.0000 - val_mae: 19387.1699\n",
            "Epoch 702/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 890468288.0000 - mae: 17286.0840 - val_loss: 775714304.0000 - val_mae: 19340.4492\n",
            "Epoch 703/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 891354816.0000 - mae: 17275.5254 - val_loss: 775494784.0000 - val_mae: 19322.4902\n",
            "Epoch 704/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 890313408.0000 - mae: 17260.8848 - val_loss: 775588224.0000 - val_mae: 19316.4160\n",
            "Epoch 705/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 890713600.0000 - mae: 17255.5723 - val_loss: 775062720.0000 - val_mae: 19342.2637\n",
            "Epoch 706/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 890118976.0000 - mae: 17263.4766 - val_loss: 775630016.0000 - val_mae: 19343.7031\n",
            "Epoch 707/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 888657984.0000 - mae: 17250.8555 - val_loss: 774846400.0000 - val_mae: 19323.7734\n",
            "Epoch 708/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 890603776.0000 - mae: 17340.4785 - val_loss: 773098304.0000 - val_mae: 19414.3594\n",
            "Epoch 709/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 891909440.0000 - mae: 17262.0176 - val_loss: 774508160.0000 - val_mae: 19337.2715\n",
            "Epoch 710/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 887453632.0000 - mae: 17293.2129 - val_loss: 773600704.0000 - val_mae: 19362.0020\n",
            "Epoch 711/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 887698240.0000 - mae: 17261.2344 - val_loss: 774845760.0000 - val_mae: 19318.8145\n",
            "Epoch 712/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 891833728.0000 - mae: 17342.2031 - val_loss: 772850304.0000 - val_mae: 19400.2852\n",
            "Epoch 713/750\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 886111296.0000 - mae: 17255.8105 - val_loss: 774352640.0000 - val_mae: 19295.1133\n",
            "Epoch 714/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 887515328.0000 - mae: 17197.7324 - val_loss: 774822592.0000 - val_mae: 19279.2676\n",
            "Epoch 715/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 888108160.0000 - mae: 17289.4590 - val_loss: 772858880.0000 - val_mae: 19385.5391\n",
            "Epoch 716/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 884684416.0000 - mae: 17255.8535 - val_loss: 773026496.0000 - val_mae: 19299.4473\n",
            "Epoch 717/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 885031936.0000 - mae: 17249.4395 - val_loss: 773721920.0000 - val_mae: 19309.4844\n",
            "Epoch 718/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 885281600.0000 - mae: 17262.5723 - val_loss: 772519680.0000 - val_mae: 19348.1973\n",
            "Epoch 719/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 884227200.0000 - mae: 17249.2188 - val_loss: 773058560.0000 - val_mae: 19300.6387\n",
            "Epoch 720/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 883294720.0000 - mae: 17216.8652 - val_loss: 774054080.0000 - val_mae: 19276.2070\n",
            "Epoch 721/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 883827200.0000 - mae: 17226.7852 - val_loss: 773820032.0000 - val_mae: 19289.2441\n",
            "Epoch 722/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 884448896.0000 - mae: 17318.4434 - val_loss: 772328256.0000 - val_mae: 19382.9121\n",
            "Epoch 723/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 883054528.0000 - mae: 17236.9160 - val_loss: 774157824.0000 - val_mae: 19274.0840\n",
            "Epoch 724/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 881822848.0000 - mae: 17197.1582 - val_loss: 773215040.0000 - val_mae: 19302.3711\n",
            "Epoch 725/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 881344256.0000 - mae: 17231.8047 - val_loss: 773354816.0000 - val_mae: 19309.5273\n",
            "Epoch 726/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 881625920.0000 - mae: 17279.8203 - val_loss: 771654144.0000 - val_mae: 19351.4414\n",
            "Epoch 727/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 880310208.0000 - mae: 17239.0703 - val_loss: 772233792.0000 - val_mae: 19322.2109\n",
            "Epoch 728/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 880154816.0000 - mae: 17240.6621 - val_loss: 771970176.0000 - val_mae: 19334.6621\n",
            "Epoch 729/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 880254784.0000 - mae: 17205.5469 - val_loss: 772973312.0000 - val_mae: 19289.3711\n",
            "Epoch 730/750\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 879312896.0000 - mae: 17203.1777 - val_loss: 772519616.0000 - val_mae: 19313.5039\n",
            "Epoch 731/750\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 877797632.0000 - mae: 17238.8320 - val_loss: 771595712.0000 - val_mae: 19347.1250\n",
            "Epoch 732/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 879664128.0000 - mae: 17292.7988 - val_loss: 770238208.0000 - val_mae: 19375.7246\n",
            "Epoch 733/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 878335488.0000 - mae: 17220.5605 - val_loss: 772084992.0000 - val_mae: 19276.5039\n",
            "Epoch 734/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 877151040.0000 - mae: 17255.0078 - val_loss: 770143744.0000 - val_mae: 19360.6328\n",
            "Epoch 735/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 877683072.0000 - mae: 17268.1738 - val_loss: 769432064.0000 - val_mae: 19400.7812\n",
            "Epoch 736/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 876838528.0000 - mae: 17252.6133 - val_loss: 770804864.0000 - val_mae: 19330.8652\n",
            "Epoch 737/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 876299904.0000 - mae: 17241.7520 - val_loss: 770637696.0000 - val_mae: 19303.2969\n",
            "Epoch 738/750\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 875681536.0000 - mae: 17212.6328 - val_loss: 770729472.0000 - val_mae: 19323.9941\n",
            "Epoch 739/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 874866432.0000 - mae: 17225.8867 - val_loss: 770293120.0000 - val_mae: 19313.8672\n",
            "Epoch 740/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 875747712.0000 - mae: 17272.4004 - val_loss: 769664576.0000 - val_mae: 19371.6367\n",
            "Epoch 741/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 874215680.0000 - mae: 17231.4238 - val_loss: 770975424.0000 - val_mae: 19266.9844\n",
            "Epoch 742/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 875215040.0000 - mae: 17231.6328 - val_loss: 769567744.0000 - val_mae: 19339.3750\n",
            "Epoch 743/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 873059520.0000 - mae: 17246.7168 - val_loss: 769663488.0000 - val_mae: 19325.3223\n",
            "Epoch 744/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 874644160.0000 - mae: 17268.7734 - val_loss: 769610752.0000 - val_mae: 19345.2344\n",
            "Epoch 745/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 874009152.0000 - mae: 17213.8906 - val_loss: 769842176.0000 - val_mae: 19316.2539\n",
            "Epoch 746/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 872097088.0000 - mae: 17240.2656 - val_loss: 769633216.0000 - val_mae: 19349.4512\n",
            "Epoch 747/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 871714624.0000 - mae: 17211.7949 - val_loss: 769617344.0000 - val_mae: 19299.4160\n",
            "Epoch 748/750\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 871479680.0000 - mae: 17196.9121 - val_loss: 770027584.0000 - val_mae: 19298.3945\n",
            "Epoch 749/750\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 870869120.0000 - mae: 17252.4395 - val_loss: 769147776.0000 - val_mae: 19346.8965\n",
            "Epoch 750/750\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 872459776.0000 - mae: 17200.4141 - val_loss: 770604416.0000 - val_mae: 19246.5566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergl(y=history.history['loss'],\n",
        "                    name='Train'))\n",
        "fig.add_trace(go.Scattergl(y=history.history['val_loss'],\n",
        "                    name='Valid'))\n",
        "fig.update_layout(height=500, width=700,\n",
        "                  xaxis_title='Epoch',\n",
        "                  yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5_sCqEXHUGtq",
        "outputId": "35d9b72a-3916-41b0-86a7-41f006cd7fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"3aa4eda6-b896-4362-8cb7-ac6cf5697474\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3aa4eda6-b896-4362-8cb7-ac6cf5697474\")) {                    Plotly.newPlot(                        \"3aa4eda6-b896-4362-8cb7-ac6cf5697474\",                        [{\"name\":\"Train\",\"y\":[39684988928.0,39681806336.0,39673421824.0,39654981632.0,39621509120.0,39566643200.0,39485698048.0,39368974336.0,39212924928.0,39009329152.0,38752587776.0,38433267712.0,38048362496.0,37597421568.0,37061099520.0,36461903872.0,35783008256.0,35029823488.0,34202091520.0,33292531712.0,32331327488.0,31282221056.0,30179641344.0,29000941568.0,27790655488.0,26500435968.0,25203220480.0,23871602688.0,22494050304.0,21130668032.0,19750031360.0,18371944448.0,17035894784.0,15697187840.0,14426090496.0,13190144000.0,12017422336.0,10887610368.0,9834896384.0,8845350912.0,7934682624.0,7120376320.0,6348561408.0,5690741248.0,5092674560.0,4577333760.0,4137299456.0,3751638784.0,3440303360.0,3171094272.0,2959776256.0,2776112128.0,2635359744.0,2514957056.0,2415703296.0,2340381952.0,2276396288.0,2226336256.0,2186985216.0,2152856576.0,2124167936.0,2101062272.0,2077670400.0,2061427968.0,2043919232.0,2029368832.0,2015402368.0,2003388672.0,1991328768.0,1978769920.0,1968101376.0,1957131392.0,1947866240.0,1937368320.0,1927757056.0,1918316672.0,1909252096.0,1902658688.0,1891498112.0,1885333888.0,1876169856.0,1868379648.0,1860077824.0,1853178624.0,1844914688.0,1839105280.0,1831694208.0,1824552704.0,1818079744.0,1812284416.0,1804816128.0,1800479744.0,1794325248.0,1787720832.0,1779146240.0,1773234432.0,1767572608.0,1760286080.0,1756001664.0,1749724032.0,1745467520.0,1738815616.0,1733167488.0,1728581504.0,1723094400.0,1718026880.0,1713404160.0,1708265344.0,1701565952.0,1698578816.0,1691393664.0,1688078592.0,1682168192.0,1676788992.0,1675645056.0,1673541248.0,1660584320.0,1657421312.0,1653574656.0,1648835840.0,1645288832.0,1639375232.0,1635135872.0,1631081856.0,1627780864.0,1622670848.0,1619235072.0,1616673664.0,1609901312.0,1606599040.0,1602804480.0,1598508544.0,1594777728.0,1590883200.0,1587894272.0,1584168832.0,1580594944.0,1575887488.0,1571848192.0,1567419392.0,1564081408.0,1560479744.0,1557765632.0,1553607296.0,1549862656.0,1547527296.0,1544535552.0,1538624384.0,1535719808.0,1533130496.0,1529374080.0,1525675520.0,1522208512.0,1519877120.0,1517620992.0,1512395648.0,1509799552.0,1505371264.0,1503922560.0,1501409152.0,1495836416.0,1492713856.0,1490261504.0,1487828480.0,1483646208.0,1481221376.0,1477544320.0,1473962624.0,1473113216.0,1467995136.0,1465146112.0,1463010432.0,1459549952.0,1457366144.0,1455014656.0,1453067136.0,1449868288.0,1445484544.0,1442507264.0,1440017920.0,1437033216.0,1433464448.0,1430794624.0,1431181568.0,1424922368.0,1423608320.0,1423069440.0,1417548032.0,1415160832.0,1412125056.0,1410278016.0,1407003904.0,1407821440.0,1402213120.0,1399629184.0,1396822528.0,1393644544.0,1391632000.0,1389621504.0,1387944320.0,1383822208.0,1382147200.0,1379210624.0,1376688128.0,1375329024.0,1370987264.0,1368971264.0,1366223488.0,1363949312.0,1361591040.0,1359047168.0,1356648064.0,1353699840.0,1351536896.0,1350072448.0,1346157440.0,1345615872.0,1341715584.0,1339677568.0,1338029696.0,1335408000.0,1333276928.0,1332697728.0,1327643520.0,1325822976.0,1325547008.0,1321616000.0,1319794944.0,1320347392.0,1316479872.0,1313683456.0,1312375936.0,1310630656.0,1306857344.0,1304367488.0,1305494272.0,1301721984.0,1298174720.0,1297053440.0,1295341312.0,1292764160.0,1293537408.0,1288660864.0,1291077632.0,1284060928.0,1284408064.0,1281059968.0,1278536960.0,1281179136.0,1274548352.0,1275509632.0,1272728448.0,1270535808.0,1268153344.0,1268319104.0,1263665536.0,1263318400.0,1261568512.0,1258341888.0,1257713152.0,1262478848.0,1255005824.0,1250855808.0,1251324928.0,1252818816.0,1246362368.0,1244720512.0,1245954560.0,1241220096.0,1239267968.0,1237919104.0,1237165440.0,1235206912.0,1232884736.0,1231333632.0,1231800704.0,1228583680.0,1228370048.0,1225010176.0,1225999744.0,1223362816.0,1221203712.0,1220965120.0,1219443968.0,1216761088.0,1214926720.0,1212576896.0,1211688064.0,1213634304.0,1209255040.0,1210492544.0,1206776192.0,1204437632.0,1202762496.0,1202271744.0,1200126208.0,1199011200.0,1197635840.0,1196682240.0,1195762816.0,1192920064.0,1193780224.0,1191440000.0,1189520640.0,1189657216.0,1186256896.0,1185249792.0,1184320512.0,1184090368.0,1181966080.0,1180283648.0,1181193216.0,1176469120.0,1176253696.0,1174707200.0,1172606848.0,1173255040.0,1171171328.0,1168160512.0,1168276224.0,1166550144.0,1165588224.0,1166412544.0,1162023424.0,1161262848.0,1161014144.0,1158823168.0,1156994176.0,1156265472.0,1154817920.0,1153671296.0,1152786176.0,1152995328.0,1150279296.0,1150232192.0,1150163584.0,1149248384.0,1146135296.0,1147006464.0,1142673536.0,1143531904.0,1142359680.0,1139483264.0,1138977536.0,1139388288.0,1137186816.0,1137438208.0,1137142784.0,1134267392.0,1132707712.0,1130331904.0,1130387584.0,1129241216.0,1132285312.0,1131667072.0,1126199808.0,1125575936.0,1123553536.0,1122492032.0,1120372736.0,1120363648.0,1119175808.0,1118783104.0,1116624000.0,1115373056.0,1114464768.0,1113065728.0,1115500672.0,1114100864.0,1110032256.0,1109724032.0,1111233536.0,1107935104.0,1107588992.0,1105265152.0,1104937856.0,1103263488.0,1102418176.0,1103047168.0,1100635008.0,1101622272.0,1098574976.0,1097307520.0,1095700736.0,1096747264.0,1094785408.0,1094395008.0,1093166592.0,1097088896.0,1090034816.0,1089468032.0,1090830592.0,1089600768.0,1087731072.0,1086200192.0,1086912000.0,1087418112.0,1083334784.0,1082989440.0,1081051648.0,1082494592.0,1079243264.0,1077923456.0,1077784064.0,1077187968.0,1075745920.0,1075105792.0,1074150784.0,1075897856.0,1072268864.0,1073010112.0,1070402240.0,1070053888.0,1069343872.0,1069601728.0,1067552576.0,1068389504.0,1066533824.0,1065126016.0,1066060928.0,1062543040.0,1064756992.0,1064616256.0,1060095104.0,1059073216.0,1057908160.0,1058846848.0,1057398080.0,1056115840.0,1056182528.0,1055426816.0,1053656512.0,1055149568.0,1053047488.0,1051633728.0,1050749824.0,1049718208.0,1048709376.0,1048979584.0,1048807360.0,1046142080.0,1046043456.0,1045618048.0,1044579328.0,1043130880.0,1043308160.0,1044284096.0,1041113088.0,1042016704.0,1040443456.0,1039120512.0,1038493440.0,1037497664.0,1036278016.0,1035574080.0,1034532160.0,1034610560.0,1033884544.0,1032468992.0,1031936192.0,1034967744.0,1029711680.0,1029264192.0,1030810816.0,1037457216.0,1028161792.0,1026296384.0,1025325952.0,1025307776.0,1023045632.0,1024487808.0,1023604928.0,1024220224.0,1020456128.0,1022555648.0,1019917824.0,1020864320.0,1018784256.0,1017351040.0,1017125888.0,1016244928.0,1017098496.0,1014119552.0,1017443968.0,1014406848.0,1012631936.0,1013642368.0,1013052544.0,1010205504.0,1009476096.0,1008462400.0,1009706880.0,1007006336.0,1007832512.0,1007062976.0,1006502400.0,1006537728.0,1005623552.0,1004284160.0,1002575744.0,1002904384.0,1002220864.0,1001037888.0,1000391168.0,999249728.0,1000974400.0,1002041152.0,998001856.0,998873344.0,996403584.0,995832768.0,994805568.0,995385984.0,993531392.0,996267328.0,991805120.0,992239360.0,990867840.0,989799104.0,990842304.0,989484864.0,989132864.0,987932096.0,988013696.0,987798912.0,986199808.0,985192640.0,985899968.0,985298240.0,983222400.0,984582400.0,984050368.0,981559808.0,980988608.0,979865408.0,979976896.0,980598784.0,979877056.0,980153600.0,977582912.0,976453248.0,975895872.0,975799936.0,977162880.0,974081472.0,973447104.0,973387392.0,972081664.0,974026496.0,971898816.0,970476352.0,972341504.0,970232512.0,970453504.0,967895104.0,967458176.0,967015808.0,967815808.0,965888384.0,966911744.0,967155328.0,964282304.0,962921024.0,962541504.0,963703360.0,961582080.0,961627584.0,959927872.0,960251456.0,960543936.0,958499712.0,957541120.0,956868992.0,957252416.0,957277824.0,955917632.0,955732928.0,954959168.0,955200768.0,953888832.0,953457792.0,953563008.0,951229440.0,951276864.0,950253376.0,950236288.0,949330752.0,948742528.0,948006848.0,948416512.0,948168128.0,946998592.0,947334208.0,946133888.0,944491648.0,944026880.0,944034368.0,943632384.0,942649152.0,942635456.0,941960000.0,941373888.0,941077120.0,940636224.0,939382272.0,938886592.0,938185216.0,937826880.0,938347904.0,936582912.0,935817536.0,935242432.0,935281600.0,934184256.0,934575424.0,936122432.0,932340096.0,933545600.0,932235968.0,932836032.0,937120576.0,929846208.0,930777984.0,929654976.0,929105024.0,929191808.0,928542464.0,927330240.0,927348160.0,928016768.0,925604096.0,925159936.0,926101696.0,924626560.0,924163776.0,923060672.0,923860928.0,923206144.0,922937408.0,921907136.0,920048768.0,920143744.0,919835776.0,918652672.0,919732224.0,917890560.0,917741056.0,916725440.0,916343872.0,916801024.0,915881408.0,916467968.0,914811648.0,914173568.0,913614656.0,912850112.0,912238400.0,912619456.0,913081344.0,913395072.0,910188160.0,910489088.0,911919552.0,909933440.0,909383296.0,909276160.0,907253824.0,911566656.0,907284672.0,906046336.0,905573568.0,906678208.0,905084608.0,904683584.0,907378112.0,905728704.0,904233920.0,902880704.0,903504704.0,903165760.0,900936576.0,901820928.0,901484544.0,901320384.0,899399616.0,898593472.0,898803456.0,898156096.0,896605056.0,897311104.0,896249344.0,895836544.0,896618176.0,894634880.0,894998016.0,893670528.0,894877184.0,892958336.0,893904960.0,892721216.0,894932160.0,890468288.0,891354816.0,890313408.0,890713600.0,890118976.0,888657984.0,890603776.0,891909440.0,887453632.0,887698240.0,891833728.0,886111296.0,887515328.0,888108160.0,884684416.0,885031936.0,885281600.0,884227200.0,883294720.0,883827200.0,884448896.0,883054528.0,881822848.0,881344256.0,881625920.0,880310208.0,880154816.0,880254784.0,879312896.0,877797632.0,879664128.0,878335488.0,877151040.0,877683072.0,876838528.0,876299904.0,875681536.0,874866432.0,875747712.0,874215680.0,875215040.0,873059520.0,874644160.0,874009152.0,872097088.0,871714624.0,871479680.0,870869120.0,872459776.0],\"type\":\"scattergl\"},{\"name\":\"Valid\",\"y\":[39713652736.0,39708389376.0,39695740928.0,39670403072.0,39626522624.0,39559438336.0,39461031936.0,39326273536.0,39146819584.0,38916038656.0,38625570816.0,38276952064.0,37858324480.0,37362098176.0,36803719168.0,36156260352.0,35436163072.0,34646876160.0,33776726016.0,32848400384.0,31829733376.0,30762117120.0,29621882880.0,28437422080.0,27162863616.0,25889019904.0,24560404480.0,23190841344.0,21844264960.0,20450725888.0,19056750592.0,17710901248.0,16352693248.0,15050022912.0,13780689920.0,12568144896.0,11375190016.0,10276322304.0,9238349824.0,8292995072.0,7418801152.0,6572515840.0,5860580864.0,5204856832.0,4645904896.0,4139656704.0,3697711104.0,3346704640.0,3038091520.0,2791642368.0,2566117376.0,2392665600.0,2242126080.0,2128119424.0,2040739200.0,1954616832.0,1887590656.0,1837163520.0,1790239232.0,1751145472.0,1718942464.0,1687932928.0,1665598592.0,1642818304.0,1625780864.0,1609701376.0,1596006144.0,1580550016.0,1567030784.0,1556043904.0,1541804928.0,1531113600.0,1520537088.0,1513105152.0,1505313664.0,1494328832.0,1485712384.0,1473582080.0,1468278400.0,1459173760.0,1454494720.0,1447799552.0,1441457920.0,1435180032.0,1427040128.0,1418613120.0,1414833280.0,1411680256.0,1405631872.0,1399331840.0,1394375552.0,1386270464.0,1388095488.0,1377838336.0,1374895104.0,1369420672.0,1365309184.0,1359654784.0,1351355264.0,1350648832.0,1345564544.0,1341770752.0,1339823744.0,1336724352.0,1329532032.0,1324034304.0,1323860992.0,1319432320.0,1315666560.0,1314093184.0,1307094400.0,1302710912.0,1300149376.0,1295554048.0,1290854912.0,1294900864.0,1285775616.0,1280074112.0,1278479104.0,1274490112.0,1270240768.0,1269089408.0,1266894336.0,1264629376.0,1260108544.0,1257840128.0,1257141376.0,1251300352.0,1251010944.0,1249257728.0,1246546304.0,1243276160.0,1239266688.0,1237750400.0,1233055232.0,1234902400.0,1230636672.0,1229032832.0,1224523904.0,1222183296.0,1220387968.0,1216783872.0,1216394752.0,1214478464.0,1210263296.0,1210897408.0,1204664320.0,1203790464.0,1204049152.0,1198159872.0,1196290432.0,1196632192.0,1195008768.0,1193558144.0,1190733056.0,1188027904.0,1184595968.0,1183041152.0,1181726336.0,1175098240.0,1176007168.0,1175008512.0,1173703168.0,1170527872.0,1169528192.0,1168687616.0,1164550400.0,1162037248.0,1161917568.0,1158328320.0,1156754688.0,1154052096.0,1153162112.0,1152703104.0,1150575488.0,1144877952.0,1150069120.0,1145409408.0,1142045696.0,1141710080.0,1140027008.0,1136710400.0,1134886144.0,1129860992.0,1131977728.0,1132156672.0,1125783808.0,1126371328.0,1124428160.0,1124014848.0,1123473664.0,1120364544.0,1114818432.0,1115688448.0,1114689536.0,1111304064.0,1109281792.0,1108382080.0,1108550912.0,1106101760.0,1102317824.0,1100545024.0,1096625024.0,1101011968.0,1099391744.0,1097610240.0,1091752064.0,1091357440.0,1088536576.0,1086519552.0,1085823872.0,1083387776.0,1082845312.0,1079383680.0,1075942912.0,1075663104.0,1072710464.0,1074347520.0,1071825152.0,1072169920.0,1067982016.0,1065540416.0,1067880704.0,1063702144.0,1061964480.0,1058590016.0,1058788032.0,1056918464.0,1057570816.0,1054183424.0,1051380288.0,1048692608.0,1049366144.0,1047885248.0,1044549120.0,1041084992.0,1043665408.0,1040992000.0,1038171776.0,1038350336.0,1035198592.0,1035947200.0,1033339584.0,1029134848.0,1030922240.0,1028103360.0,1027099008.0,1031552320.0,1031837440.0,1025755264.0,1024248512.0,1020432512.0,1020068416.0,1019150592.0,1015164096.0,1015509696.0,1015683328.0,1011762496.0,1012532544.0,1012325312.0,1017046912.0,1011003392.0,1007390016.0,1005979904.0,999959104.0,1000228416.0,999748864.0,995764608.0,995478016.0,995786304.0,994463104.0,994690752.0,990005888.0,989761024.0,988507584.0,989750784.0,987116928.0,987460992.0,983914560.0,983615424.0,981449216.0,978876672.0,977532160.0,976467968.0,978195072.0,976900032.0,974568512.0,971805696.0,972815680.0,969384512.0,970447616.0,966252032.0,967199936.0,964834688.0,963233280.0,960147968.0,961187648.0,958933120.0,958439936.0,958722176.0,957041984.0,951933632.0,954460480.0,952172032.0,952699968.0,950235904.0,949179584.0,949289856.0,948794176.0,943339648.0,942448896.0,945709952.0,942284544.0,939503104.0,939791872.0,937928448.0,937251200.0,937642368.0,935449600.0,933406336.0,932271744.0,933360896.0,929201280.0,930583552.0,926528064.0,926942912.0,926358912.0,924747904.0,924195072.0,922845760.0,921384576.0,919636864.0,918923776.0,917098112.0,915132672.0,917574912.0,916270272.0,913234880.0,910031808.0,912178624.0,910213824.0,913833600.0,910644800.0,908672448.0,908578048.0,906094464.0,903606592.0,907702656.0,901935616.0,900505088.0,902373888.0,902328512.0,901585600.0,895791488.0,900105088.0,898466304.0,895867328.0,896267264.0,895523392.0,892644864.0,891098688.0,891567488.0,889691392.0,890145536.0,888445312.0,888584704.0,887371200.0,887375616.0,883118592.0,885144576.0,882478016.0,888567296.0,883114496.0,883975872.0,881608128.0,879455744.0,878274368.0,879743680.0,878668480.0,876861568.0,878287744.0,876301184.0,874880704.0,872328256.0,873459392.0,870933824.0,869768640.0,870482048.0,866808704.0,871008576.0,867597824.0,868102784.0,864749248.0,867379328.0,865332032.0,865686016.0,862035584.0,862862144.0,861256192.0,862368640.0,863299264.0,860445120.0,859128704.0,859758912.0,857211392.0,857623744.0,856491008.0,855150080.0,856028544.0,855281152.0,853140352.0,853966336.0,852050944.0,853783104.0,851450816.0,852005440.0,849224640.0,850966912.0,849093056.0,847435328.0,849055232.0,844913856.0,847675648.0,845416768.0,844856128.0,843934016.0,843187264.0,843072960.0,843376448.0,843850880.0,839946368.0,841056640.0,839306048.0,840019968.0,839455296.0,837812736.0,836980352.0,837338496.0,835674240.0,837622400.0,835017472.0,834662912.0,837981248.0,835984384.0,834492160.0,834587264.0,832868032.0,833631104.0,830894784.0,833412288.0,834409600.0,830063616.0,828357120.0,828372480.0,829412352.0,828790656.0,829420032.0,828975296.0,826393472.0,824628736.0,827084800.0,825867072.0,826158720.0,821685248.0,827924928.0,823503360.0,825140928.0,825267392.0,826324480.0,823822848.0,822942208.0,821483328.0,820568384.0,823189120.0,819917504.0,822926656.0,819074240.0,817770048.0,819301248.0,817487040.0,818954176.0,815357824.0,818342208.0,819034816.0,815036992.0,814304384.0,816159680.0,813099456.0,814145856.0,813451328.0,812548672.0,813179200.0,811701888.0,811152704.0,811995328.0,812457728.0,810615616.0,811258816.0,809595840.0,809937728.0,808458944.0,808003072.0,809327168.0,808341376.0,808527040.0,806848960.0,812475840.0,810167872.0,807285824.0,811665728.0,810430592.0,809429568.0,806948416.0,808118976.0,804646848.0,807833152.0,806900800.0,805964864.0,804528384.0,804331008.0,804684544.0,805518400.0,803532096.0,803110848.0,804267200.0,802959488.0,803315712.0,804168640.0,801566336.0,802046976.0,800833536.0,803507968.0,800624064.0,800643008.0,800247104.0,800565504.0,801314624.0,798835072.0,800740864.0,798045824.0,798357120.0,797281472.0,797473216.0,800188480.0,797730752.0,797476032.0,797179136.0,796797632.0,796022016.0,797906432.0,797234304.0,794982016.0,795242432.0,794810112.0,795421504.0,793700544.0,794577472.0,794292416.0,794226688.0,792585024.0,795092352.0,793223872.0,793955648.0,792970432.0,791147008.0,792961344.0,791590400.0,794401984.0,795218944.0,792098944.0,792375680.0,792281920.0,791821312.0,791913472.0,792663296.0,790888064.0,790244736.0,790004928.0,791565120.0,788003008.0,788728960.0,789876608.0,787958912.0,787602496.0,787523584.0,788886976.0,786963072.0,787903552.0,787185216.0,787583680.0,786220608.0,787016512.0,786394048.0,786293632.0,786038912.0,787615104.0,787965056.0,785853696.0,786121984.0,786762240.0,785129280.0,789735808.0,786560320.0,786862464.0,785799360.0,786305280.0,787360128.0,787582976.0,786892416.0,786387072.0,785582080.0,785738176.0,786133248.0,785032256.0,785307776.0,786175680.0,783855040.0,783627712.0,783397184.0,784977600.0,781276608.0,783749760.0,783869248.0,783635968.0,782211200.0,781431424.0,783101056.0,781847744.0,782980160.0,780427968.0,784121600.0,782865856.0,781388288.0,782359232.0,782875648.0,781151104.0,779652608.0,783231616.0,784911104.0,781782336.0,782527168.0,782321600.0,780996800.0,780829824.0,781145664.0,780739520.0,780743360.0,780239552.0,780268480.0,780887040.0,779575360.0,780196096.0,778812480.0,779188800.0,779321728.0,779112576.0,779519808.0,778513728.0,779893888.0,778419712.0,778518720.0,779205376.0,780411968.0,777265472.0,775961216.0,776328704.0,777623424.0,778866048.0,777325760.0,776567680.0,777332800.0,776094656.0,777267200.0,775864448.0,778904384.0,776814016.0,776861696.0,777955712.0,776391936.0,777078592.0,776741632.0,775893312.0,775078464.0,774669376.0,774828544.0,775971392.0,776297088.0,774523456.0,776240000.0,775606720.0,776617472.0,777408704.0,775462848.0,776254528.0,776625600.0,776648576.0,776311168.0,775791104.0,775776512.0,775869056.0,774763392.0,775714304.0,775494784.0,775588224.0,775062720.0,775630016.0,774846400.0,773098304.0,774508160.0,773600704.0,774845760.0,772850304.0,774352640.0,774822592.0,772858880.0,773026496.0,773721920.0,772519680.0,773058560.0,774054080.0,773820032.0,772328256.0,774157824.0,773215040.0,773354816.0,771654144.0,772233792.0,771970176.0,772973312.0,772519616.0,771595712.0,770238208.0,772084992.0,770143744.0,769432064.0,770804864.0,770637696.0,770729472.0,770293120.0,769664576.0,770975424.0,769567744.0,769663488.0,769610752.0,769842176.0,769633216.0,769617344.0,770027584.0,769147776.0,770604416.0],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"height\":500,\"width\":700,\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3aa4eda6-b896-4362-8cb7-ac6cf5697474');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.25)"
      ],
      "metadata": {
        "id": "gX-3ScnxZVR7",
        "outputId": "78f6b449-85ad-4e66-e811-64bda22ef9c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 700518016.0000 - mae: 16253.1836 - val_loss: 754047680.0000 - val_mae: 19215.1738\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 700189184.0000 - mae: 16263.4951 - val_loss: 754947456.0000 - val_mae: 19235.9707\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 699735552.0000 - mae: 16255.5674 - val_loss: 754649152.0000 - val_mae: 19173.3359\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 699756928.0000 - mae: 16243.1162 - val_loss: 754635840.0000 - val_mae: 19157.1875\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 699655680.0000 - mae: 16265.5967 - val_loss: 754389056.0000 - val_mae: 19215.1406\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 699653120.0000 - mae: 16250.6406 - val_loss: 754748928.0000 - val_mae: 19203.4707\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 698773440.0000 - mae: 16238.6426 - val_loss: 754915264.0000 - val_mae: 19189.7051\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 698858048.0000 - mae: 16244.0400 - val_loss: 754302464.0000 - val_mae: 19252.9316\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 698163392.0000 - mae: 16247.1748 - val_loss: 754166400.0000 - val_mae: 19201.1914\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 697806784.0000 - mae: 16243.7510 - val_loss: 754413760.0000 - val_mae: 19210.3281\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 698236928.0000 - mae: 16230.0713 - val_loss: 754049280.0000 - val_mae: 19156.1035\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 697856192.0000 - mae: 16226.1963 - val_loss: 754274240.0000 - val_mae: 19256.2246\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 696668672.0000 - mae: 16231.2842 - val_loss: 753816320.0000 - val_mae: 19193.9648\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 697637760.0000 - mae: 16241.8945 - val_loss: 753892800.0000 - val_mae: 19250.9668\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 697666432.0000 - mae: 16256.6689 - val_loss: 753759680.0000 - val_mae: 19168.6445\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 696377408.0000 - mae: 16232.4346 - val_loss: 754799680.0000 - val_mae: 19215.7656\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 697163584.0000 - mae: 16234.9795 - val_loss: 754349376.0000 - val_mae: 19269.4844\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 695854336.0000 - mae: 16227.0391 - val_loss: 752878592.0000 - val_mae: 19218.1133\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 695860672.0000 - mae: 16224.6309 - val_loss: 753770176.0000 - val_mae: 19192.3613\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 695611008.0000 - mae: 16229.2109 - val_loss: 753332992.0000 - val_mae: 19216.5371\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 694921920.0000 - mae: 16224.7930 - val_loss: 754271744.0000 - val_mae: 19244.5840\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 694433344.0000 - mae: 16224.5918 - val_loss: 754268160.0000 - val_mae: 19222.1465\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 696281152.0000 - mae: 16208.2500 - val_loss: 754520320.0000 - val_mae: 19162.0723\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 693987840.0000 - mae: 16212.0029 - val_loss: 753945856.0000 - val_mae: 19224.2949\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 695091712.0000 - mae: 16209.5723 - val_loss: 754644288.0000 - val_mae: 19207.8613\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 694082560.0000 - mae: 16237.9248 - val_loss: 754955456.0000 - val_mae: 19330.4629\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 692730688.0000 - mae: 16223.1279 - val_loss: 753812992.0000 - val_mae: 19227.2734\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 693631168.0000 - mae: 16207.4336 - val_loss: 753939968.0000 - val_mae: 19174.6367\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 697361536.0000 - mae: 16284.3691 - val_loss: 754768576.0000 - val_mae: 19309.0176\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 692423808.0000 - mae: 16203.9346 - val_loss: 753519744.0000 - val_mae: 19219.4941\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 692528768.0000 - mae: 16201.2900 - val_loss: 753536256.0000 - val_mae: 19183.5840\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 693396928.0000 - mae: 16195.5674 - val_loss: 754553088.0000 - val_mae: 19170.7520\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 691694976.0000 - mae: 16193.9971 - val_loss: 754095552.0000 - val_mae: 19208.1895\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 693824640.0000 - mae: 16246.2490 - val_loss: 753722880.0000 - val_mae: 19295.2441\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 693462016.0000 - mae: 16199.2891 - val_loss: 755119104.0000 - val_mae: 19148.4805\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 690783488.0000 - mae: 16201.6748 - val_loss: 755001472.0000 - val_mae: 19200.0176\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 691682176.0000 - mae: 16218.9482 - val_loss: 756187008.0000 - val_mae: 19286.9668\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 690905664.0000 - mae: 16227.0352 - val_loss: 755316480.0000 - val_mae: 19259.2832\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 691247296.0000 - mae: 16198.8311 - val_loss: 755104192.0000 - val_mae: 19189.7578\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 690226624.0000 - mae: 16182.9717 - val_loss: 753839616.0000 - val_mae: 19238.6582\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 689867328.0000 - mae: 16196.2197 - val_loss: 754289792.0000 - val_mae: 19223.7812\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 689538048.0000 - mae: 16184.8525 - val_loss: 754669248.0000 - val_mae: 19219.3164\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 689989056.0000 - mae: 16203.3359 - val_loss: 755532672.0000 - val_mae: 19267.3496\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 689583360.0000 - mae: 16189.8398 - val_loss: 754928000.0000 - val_mae: 19209.4512\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 690759616.0000 - mae: 16214.0762 - val_loss: 754870080.0000 - val_mae: 19327.7500\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 688249088.0000 - mae: 16181.6006 - val_loss: 753693184.0000 - val_mae: 19197.0918\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 688721216.0000 - mae: 16181.1777 - val_loss: 755314816.0000 - val_mae: 19262.6445\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 688267904.0000 - mae: 16204.1572 - val_loss: 755271296.0000 - val_mae: 19302.7344\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 688129600.0000 - mae: 16196.0391 - val_loss: 754737856.0000 - val_mae: 19197.7246\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 687303808.0000 - mae: 16174.2100 - val_loss: 754549952.0000 - val_mae: 19254.4512\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 688748928.0000 - mae: 16178.3760 - val_loss: 754767104.0000 - val_mae: 19206.8926\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 686488640.0000 - mae: 16181.1406 - val_loss: 755514304.0000 - val_mae: 19321.9375\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 688445056.0000 - mae: 16224.3838 - val_loss: 754871616.0000 - val_mae: 19319.5742\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 686803200.0000 - mae: 16176.0195 - val_loss: 754070144.0000 - val_mae: 19221.1328\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 686113344.0000 - mae: 16164.9658 - val_loss: 754510016.0000 - val_mae: 19260.0801\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 686091712.0000 - mae: 16171.9092 - val_loss: 754863168.0000 - val_mae: 19271.7383\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 686922752.0000 - mae: 16191.8066 - val_loss: 754361984.0000 - val_mae: 19265.4062\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 686562752.0000 - mae: 16172.6299 - val_loss: 753587328.0000 - val_mae: 19251.9258\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 687429120.0000 - mae: 16179.8926 - val_loss: 754061120.0000 - val_mae: 19301.9004\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 684282496.0000 - mae: 16156.7402 - val_loss: 753982656.0000 - val_mae: 19210.9570\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 685559744.0000 - mae: 16148.5859 - val_loss: 754677952.0000 - val_mae: 19235.0527\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 684371968.0000 - mae: 16157.9268 - val_loss: 754972224.0000 - val_mae: 19263.9336\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 684817472.0000 - mae: 16150.8594 - val_loss: 754470208.0000 - val_mae: 19232.1699\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 684013696.0000 - mae: 16158.3379 - val_loss: 755299968.0000 - val_mae: 19270.7812\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 684948672.0000 - mae: 16173.0762 - val_loss: 754757760.0000 - val_mae: 19311.8281\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 683772800.0000 - mae: 16148.6504 - val_loss: 753340800.0000 - val_mae: 19255.9805\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 683626752.0000 - mae: 16145.5781 - val_loss: 754208448.0000 - val_mae: 19251.1211\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 683425472.0000 - mae: 16150.6504 - val_loss: 755192000.0000 - val_mae: 19254.8027\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 683179648.0000 - mae: 16157.0850 - val_loss: 754377792.0000 - val_mae: 19238.9219\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 682902080.0000 - mae: 16167.2451 - val_loss: 754937728.0000 - val_mae: 19299.5977\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 683764480.0000 - mae: 16151.9609 - val_loss: 754989696.0000 - val_mae: 19258.6641\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 682381312.0000 - mae: 16159.9053 - val_loss: 755629696.0000 - val_mae: 19348.7246\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 683942592.0000 - mae: 16157.5029 - val_loss: 754672064.0000 - val_mae: 19245.0039\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 682391296.0000 - mae: 16176.3076 - val_loss: 755449280.0000 - val_mae: 19334.3008\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 682908032.0000 - mae: 16161.8799 - val_loss: 753783104.0000 - val_mae: 19298.2422\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 681979584.0000 - mae: 16115.1426 - val_loss: 754693760.0000 - val_mae: 19230.7363\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 681180608.0000 - mae: 16139.6240 - val_loss: 754897344.0000 - val_mae: 19306.9414\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 681337536.0000 - mae: 16134.9668 - val_loss: 754874304.0000 - val_mae: 19238.8281\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 680592960.0000 - mae: 16129.1221 - val_loss: 755076992.0000 - val_mae: 19271.7051\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 680699008.0000 - mae: 16140.9707 - val_loss: 754543680.0000 - val_mae: 19282.4902\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 680613696.0000 - mae: 16154.0674 - val_loss: 754738112.0000 - val_mae: 19310.6230\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 679412864.0000 - mae: 16123.8115 - val_loss: 754489856.0000 - val_mae: 19257.1875\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 679968448.0000 - mae: 16129.5176 - val_loss: 754806464.0000 - val_mae: 19332.4473\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 679409536.0000 - mae: 16137.8623 - val_loss: 754848960.0000 - val_mae: 19291.1836\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 680302144.0000 - mae: 16115.3154 - val_loss: 753984704.0000 - val_mae: 19298.7285\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 678836672.0000 - mae: 16128.1191 - val_loss: 754922432.0000 - val_mae: 19278.4023\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 678680704.0000 - mae: 16116.5254 - val_loss: 754727424.0000 - val_mae: 19255.6484\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 678583296.0000 - mae: 16117.2422 - val_loss: 755086784.0000 - val_mae: 19263.3301\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 679093376.0000 - mae: 16114.9717 - val_loss: 755066304.0000 - val_mae: 19347.3535\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 678169920.0000 - mae: 16121.6123 - val_loss: 755805120.0000 - val_mae: 19318.7656\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 678133824.0000 - mae: 16114.3896 - val_loss: 754697344.0000 - val_mae: 19348.2617\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 677561024.0000 - mae: 16132.2354 - val_loss: 755709120.0000 - val_mae: 19346.9355\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 677848832.0000 - mae: 16114.0615 - val_loss: 754893696.0000 - val_mae: 19332.5703\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 677741696.0000 - mae: 16121.4922 - val_loss: 754989696.0000 - val_mae: 19332.7871\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 676704768.0000 - mae: 16099.5488 - val_loss: 755269888.0000 - val_mae: 19282.9863\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 676809728.0000 - mae: 16093.6299 - val_loss: 755584000.0000 - val_mae: 19282.7754\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 677264576.0000 - mae: 16113.2295 - val_loss: 755745728.0000 - val_mae: 19375.6797\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 676750976.0000 - mae: 16109.5674 - val_loss: 755072960.0000 - val_mae: 19290.2578\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 675731840.0000 - mae: 16089.9375 - val_loss: 754779136.0000 - val_mae: 19298.9531\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 676473664.0000 - mae: 16118.8369 - val_loss: 755220736.0000 - val_mae: 19371.4570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergl(y=history.history['loss'],\n",
        "                    name='Train'))\n",
        "fig.add_trace(go.Scattergl(y=history.history['val_loss'],\n",
        "                    name='Valid'))\n",
        "fig.update_layout(height=500, width=700,\n",
        "                  xaxis_title='Epoch',\n",
        "                  yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Kn1LXeIaZen_",
        "outputId": "0ec916aa-1c6b-408c-b051-d9806818b866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"878ec8b7-55d1-4530-9d98-c5d02ee8844b\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"878ec8b7-55d1-4530-9d98-c5d02ee8844b\")) {                    Plotly.newPlot(                        \"878ec8b7-55d1-4530-9d98-c5d02ee8844b\",                        [{\"name\":\"Train\",\"y\":[700518016.0,700189184.0,699735552.0,699756928.0,699655680.0,699653120.0,698773440.0,698858048.0,698163392.0,697806784.0,698236928.0,697856192.0,696668672.0,697637760.0,697666432.0,696377408.0,697163584.0,695854336.0,695860672.0,695611008.0,694921920.0,694433344.0,696281152.0,693987840.0,695091712.0,694082560.0,692730688.0,693631168.0,697361536.0,692423808.0,692528768.0,693396928.0,691694976.0,693824640.0,693462016.0,690783488.0,691682176.0,690905664.0,691247296.0,690226624.0,689867328.0,689538048.0,689989056.0,689583360.0,690759616.0,688249088.0,688721216.0,688267904.0,688129600.0,687303808.0,688748928.0,686488640.0,688445056.0,686803200.0,686113344.0,686091712.0,686922752.0,686562752.0,687429120.0,684282496.0,685559744.0,684371968.0,684817472.0,684013696.0,684948672.0,683772800.0,683626752.0,683425472.0,683179648.0,682902080.0,683764480.0,682381312.0,683942592.0,682391296.0,682908032.0,681979584.0,681180608.0,681337536.0,680592960.0,680699008.0,680613696.0,679412864.0,679968448.0,679409536.0,680302144.0,678836672.0,678680704.0,678583296.0,679093376.0,678169920.0,678133824.0,677561024.0,677848832.0,677741696.0,676704768.0,676809728.0,677264576.0,676750976.0,675731840.0,676473664.0],\"type\":\"scattergl\"},{\"name\":\"Valid\",\"y\":[754047680.0,754947456.0,754649152.0,754635840.0,754389056.0,754748928.0,754915264.0,754302464.0,754166400.0,754413760.0,754049280.0,754274240.0,753816320.0,753892800.0,753759680.0,754799680.0,754349376.0,752878592.0,753770176.0,753332992.0,754271744.0,754268160.0,754520320.0,753945856.0,754644288.0,754955456.0,753812992.0,753939968.0,754768576.0,753519744.0,753536256.0,754553088.0,754095552.0,753722880.0,755119104.0,755001472.0,756187008.0,755316480.0,755104192.0,753839616.0,754289792.0,754669248.0,755532672.0,754928000.0,754870080.0,753693184.0,755314816.0,755271296.0,754737856.0,754549952.0,754767104.0,755514304.0,754871616.0,754070144.0,754510016.0,754863168.0,754361984.0,753587328.0,754061120.0,753982656.0,754677952.0,754972224.0,754470208.0,755299968.0,754757760.0,753340800.0,754208448.0,755192000.0,754377792.0,754937728.0,754989696.0,755629696.0,754672064.0,755449280.0,753783104.0,754693760.0,754897344.0,754874304.0,755076992.0,754543680.0,754738112.0,754489856.0,754806464.0,754848960.0,753984704.0,754922432.0,754727424.0,755086784.0,755066304.0,755805120.0,754697344.0,755709120.0,754893696.0,754989696.0,755269888.0,755584000.0,755745728.0,755072960.0,754779136.0,755220736.0],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"height\":500,\"width\":700,\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('878ec8b7-55d1-4530-9d98-c5d02ee8844b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house_nn_test_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "T3PtVI0QaQ1e",
        "outputId": "8adaea40-ff41-4837-8650-c66b5603a83c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSwpyOQZ3i0C",
        "outputId": "89ad43b8-527e-4bd5-917f-00090b685272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, house_nn_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-house_nn_test_pred)/house_nn_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, house_nn_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, house_nn_test_pred))))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 (explained variance): 0.87\n",
            "Mean Absolute Perc Error (Σ(|y-pred|/y)/n): 0.51\n",
            "Mean Absolute Error (Σ|y-pred|/n): 18,665\n",
            "Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)): 25,633\n"
          ]
        }
      ]
    }
  ]
}