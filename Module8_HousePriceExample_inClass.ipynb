{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/ML_656/blob/main/Module8_HousePriceExample_inClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vCC-SQb7VRR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "import pydot\n",
        "from io import StringIO\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "import shap"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRIewfHHQt-u"
      },
      "source": [
        "# HOUSE PRICE EXAMPLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oczDAE4wjt4"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joqrQm2gSDdZ"
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/ML_656.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jILOaSki7VRX",
        "outputId": "e3da8d5f-3e07-4811-f36b-d7dbda89d5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "house = pd.read_csv('ML_656/HouseData.csv')\n",
        "house.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c232e7f-b94e-4207-a572-e737ad7070eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c232e7f-b94e-4207-a572-e737ad7070eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c232e7f-b94e-4207-a572-e737ad7070eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c232e7f-b94e-4207-a572-e737ad7070eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c4aa8de-8bfa-4518-ba97-a81a2f313e7c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c4aa8de-8bfa-4518-ba97-a81a2f313e7c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c4aa8de-8bfa-4518-ba97-a81a2f313e7c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWBCjNh2woDd"
      },
      "source": [
        "## Prep Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abomVqWFlxVo",
        "outputId": "da9fb994-663d-4368-cbac-0a248c1d8891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None)\n",
        "house.isnull().sum(axis = 0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                  0\n",
              "MSSubClass          0\n",
              "MSZoning            0\n",
              "LotFrontage       259\n",
              "LotArea             0\n",
              "Street              0\n",
              "Alley            1369\n",
              "LotShape            0\n",
              "LandContour         0\n",
              "Utilities           0\n",
              "LotConfig           0\n",
              "LandSlope           0\n",
              "Neighborhood        0\n",
              "Condition1          0\n",
              "Condition2          0\n",
              "BldgType            0\n",
              "HouseStyle          0\n",
              "OverallQual         0\n",
              "OverallCond         0\n",
              "YearBuilt           0\n",
              "YearRemodAdd        0\n",
              "RoofStyle           0\n",
              "RoofMatl            0\n",
              "Exterior1st         0\n",
              "Exterior2nd         0\n",
              "MasVnrType          8\n",
              "MasVnrArea          8\n",
              "ExterQual           0\n",
              "ExterCond           0\n",
              "Foundation          0\n",
              "BsmtQual           37\n",
              "BsmtCond           37\n",
              "BsmtExposure       38\n",
              "BsmtFinType1       37\n",
              "BsmtFinSF1          0\n",
              "BsmtFinType2       38\n",
              "BsmtFinSF2          0\n",
              "BsmtUnfSF           0\n",
              "TotalBsmtSF         0\n",
              "Heating             0\n",
              "HeatingQC           0\n",
              "CentralAir          0\n",
              "Electrical          1\n",
              "1stFlrSF            0\n",
              "2ndFlrSF            0\n",
              "LowQualFinSF        0\n",
              "GrLivArea           0\n",
              "BsmtFullBath        0\n",
              "BsmtHalfBath        0\n",
              "FullBath            0\n",
              "HalfBath            0\n",
              "BedroomAbvGr        0\n",
              "KitchenAbvGr        0\n",
              "KitchenQual         0\n",
              "TotRmsAbvGrd        0\n",
              "Functional          0\n",
              "Fireplaces          0\n",
              "FireplaceQu       690\n",
              "GarageType         81\n",
              "GarageYrBlt        81\n",
              "GarageFinish       81\n",
              "GarageCars          0\n",
              "GarageArea          0\n",
              "GarageQual         81\n",
              "GarageCond         81\n",
              "PavedDrive          0\n",
              "WoodDeckSF          0\n",
              "OpenPorchSF         0\n",
              "EnclosedPorch       0\n",
              "3SsnPorch           0\n",
              "ScreenPorch         0\n",
              "PoolArea            0\n",
              "PoolQC           1453\n",
              "Fence            1179\n",
              "MiscFeature      1406\n",
              "MiscVal             0\n",
              "MoSold              0\n",
              "YrSold              0\n",
              "SaleType            0\n",
              "SaleCondition       0\n",
              "SalePrice           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house.describe()"
      ],
      "metadata": {
        "id": "Dg7pbMsbyJoy",
        "outputId": "8e6c8558-4bc2-40bc-cfd1-bb834e1ac71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
              "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
              "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
              "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
              "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
              "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
              "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
              "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
              "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
              "\n",
              "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
              "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
              "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
              "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
              "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
              "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
              "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
              "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
              "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
              "\n",
              "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
              "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
              "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
              "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
              "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
              "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
              "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
              "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
              "\n",
              "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
              "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
              "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
              "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
              "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
              "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
              "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
              "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
              "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
              "\n",
              "[8 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48f1bc58-f1b8-44d6-b1e7-ceb152671488\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>...</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>...</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48f1bc58-f1b8-44d6-b1e7-ceb152671488')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48f1bc58-f1b8-44d6-b1e7-ceb152671488 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48f1bc58-f1b8-44d6-b1e7-ceb152671488');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-de16b22d-b721-4158-a57c-0ce297dd1ce6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de16b22d-b721-4158-a57c-0ce297dd1ce6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-de16b22d-b721-4158-a57c-0ce297dd1ce6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuUNldN6nzFE"
      },
      "source": [
        "house = house.drop(columns=['Id','LotFrontage','Alley', 'BsmtQual', 'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6FzvzLRrYmx",
        "outputId": "62814ee9-b3a8-49dd-873d-1bb5fab3fb24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "house = house.dropna()\n",
        "house.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1451 entries, 0 to 1459\n",
            "Data columns (total 64 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   MSSubClass     1451 non-null   int64  \n",
            " 1   MSZoning       1451 non-null   object \n",
            " 2   LotArea        1451 non-null   int64  \n",
            " 3   Street         1451 non-null   object \n",
            " 4   LotShape       1451 non-null   object \n",
            " 5   LandContour    1451 non-null   object \n",
            " 6   Utilities      1451 non-null   object \n",
            " 7   LotConfig      1451 non-null   object \n",
            " 8   LandSlope      1451 non-null   object \n",
            " 9   Neighborhood   1451 non-null   object \n",
            " 10  Condition1     1451 non-null   object \n",
            " 11  Condition2     1451 non-null   object \n",
            " 12  BldgType       1451 non-null   object \n",
            " 13  HouseStyle     1451 non-null   object \n",
            " 14  OverallQual    1451 non-null   int64  \n",
            " 15  OverallCond    1451 non-null   int64  \n",
            " 16  YearBuilt      1451 non-null   int64  \n",
            " 17  YearRemodAdd   1451 non-null   int64  \n",
            " 18  RoofStyle      1451 non-null   object \n",
            " 19  RoofMatl       1451 non-null   object \n",
            " 20  Exterior1st    1451 non-null   object \n",
            " 21  Exterior2nd    1451 non-null   object \n",
            " 22  MasVnrType     1451 non-null   object \n",
            " 23  MasVnrArea     1451 non-null   float64\n",
            " 24  ExterQual      1451 non-null   object \n",
            " 25  ExterCond      1451 non-null   object \n",
            " 26  Foundation     1451 non-null   object \n",
            " 27  BsmtFinSF1     1451 non-null   int64  \n",
            " 28  BsmtFinSF2     1451 non-null   int64  \n",
            " 29  BsmtUnfSF      1451 non-null   int64  \n",
            " 30  TotalBsmtSF    1451 non-null   int64  \n",
            " 31  Heating        1451 non-null   object \n",
            " 32  HeatingQC      1451 non-null   object \n",
            " 33  CentralAir     1451 non-null   object \n",
            " 34  Electrical     1451 non-null   object \n",
            " 35  1stFlrSF       1451 non-null   int64  \n",
            " 36  2ndFlrSF       1451 non-null   int64  \n",
            " 37  LowQualFinSF   1451 non-null   int64  \n",
            " 38  GrLivArea      1451 non-null   int64  \n",
            " 39  BsmtFullBath   1451 non-null   int64  \n",
            " 40  BsmtHalfBath   1451 non-null   int64  \n",
            " 41  FullBath       1451 non-null   int64  \n",
            " 42  HalfBath       1451 non-null   int64  \n",
            " 43  BedroomAbvGr   1451 non-null   int64  \n",
            " 44  KitchenAbvGr   1451 non-null   int64  \n",
            " 45  KitchenQual    1451 non-null   object \n",
            " 46  TotRmsAbvGrd   1451 non-null   int64  \n",
            " 47  Functional     1451 non-null   object \n",
            " 48  Fireplaces     1451 non-null   int64  \n",
            " 49  GarageCars     1451 non-null   int64  \n",
            " 50  GarageArea     1451 non-null   int64  \n",
            " 51  PavedDrive     1451 non-null   object \n",
            " 52  WoodDeckSF     1451 non-null   int64  \n",
            " 53  OpenPorchSF    1451 non-null   int64  \n",
            " 54  EnclosedPorch  1451 non-null   int64  \n",
            " 55  3SsnPorch      1451 non-null   int64  \n",
            " 56  ScreenPorch    1451 non-null   int64  \n",
            " 57  PoolArea       1451 non-null   int64  \n",
            " 58  MiscVal        1451 non-null   int64  \n",
            " 59  MoSold         1451 non-null   int64  \n",
            " 60  YrSold         1451 non-null   int64  \n",
            " 61  SaleType       1451 non-null   object \n",
            " 62  SaleCondition  1451 non-null   object \n",
            " 63  SalePrice      1451 non-null   int64  \n",
            "dtypes: float64(1), int64(34), object(29)\n",
            "memory usage: 736.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ77WRKus_Xc"
      },
      "source": [
        "col_types = house.columns.to_series().groupby(house.dtypes).groups\n",
        "numerics = list(house.select_dtypes(include=['int64']).columns)\n",
        "factors = list(house.select_dtypes(include=['object']).columns)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSHiS4cbrBDD",
        "outputId": "11493296-907c-4265-872e-b693f945a5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "house_numcols = house[numerics].drop(columns = ['SalePrice'])\n",
        "house_faccols = house[factors]\n",
        "dummies = pd.get_dummies(house_faccols, drop_first=True)\n",
        "house_numcols_sc_0 = scale(house_numcols)\n",
        "house_numcols_sc = pd.DataFrame(data=house_numcols_sc_0, columns = house_numcols.columns, index = dummies.index)\n",
        "house_sc = pd.concat([house_numcols_sc, dummies], axis = 1)\n",
        "house_sc = pd.concat([house_sc, house['SalePrice']], axis =1)\n",
        "house_sc = house_sc.rename(columns={\"SalePrice\":\"Y\"})\n",
        "house_sc.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MSSubClass   LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
              "0    0.072441 -0.205996     0.656247    -0.520740   1.057250      0.883532   \n",
              "1   -0.872386 -0.090876    -0.067870     2.174601   0.162613     -0.424340   \n",
              "2    0.072441  0.074297     0.656247    -0.520740   0.990980      0.835093   \n",
              "3    0.308648 -0.095881     0.656247    -0.520740  -1.858602     -0.714978   \n",
              "4    0.072441  0.375612     1.380365    -0.520740   0.957846      0.738213   \n",
              "\n",
              "   BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  ...  SaleType_ConLw  \\\n",
              "0    0.579345   -0.289621  -0.943764    -0.457576  ...               0   \n",
              "1    1.176868   -0.289621  -0.640635     0.469865  ...               0   \n",
              "2    0.096054   -0.289621  -0.301312    -0.311378  ...               0   \n",
              "3   -0.497076   -0.289621  -0.061524    -0.686010  ...               0   \n",
              "4    0.467309   -0.289621  -0.174632     0.202598  ...               0   \n",
              "\n",
              "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  \\\n",
              "0             0             0            1                      0   \n",
              "1             0             0            1                      0   \n",
              "2             0             0            1                      0   \n",
              "3             0             0            1                      0   \n",
              "4             0             0            1                      0   \n",
              "\n",
              "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
              "0                     0                     0                     1   \n",
              "1                     0                     0                     1   \n",
              "2                     0                     0                     1   \n",
              "3                     0                     0                     0   \n",
              "4                     0                     0                     1   \n",
              "\n",
              "   SaleCondition_Partial       Y  \n",
              "0                      0  208500  \n",
              "1                      0  181500  \n",
              "2                      0  223500  \n",
              "3                      0  140000  \n",
              "4                      0  250000  \n",
              "\n",
              "[5 rows x 196 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c49f7ad-25b5-4587-866a-d08fb5a5c24d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.072441</td>\n",
              "      <td>-0.205996</td>\n",
              "      <td>0.656247</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>1.057250</td>\n",
              "      <td>0.883532</td>\n",
              "      <td>0.579345</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.943764</td>\n",
              "      <td>-0.457576</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.872386</td>\n",
              "      <td>-0.090876</td>\n",
              "      <td>-0.067870</td>\n",
              "      <td>2.174601</td>\n",
              "      <td>0.162613</td>\n",
              "      <td>-0.424340</td>\n",
              "      <td>1.176868</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.640635</td>\n",
              "      <td>0.469865</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.072441</td>\n",
              "      <td>0.074297</td>\n",
              "      <td>0.656247</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>0.990980</td>\n",
              "      <td>0.835093</td>\n",
              "      <td>0.096054</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.301312</td>\n",
              "      <td>-0.311378</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.308648</td>\n",
              "      <td>-0.095881</td>\n",
              "      <td>0.656247</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>-1.858602</td>\n",
              "      <td>-0.714978</td>\n",
              "      <td>-0.497076</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.061524</td>\n",
              "      <td>-0.686010</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.072441</td>\n",
              "      <td>0.375612</td>\n",
              "      <td>1.380365</td>\n",
              "      <td>-0.520740</td>\n",
              "      <td>0.957846</td>\n",
              "      <td>0.738213</td>\n",
              "      <td>0.467309</td>\n",
              "      <td>-0.289621</td>\n",
              "      <td>-0.174632</td>\n",
              "      <td>0.202598</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 196 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c49f7ad-25b5-4587-866a-d08fb5a5c24d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c49f7ad-25b5-4587-866a-d08fb5a5c24d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c49f7ad-25b5-4587-866a-d08fb5a5c24d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36e617e3-2049-4673-8d4e-96348eb04377\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36e617e3-2049-4673-8d4e-96348eb04377')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36e617e3-2049-4673-8d4e-96348eb04377 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALiq7uTFwvZ7"
      },
      "source": [
        "## Explore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahz5pTT-xodx",
        "outputId": "0f759d58-2cac-4b28-f0df-0bde0970b873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        }
      },
      "source": [
        "#From https://towardsdatascience.com/machine-learning-with-python-regression-complete-tutorial-47268e546cea\n",
        "x = \"Y\"\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2,  sharex=False, sharey=False)\n",
        "fig.suptitle(x, fontsize=20)\n",
        "### distribution\n",
        "ax[0].title.set_text('distribution')\n",
        "variable = house_sc[x].fillna(house_sc[x].mean())\n",
        "breaks = np.quantile(variable, q=np.linspace(0, 1, 11))\n",
        "variable = variable[ (variable > breaks[0]) & (variable <\n",
        "                    breaks[10]) ]\n",
        "sns.distplot(variable, hist=True, kde=True, kde_kws={\"shade\": True}, ax=ax[0])\n",
        "des = house_sc[x].describe()\n",
        "ax[0].axvline(des[\"25%\"], ls='--')\n",
        "ax[0].axvline(des[\"mean\"], ls='--')\n",
        "ax[0].axvline(des[\"75%\"], ls='--')\n",
        "ax[0].grid(True)\n",
        "des = round(des, 2).apply(lambda x: str(x))\n",
        "box = '\\n'.join((\"min: \"+des[\"min\"], \"25%: \"+des[\"25%\"], \"mean: \"+des[\"mean\"], \"75%: \"+des[\"75%\"], \"max: \"+des[\"max\"]))\n",
        "ax[0].text(0.95, 0.95, box, transform=ax[0].transAxes, fontsize=10, va='top', ha=\"right\", bbox=dict(boxstyle='round', facecolor='white', alpha=1))\n",
        "### boxplot\n",
        "ax[1].title.set_text('outliers (log scale)')\n",
        "tmp_dtf = pd.DataFrame(house_sc[x])\n",
        "tmp_dtf[x] = np.log(tmp_dtf[x])\n",
        "tmp_dtf.boxplot(column=x, ax=ax[1])\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "\n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55xSsRHJLUuu",
        "outputId": "4159f012-e0fe-45a9-9e82-4530e39822a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.random.seed(42)\n",
        "train, test = train_test_split(house_sc, test_size = 0.25)\n",
        "X_train = train.drop(columns = ['Y']).values\n",
        "y_train = train['Y'].values\n",
        "X_test = test.drop(columns = ['Y']).values\n",
        "y_test = test['Y'].values\n",
        "X_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1088, 195)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "3J1jPEOq2wsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house_rf = RandomForestRegressor(random_state=1)\n",
        "house_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "uYSatFjo2v2E",
        "outputId": "f00a1e53-fc61-4719-bf5d-38a77474e2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house_rf_test_pred = house_rf.predict(X_test)"
      ],
      "metadata": {
        "id": "TM6yaPNi3Xj7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, house_rf_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-house_rf_test_pred)/house_rf_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, house_rf_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, house_rf_test_pred))))"
      ],
      "metadata": {
        "id": "3VqeIG8O3bZW",
        "outputId": "260767ff-9a6a-4d01-9579-1f23b44e7dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 (explained variance): 0.9\n",
            "Mean Absolute Perc Error (Σ(|y-pred|/y)/n): 0.09\n",
            "Mean Absolute Error (Σ|y-pred|/n): 15,485\n",
            "Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)): 22,399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "5TNaAgjLRAf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(50, input_shape=(195, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(25, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "#https://keras.io/api/models/model_training_apis/\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "n8aW_lMbQ_s5",
        "outputId": "6ced9efd-94ff-415e-8ae8-eee64a4a0111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 50)                9800      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11101 (43.36 KB)\n",
            "Trainable params: 11101 (43.36 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.25)"
      ],
      "metadata": {
        "id": "id3GR3gNT6t8",
        "outputId": "4632cb43-b30e-4b1c-e941-e4924f59e2e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "26/26 [==============================] - 1s 11ms/step - loss: 39685058560.0000 - mae: 181681.3281 - val_loss: 39713689600.0000 - val_mae: 182001.5156\n",
            "Epoch 2/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 39681732608.0000 - mae: 181673.0000 - val_loss: 39707979776.0000 - val_mae: 181987.3750\n",
            "Epoch 3/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 39672213504.0000 - mae: 181649.4688 - val_loss: 39693369344.0000 - val_mae: 181951.4844\n",
            "Epoch 4/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 39651520512.0000 - mae: 181597.7500 - val_loss: 39664386048.0000 - val_mae: 181880.1719\n",
            "Epoch 5/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 39613923328.0000 - mae: 181503.1250 - val_loss: 39615225856.0000 - val_mae: 181758.8281\n",
            "Epoch 6/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 39551729664.0000 - mae: 181349.6250 - val_loss: 39538978816.0000 - val_mae: 181569.9062\n",
            "Epoch 7/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 39459250176.0000 - mae: 181117.6719 - val_loss: 39427059712.0000 - val_mae: 181293.8906\n",
            "Epoch 8/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 39328985088.0000 - mae: 180792.8750 - val_loss: 39274987520.0000 - val_mae: 180918.6094\n",
            "Epoch 9/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 39155503104.0000 - mae: 180359.8438 - val_loss: 39076270080.0000 - val_mae: 180427.2812\n",
            "Epoch 10/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 38930198528.0000 - mae: 179798.0469 - val_loss: 38822633472.0000 - val_mae: 179798.0625\n",
            "Epoch 11/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 38644809728.0000 - mae: 179084.9062 - val_loss: 38506393600.0000 - val_mae: 179012.5312\n",
            "Epoch 12/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 38295056384.0000 - mae: 178208.3750 - val_loss: 38120742912.0000 - val_mae: 178050.6094\n",
            "Epoch 13/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 37874466816.0000 - mae: 177149.3125 - val_loss: 37664534528.0000 - val_mae: 176905.4062\n",
            "Epoch 14/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 37385089024.0000 - mae: 175889.6094 - val_loss: 37127028736.0000 - val_mae: 175548.9062\n",
            "Epoch 15/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 36811100160.0000 - mae: 174438.6719 - val_loss: 36525211648.0000 - val_mae: 174010.1875\n",
            "Epoch 16/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 36167720960.0000 - mae: 172757.2500 - val_loss: 35836977152.0000 - val_mae: 172237.6875\n",
            "Epoch 17/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 35441287168.0000 - mae: 170865.7188 - val_loss: 35069140992.0000 - val_mae: 170238.0000\n",
            "Epoch 18/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 34636738560.0000 - mae: 168726.2812 - val_loss: 34221361152.0000 - val_mae: 168001.9688\n",
            "Epoch 19/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 33740261376.0000 - mae: 166349.6250 - val_loss: 33297141760.0000 - val_mae: 165527.0781\n",
            "Epoch 20/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 32770197504.0000 - mae: 163707.1719 - val_loss: 32287830016.0000 - val_mae: 162787.2344\n",
            "Epoch 21/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 31729709056.0000 - mae: 160797.0938 - val_loss: 31191465984.0000 - val_mae: 159763.8750\n",
            "Epoch 22/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 30602199040.0000 - mae: 157646.0938 - val_loss: 30045356032.0000 - val_mae: 156534.6562\n",
            "Epoch 23/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 29413847040.0000 - mae: 154258.2188 - val_loss: 28843257856.0000 - val_mae: 153073.9375\n",
            "Epoch 24/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 28172412928.0000 - mae: 150591.3125 - val_loss: 27550148608.0000 - val_mae: 149281.3750\n",
            "Epoch 25/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 26861262848.0000 - mae: 146656.3438 - val_loss: 26224175104.0000 - val_mae: 145281.3750\n",
            "Epoch 26/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 25522769920.0000 - mae: 142491.0781 - val_loss: 24836765696.0000 - val_mae: 140993.2031\n",
            "Epoch 27/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 24140306432.0000 - mae: 138059.3750 - val_loss: 23451764736.0000 - val_mae: 136558.0000\n",
            "Epoch 28/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 22733977600.0000 - mae: 133447.7031 - val_loss: 22025256960.0000 - val_mae: 131856.2812\n",
            "Epoch 29/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 21308973056.0000 - mae: 128601.5000 - val_loss: 20593268736.0000 - val_mae: 126962.0312\n",
            "Epoch 30/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 19880419328.0000 - mae: 123567.4375 - val_loss: 19168563200.0000 - val_mae: 121899.5391\n",
            "Epoch 31/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 18464251904.0000 - mae: 118357.2734 - val_loss: 17753774080.0000 - val_mae: 116664.2734\n",
            "Epoch 32/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 17055075328.0000 - mae: 113016.5703 - val_loss: 16343020544.0000 - val_mae: 111226.3516\n",
            "Epoch 33/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 15683969024.0000 - mae: 107505.3984 - val_loss: 14977058816.0000 - val_mae: 105699.1250\n",
            "Epoch 34/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 14346945536.0000 - mae: 101917.5781 - val_loss: 13675037696.0000 - val_mae: 100134.4062\n",
            "Epoch 35/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 13079038976.0000 - mae: 96263.2422 - val_loss: 12404798464.0000 - val_mae: 94432.1094\n",
            "Epoch 36/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 11855013888.0000 - mae: 90567.5625 - val_loss: 11209111552.0000 - val_mae: 88739.9375\n",
            "Epoch 37/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 10692134912.0000 - mae: 84915.8438 - val_loss: 10095564800.0000 - val_mae: 83090.0781\n",
            "Epoch 38/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 9613779968.0000 - mae: 79250.2188 - val_loss: 9026323456.0000 - val_mae: 77398.0781\n",
            "Epoch 39/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 8611247104.0000 - mae: 73596.5547 - val_loss: 8039577600.0000 - val_mae: 71796.1250\n",
            "Epoch 40/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 7704344064.0000 - mae: 68044.2266 - val_loss: 7134054912.0000 - val_mae: 66349.3828\n",
            "Epoch 41/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 6863136256.0000 - mae: 62819.5781 - val_loss: 6357978112.0000 - val_mae: 61367.0859\n",
            "Epoch 42/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6130608128.0000 - mae: 57819.2656 - val_loss: 5640355840.0000 - val_mae: 56446.2773\n",
            "Epoch 43/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 5473202176.0000 - mae: 53079.3633 - val_loss: 5005343232.0000 - val_mae: 51781.3672\n",
            "Epoch 44/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4902282752.0000 - mae: 48598.8984 - val_loss: 4440055808.0000 - val_mae: 47300.7500\n",
            "Epoch 45/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4395658752.0000 - mae: 44551.2852 - val_loss: 3965748480.0000 - val_mae: 43272.2305\n",
            "Epoch 46/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3965850624.0000 - mae: 40928.8750 - val_loss: 3554913024.0000 - val_mae: 39558.9961\n",
            "Epoch 47/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 3613607168.0000 - mae: 37638.8867 - val_loss: 3180669184.0000 - val_mae: 36186.7070\n",
            "Epoch 48/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3295740928.0000 - mae: 34913.5703 - val_loss: 2899933440.0000 - val_mae: 33640.2695\n",
            "Epoch 49/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 3047649280.0000 - mae: 32756.1699 - val_loss: 2662587136.0000 - val_mae: 31609.6543\n",
            "Epoch 50/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2846365440.0000 - mae: 31000.5762 - val_loss: 2456724992.0000 - val_mae: 29954.1445\n",
            "Epoch 51/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2683763200.0000 - mae: 29820.6094 - val_loss: 2285106944.0000 - val_mae: 28628.4785\n",
            "Epoch 52/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2546123776.0000 - mae: 28880.0781 - val_loss: 2158413056.0000 - val_mae: 27674.6875\n",
            "Epoch 53/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2440450560.0000 - mae: 28262.0938 - val_loss: 2056321152.0000 - val_mae: 27025.7246\n",
            "Epoch 54/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2362082304.0000 - mae: 27876.2812 - val_loss: 1966965248.0000 - val_mae: 26582.9238\n",
            "Epoch 55/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2289885440.0000 - mae: 27577.5859 - val_loss: 1901318528.0000 - val_mae: 26280.4746\n",
            "Epoch 56/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2237263360.0000 - mae: 27440.6719 - val_loss: 1846351360.0000 - val_mae: 26116.7246\n",
            "Epoch 57/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2194477312.0000 - mae: 27329.0020 - val_loss: 1794193920.0000 - val_mae: 26020.5781\n",
            "Epoch 58/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2156861952.0000 - mae: 27255.8105 - val_loss: 1754715008.0000 - val_mae: 26002.2500\n",
            "Epoch 59/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2127857024.0000 - mae: 27201.2188 - val_loss: 1723919872.0000 - val_mae: 26010.3477\n",
            "Epoch 60/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2102905344.0000 - mae: 27155.0391 - val_loss: 1696911232.0000 - val_mae: 26038.4062\n",
            "Epoch 61/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2083392512.0000 - mae: 27165.3926 - val_loss: 1665114880.0000 - val_mae: 26097.8750\n",
            "Epoch 62/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2063045376.0000 - mae: 27096.2383 - val_loss: 1646928384.0000 - val_mae: 26078.2676\n",
            "Epoch 63/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2048369664.0000 - mae: 27105.0273 - val_loss: 1626026880.0000 - val_mae: 26115.4219\n",
            "Epoch 64/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 2031343872.0000 - mae: 27036.0488 - val_loss: 1611672960.0000 - val_mae: 26080.3594\n",
            "Epoch 65/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2018280704.0000 - mae: 26992.1055 - val_loss: 1596500352.0000 - val_mae: 26089.5859\n",
            "Epoch 66/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2004858368.0000 - mae: 26940.2695 - val_loss: 1583296768.0000 - val_mae: 26072.9062\n",
            "Epoch 67/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1992425344.0000 - mae: 26867.0312 - val_loss: 1570607744.0000 - val_mae: 26052.9922\n",
            "Epoch 68/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1981538816.0000 - mae: 26831.9160 - val_loss: 1555982592.0000 - val_mae: 26051.0293\n",
            "Epoch 69/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1970271104.0000 - mae: 26746.7793 - val_loss: 1544447232.0000 - val_mae: 25999.0312\n",
            "Epoch 70/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1958798336.0000 - mae: 26670.0000 - val_loss: 1535268864.0000 - val_mae: 25964.6875\n",
            "Epoch 71/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1949184128.0000 - mae: 26618.4609 - val_loss: 1522877568.0000 - val_mae: 25949.1074\n",
            "Epoch 72/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1938722304.0000 - mae: 26569.2520 - val_loss: 1512141056.0000 - val_mae: 25924.8496\n",
            "Epoch 73/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1928284032.0000 - mae: 26482.9219 - val_loss: 1504659328.0000 - val_mae: 25870.0684\n",
            "Epoch 74/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1919236736.0000 - mae: 26369.0840 - val_loss: 1496589824.0000 - val_mae: 25770.6035\n",
            "Epoch 75/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1910554240.0000 - mae: 26277.4727 - val_loss: 1488067584.0000 - val_mae: 25754.5098\n",
            "Epoch 76/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1901668096.0000 - mae: 26246.1855 - val_loss: 1478326144.0000 - val_mae: 25726.5957\n",
            "Epoch 77/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1891511296.0000 - mae: 26147.7129 - val_loss: 1470703232.0000 - val_mae: 25671.1855\n",
            "Epoch 78/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1882788736.0000 - mae: 26078.7988 - val_loss: 1462300288.0000 - val_mae: 25624.9004\n",
            "Epoch 79/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1874739968.0000 - mae: 26019.8496 - val_loss: 1453296128.0000 - val_mae: 25619.2480\n",
            "Epoch 80/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1866724480.0000 - mae: 25947.8672 - val_loss: 1446463104.0000 - val_mae: 25552.7148\n",
            "Epoch 81/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1859343232.0000 - mae: 25895.7344 - val_loss: 1438109312.0000 - val_mae: 25536.1855\n",
            "Epoch 82/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1852448128.0000 - mae: 25849.7188 - val_loss: 1429523200.0000 - val_mae: 25538.0684\n",
            "Epoch 83/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1843680896.0000 - mae: 25768.8750 - val_loss: 1424489344.0000 - val_mae: 25457.0234\n",
            "Epoch 84/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1836247040.0000 - mae: 25646.4043 - val_loss: 1420770176.0000 - val_mae: 25367.5371\n",
            "Epoch 85/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1829621632.0000 - mae: 25588.6562 - val_loss: 1412896896.0000 - val_mae: 25343.4062\n",
            "Epoch 86/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1822966400.0000 - mae: 25485.7695 - val_loss: 1410601344.0000 - val_mae: 25262.2441\n",
            "Epoch 87/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1814814720.0000 - mae: 25405.9395 - val_loss: 1403857920.0000 - val_mae: 25243.3594\n",
            "Epoch 88/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1808192512.0000 - mae: 25335.9551 - val_loss: 1398227456.0000 - val_mae: 25196.8281\n",
            "Epoch 89/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1802131072.0000 - mae: 25264.1836 - val_loss: 1393273600.0000 - val_mae: 25168.0371\n",
            "Epoch 90/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1796900736.0000 - mae: 25276.7188 - val_loss: 1383826816.0000 - val_mae: 25193.0938\n",
            "Epoch 91/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1788724864.0000 - mae: 25168.7344 - val_loss: 1380618368.0000 - val_mae: 25101.0703\n",
            "Epoch 92/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1782622720.0000 - mae: 25104.1914 - val_loss: 1375764992.0000 - val_mae: 25053.9219\n",
            "Epoch 93/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1775546112.0000 - mae: 25028.6719 - val_loss: 1371143936.0000 - val_mae: 25033.1094\n",
            "Epoch 94/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1770726016.0000 - mae: 24936.1035 - val_loss: 1366372352.0000 - val_mae: 24975.6992\n",
            "Epoch 95/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1764312448.0000 - mae: 24906.8262 - val_loss: 1361343360.0000 - val_mae: 24966.1055\n",
            "Epoch 96/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1757966208.0000 - mae: 24861.2988 - val_loss: 1355085696.0000 - val_mae: 24963.4043\n",
            "Epoch 97/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1753773824.0000 - mae: 24814.4531 - val_loss: 1348749824.0000 - val_mae: 24945.0020\n",
            "Epoch 98/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1746891264.0000 - mae: 24661.1699 - val_loss: 1350268672.0000 - val_mae: 24808.1934\n",
            "Epoch 99/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1740382720.0000 - mae: 24564.1797 - val_loss: 1346354304.0000 - val_mae: 24767.8906\n",
            "Epoch 100/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1735142016.0000 - mae: 24548.6699 - val_loss: 1339764480.0000 - val_mae: 24780.5684\n",
            "Epoch 101/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1730427008.0000 - mae: 24519.7598 - val_loss: 1334527232.0000 - val_mae: 24770.1621\n",
            "Epoch 102/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1723205376.0000 - mae: 24457.7891 - val_loss: 1328822016.0000 - val_mae: 24754.3887\n",
            "Epoch 103/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1716750336.0000 - mae: 24383.7344 - val_loss: 1326852992.0000 - val_mae: 24684.6680\n",
            "Epoch 104/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1711894016.0000 - mae: 24297.9980 - val_loss: 1324020992.0000 - val_mae: 24652.8750\n",
            "Epoch 105/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1707380224.0000 - mae: 24235.2285 - val_loss: 1320859648.0000 - val_mae: 24598.3555\n",
            "Epoch 106/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1701351936.0000 - mae: 24160.9531 - val_loss: 1316517888.0000 - val_mae: 24571.7559\n",
            "Epoch 107/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1697201024.0000 - mae: 24193.2949 - val_loss: 1309674368.0000 - val_mae: 24629.4219\n",
            "Epoch 108/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1691425024.0000 - mae: 24099.1074 - val_loss: 1308515584.0000 - val_mae: 24522.2207\n",
            "Epoch 109/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1686385152.0000 - mae: 24014.5508 - val_loss: 1304698240.0000 - val_mae: 24497.9199\n",
            "Epoch 110/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1682097920.0000 - mae: 24016.5410 - val_loss: 1297937408.0000 - val_mae: 24531.8262\n",
            "Epoch 111/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1675647360.0000 - mae: 23939.1465 - val_loss: 1296466944.0000 - val_mae: 24447.5215\n",
            "Epoch 112/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1671362816.0000 - mae: 23871.5312 - val_loss: 1293410688.0000 - val_mae: 24424.1895\n",
            "Epoch 113/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1667617152.0000 - mae: 23849.2090 - val_loss: 1289170944.0000 - val_mae: 24408.9570\n",
            "Epoch 114/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1662102784.0000 - mae: 23799.2520 - val_loss: 1286380672.0000 - val_mae: 24360.4043\n",
            "Epoch 115/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1656838272.0000 - mae: 23692.2227 - val_loss: 1285260416.0000 - val_mae: 24276.2656\n",
            "Epoch 116/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1652261888.0000 - mae: 23610.3398 - val_loss: 1282105600.0000 - val_mae: 24250.7969\n",
            "Epoch 117/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1647032320.0000 - mae: 23594.2402 - val_loss: 1276638720.0000 - val_mae: 24273.6562\n",
            "Epoch 118/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1644432384.0000 - mae: 23521.2441 - val_loss: 1275118080.0000 - val_mae: 24209.4355\n",
            "Epoch 119/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1638912896.0000 - mae: 23534.7422 - val_loss: 1270871808.0000 - val_mae: 24215.4434\n",
            "Epoch 120/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1634978048.0000 - mae: 23472.4258 - val_loss: 1267568896.0000 - val_mae: 24181.5059\n",
            "Epoch 121/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1630026752.0000 - mae: 23410.6426 - val_loss: 1264374144.0000 - val_mae: 24161.6152\n",
            "Epoch 122/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1628633088.0000 - mae: 23458.4355 - val_loss: 1259520768.0000 - val_mae: 24181.9453\n",
            "Epoch 123/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1620791680.0000 - mae: 23359.7188 - val_loss: 1257536512.0000 - val_mae: 24111.2910\n",
            "Epoch 124/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1616713472.0000 - mae: 23268.4824 - val_loss: 1257059840.0000 - val_mae: 24046.6875\n",
            "Epoch 125/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1614965248.0000 - mae: 23156.0215 - val_loss: 1255988224.0000 - val_mae: 23981.3730\n",
            "Epoch 126/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1606758016.0000 - mae: 23136.0801 - val_loss: 1250528128.0000 - val_mae: 24010.2051\n",
            "Epoch 127/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1604851968.0000 - mae: 23174.8164 - val_loss: 1245606656.0000 - val_mae: 24020.5781\n",
            "Epoch 128/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1600050176.0000 - mae: 23147.3047 - val_loss: 1242163968.0000 - val_mae: 24006.2773\n",
            "Epoch 129/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1598253056.0000 - mae: 23024.2148 - val_loss: 1243904384.0000 - val_mae: 23883.7793\n",
            "Epoch 130/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1590764544.0000 - mae: 23017.9805 - val_loss: 1236952832.0000 - val_mae: 23964.8438\n",
            "Epoch 131/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1587315968.0000 - mae: 23010.5996 - val_loss: 1234116224.0000 - val_mae: 23929.9082\n",
            "Epoch 132/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1584387840.0000 - mae: 22935.3496 - val_loss: 1232738176.0000 - val_mae: 23874.0820\n",
            "Epoch 133/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1580199680.0000 - mae: 22887.5254 - val_loss: 1229172992.0000 - val_mae: 23867.1719\n",
            "Epoch 134/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1575739904.0000 - mae: 22847.0742 - val_loss: 1229099008.0000 - val_mae: 23786.1133\n",
            "Epoch 135/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1572111744.0000 - mae: 22763.6934 - val_loss: 1227425152.0000 - val_mae: 23757.1133\n",
            "Epoch 136/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1569603968.0000 - mae: 22754.2988 - val_loss: 1224020608.0000 - val_mae: 23751.8262\n",
            "Epoch 137/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1564999552.0000 - mae: 22717.9141 - val_loss: 1220773376.0000 - val_mae: 23739.1016\n",
            "Epoch 138/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1561599232.0000 - mae: 22667.2949 - val_loss: 1217915648.0000 - val_mae: 23712.1309\n",
            "Epoch 139/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1558303104.0000 - mae: 22584.4043 - val_loss: 1219320832.0000 - val_mae: 23600.9980\n",
            "Epoch 140/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1553285120.0000 - mae: 22542.4980 - val_loss: 1214651648.0000 - val_mae: 23632.0762\n",
            "Epoch 141/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1551286656.0000 - mae: 22492.4746 - val_loss: 1213987712.0000 - val_mae: 23586.2422\n",
            "Epoch 142/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1546385664.0000 - mae: 22461.1230 - val_loss: 1209675264.0000 - val_mae: 23594.5723\n",
            "Epoch 143/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1543079296.0000 - mae: 22497.9609 - val_loss: 1204850688.0000 - val_mae: 23617.2012\n",
            "Epoch 144/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1538521856.0000 - mae: 22414.2715 - val_loss: 1205250176.0000 - val_mae: 23532.8965\n",
            "Epoch 145/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1535173248.0000 - mae: 22344.8203 - val_loss: 1203731968.0000 - val_mae: 23501.1035\n",
            "Epoch 146/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1533351936.0000 - mae: 22376.2402 - val_loss: 1199172480.0000 - val_mae: 23513.5078\n",
            "Epoch 147/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1529736320.0000 - mae: 22280.7090 - val_loss: 1197107456.0000 - val_mae: 23464.9727\n",
            "Epoch 148/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1528499968.0000 - mae: 22212.8730 - val_loss: 1199340672.0000 - val_mae: 23372.7949\n",
            "Epoch 149/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1521187712.0000 - mae: 22186.8438 - val_loss: 1193816832.0000 - val_mae: 23416.5781\n",
            "Epoch 150/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1517856640.0000 - mae: 22187.2031 - val_loss: 1191717504.0000 - val_mae: 23382.3086\n",
            "Epoch 151/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1515766784.0000 - mae: 22091.8867 - val_loss: 1190659200.0000 - val_mae: 23338.2090\n",
            "Epoch 152/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1515410176.0000 - mae: 22163.0781 - val_loss: 1186507776.0000 - val_mae: 23347.5098\n",
            "Epoch 153/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1509192064.0000 - mae: 22046.4512 - val_loss: 1187232896.0000 - val_mae: 23273.1367\n",
            "Epoch 154/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1504615680.0000 - mae: 22028.4355 - val_loss: 1182938496.0000 - val_mae: 23291.9961\n",
            "Epoch 155/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1501895552.0000 - mae: 22040.2441 - val_loss: 1179407104.0000 - val_mae: 23285.3535\n",
            "Epoch 156/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1497292928.0000 - mae: 21986.2559 - val_loss: 1177395072.0000 - val_mae: 23263.3574\n",
            "Epoch 157/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1495589888.0000 - mae: 21930.5254 - val_loss: 1176565504.0000 - val_mae: 23207.1348\n",
            "Epoch 158/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1491524352.0000 - mae: 21895.0078 - val_loss: 1173731072.0000 - val_mae: 23194.1836\n",
            "Epoch 159/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1488016256.0000 - mae: 21868.9492 - val_loss: 1172294144.0000 - val_mae: 23176.8965\n",
            "Epoch 160/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1485912320.0000 - mae: 21855.3477 - val_loss: 1168447232.0000 - val_mae: 23168.5156\n",
            "Epoch 161/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1481811200.0000 - mae: 21818.9395 - val_loss: 1166506112.0000 - val_mae: 23144.1074\n",
            "Epoch 162/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1479989504.0000 - mae: 21804.3262 - val_loss: 1162214400.0000 - val_mae: 23158.4863\n",
            "Epoch 163/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1475760512.0000 - mae: 21794.9258 - val_loss: 1160578432.0000 - val_mae: 23116.0898\n",
            "Epoch 164/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1470813056.0000 - mae: 21697.4336 - val_loss: 1162032512.0000 - val_mae: 23028.1445\n",
            "Epoch 165/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1468875904.0000 - mae: 21622.9746 - val_loss: 1160299136.0000 - val_mae: 22999.2422\n",
            "Epoch 166/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1469758976.0000 - mae: 21554.6445 - val_loss: 1159723136.0000 - val_mae: 22961.4219\n",
            "Epoch 167/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1463402624.0000 - mae: 21567.2773 - val_loss: 1154957952.0000 - val_mae: 22985.4395\n",
            "Epoch 168/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1460216448.0000 - mae: 21542.3086 - val_loss: 1153258752.0000 - val_mae: 22962.8203\n",
            "Epoch 169/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1457257088.0000 - mae: 21500.6602 - val_loss: 1152439424.0000 - val_mae: 22918.8984\n",
            "Epoch 170/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1454293504.0000 - mae: 21447.7773 - val_loss: 1150456064.0000 - val_mae: 22890.3867\n",
            "Epoch 171/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1454590976.0000 - mae: 21398.7422 - val_loss: 1152187520.0000 - val_mae: 22838.2793\n",
            "Epoch 172/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1448185088.0000 - mae: 21403.7402 - val_loss: 1147186688.0000 - val_mae: 22862.3184\n",
            "Epoch 173/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1444895616.0000 - mae: 21377.8242 - val_loss: 1146886784.0000 - val_mae: 22812.1504\n",
            "Epoch 174/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1443159552.0000 - mae: 21346.5859 - val_loss: 1145392512.0000 - val_mae: 22788.6582\n",
            "Epoch 175/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1438557568.0000 - mae: 21317.4727 - val_loss: 1141238400.0000 - val_mae: 22817.8008\n",
            "Epoch 176/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1437451008.0000 - mae: 21317.0859 - val_loss: 1139639936.0000 - val_mae: 22775.1094\n",
            "Epoch 177/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1433208192.0000 - mae: 21254.3105 - val_loss: 1137507968.0000 - val_mae: 22760.1562\n",
            "Epoch 178/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1431880064.0000 - mae: 21215.4629 - val_loss: 1137978496.0000 - val_mae: 22694.9844\n",
            "Epoch 179/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1428669696.0000 - mae: 21148.2344 - val_loss: 1135435904.0000 - val_mae: 22682.9668\n",
            "Epoch 180/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1423890048.0000 - mae: 21170.2754 - val_loss: 1130254464.0000 - val_mae: 22708.7402\n",
            "Epoch 181/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1422712960.0000 - mae: 21185.3008 - val_loss: 1126113280.0000 - val_mae: 22731.0566\n",
            "Epoch 182/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1418989440.0000 - mae: 21109.9629 - val_loss: 1129529856.0000 - val_mae: 22619.4648\n",
            "Epoch 183/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1418082048.0000 - mae: 21126.6660 - val_loss: 1124235520.0000 - val_mae: 22653.6738\n",
            "Epoch 184/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1413348864.0000 - mae: 21048.4902 - val_loss: 1125107712.0000 - val_mae: 22583.9277\n",
            "Epoch 185/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1410167040.0000 - mae: 21001.0898 - val_loss: 1122857344.0000 - val_mae: 22572.4902\n",
            "Epoch 186/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1407927936.0000 - mae: 20992.1074 - val_loss: 1120739968.0000 - val_mae: 22556.6875\n",
            "Epoch 187/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1405717376.0000 - mae: 20990.0703 - val_loss: 1117768064.0000 - val_mae: 22554.7402\n",
            "Epoch 188/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1402720768.0000 - mae: 20955.0020 - val_loss: 1114602496.0000 - val_mae: 22550.4883\n",
            "Epoch 189/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1398931072.0000 - mae: 20912.9004 - val_loss: 1114155776.0000 - val_mae: 22501.7891\n",
            "Epoch 190/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1397352704.0000 - mae: 20916.7441 - val_loss: 1110631168.0000 - val_mae: 22514.6055\n",
            "Epoch 191/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1393751168.0000 - mae: 20858.1992 - val_loss: 1111308544.0000 - val_mae: 22430.5449\n",
            "Epoch 192/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1391734912.0000 - mae: 20836.1074 - val_loss: 1107813376.0000 - val_mae: 22454.4844\n",
            "Epoch 193/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1389241600.0000 - mae: 20834.6426 - val_loss: 1106496000.0000 - val_mae: 22421.2695\n",
            "Epoch 194/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1386243328.0000 - mae: 20782.2676 - val_loss: 1105548544.0000 - val_mae: 22375.4316\n",
            "Epoch 195/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1384962048.0000 - mae: 20741.5703 - val_loss: 1102268544.0000 - val_mae: 22384.7812\n",
            "Epoch 196/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1382752896.0000 - mae: 20704.9434 - val_loss: 1104300800.0000 - val_mae: 22300.9395\n",
            "Epoch 197/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1378888960.0000 - mae: 20687.7246 - val_loss: 1098883456.0000 - val_mae: 22349.9922\n",
            "Epoch 198/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1375900544.0000 - mae: 20667.2656 - val_loss: 1098439936.0000 - val_mae: 22305.5645\n",
            "Epoch 199/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1378943488.0000 - mae: 20703.8945 - val_loss: 1093867008.0000 - val_mae: 22326.5156\n",
            "Epoch 200/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1372023808.0000 - mae: 20622.9746 - val_loss: 1093681152.0000 - val_mae: 22255.9492\n",
            "Epoch 201/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1371065216.0000 - mae: 20547.4062 - val_loss: 1094164352.0000 - val_mae: 22217.5684\n",
            "Epoch 202/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1366588288.0000 - mae: 20583.6270 - val_loss: 1089360128.0000 - val_mae: 22272.7129\n",
            "Epoch 203/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1365641600.0000 - mae: 20537.6387 - val_loss: 1090258816.0000 - val_mae: 22195.3438\n",
            "Epoch 204/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1362487936.0000 - mae: 20548.7793 - val_loss: 1085517312.0000 - val_mae: 22237.6816\n",
            "Epoch 205/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1358274048.0000 - mae: 20516.4473 - val_loss: 1084050048.0000 - val_mae: 22200.1719\n",
            "Epoch 206/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1358674688.0000 - mae: 20464.1289 - val_loss: 1083948928.0000 - val_mae: 22163.4238\n",
            "Epoch 207/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1358560512.0000 - mae: 20515.7246 - val_loss: 1078022656.0000 - val_mae: 22245.0332\n",
            "Epoch 208/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1352274176.0000 - mae: 20455.3848 - val_loss: 1078125440.0000 - val_mae: 22155.0566\n",
            "Epoch 209/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1352573056.0000 - mae: 20364.0469 - val_loss: 1084310016.0000 - val_mae: 22013.4922\n",
            "Epoch 210/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1348313728.0000 - mae: 20333.6855 - val_loss: 1079596672.0000 - val_mae: 22065.3672\n",
            "Epoch 211/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1344196096.0000 - mae: 20341.8770 - val_loss: 1076548096.0000 - val_mae: 22087.2207\n",
            "Epoch 212/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1342003328.0000 - mae: 20316.9648 - val_loss: 1075212288.0000 - val_mae: 22057.6875\n",
            "Epoch 213/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1341597056.0000 - mae: 20346.0352 - val_loss: 1069104896.0000 - val_mae: 22113.9531\n",
            "Epoch 214/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1337890176.0000 - mae: 20271.9590 - val_loss: 1073510528.0000 - val_mae: 21980.4160\n",
            "Epoch 215/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1334986624.0000 - mae: 20214.3672 - val_loss: 1070331200.0000 - val_mae: 21975.5586\n",
            "Epoch 216/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1332867072.0000 - mae: 20195.3691 - val_loss: 1071755008.0000 - val_mae: 21929.2617\n",
            "Epoch 217/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1332434048.0000 - mae: 20198.1504 - val_loss: 1065342016.0000 - val_mae: 21994.1113\n",
            "Epoch 218/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1328608640.0000 - mae: 20162.0332 - val_loss: 1067625152.0000 - val_mae: 21900.2988\n",
            "Epoch 219/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1326458112.0000 - mae: 20125.0977 - val_loss: 1065319616.0000 - val_mae: 21903.8848\n",
            "Epoch 220/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1323890688.0000 - mae: 20154.6367 - val_loss: 1061536256.0000 - val_mae: 21924.5469\n",
            "Epoch 221/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1321756928.0000 - mae: 20129.7656 - val_loss: 1060356096.0000 - val_mae: 21902.5840\n",
            "Epoch 222/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1324064384.0000 - mae: 20180.1367 - val_loss: 1056829184.0000 - val_mae: 21906.4121\n",
            "Epoch 223/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1317827072.0000 - mae: 20103.9004 - val_loss: 1055088640.0000 - val_mae: 21876.3965\n",
            "Epoch 224/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1314852480.0000 - mae: 20061.3965 - val_loss: 1055500288.0000 - val_mae: 21828.3262\n",
            "Epoch 225/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1312391552.0000 - mae: 20033.0859 - val_loss: 1052339392.0000 - val_mae: 21845.5625\n",
            "Epoch 226/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1310340096.0000 - mae: 20022.5801 - val_loss: 1050706496.0000 - val_mae: 21819.4531\n",
            "Epoch 227/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1310297344.0000 - mae: 19987.8379 - val_loss: 1049672512.0000 - val_mae: 21799.0586\n",
            "Epoch 228/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1306380032.0000 - mae: 20004.4922 - val_loss: 1046507136.0000 - val_mae: 21805.9141\n",
            "Epoch 229/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1303461248.0000 - mae: 19970.2227 - val_loss: 1046242624.0000 - val_mae: 21760.3125\n",
            "Epoch 230/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1302897024.0000 - mae: 19933.5879 - val_loss: 1043213504.0000 - val_mae: 21750.7246\n",
            "Epoch 231/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1302208640.0000 - mae: 19908.3301 - val_loss: 1045309056.0000 - val_mae: 21681.1172\n",
            "Epoch 232/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1298877952.0000 - mae: 19858.6895 - val_loss: 1042608960.0000 - val_mae: 21697.3281\n",
            "Epoch 233/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1295620736.0000 - mae: 19855.6836 - val_loss: 1039797312.0000 - val_mae: 21692.7109\n",
            "Epoch 234/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1293464960.0000 - mae: 19872.0547 - val_loss: 1035920832.0000 - val_mae: 21704.3711\n",
            "Epoch 235/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1292994560.0000 - mae: 19911.1797 - val_loss: 1033641728.0000 - val_mae: 21751.0254\n",
            "Epoch 236/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1291243392.0000 - mae: 19821.5371 - val_loss: 1035794432.0000 - val_mae: 21618.9980\n",
            "Epoch 237/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1287504896.0000 - mae: 19780.1270 - val_loss: 1032930240.0000 - val_mae: 21631.4824\n",
            "Epoch 238/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1288425984.0000 - mae: 19756.3398 - val_loss: 1032660032.0000 - val_mae: 21592.1582\n",
            "Epoch 239/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1282815616.0000 - mae: 19748.6602 - val_loss: 1029196736.0000 - val_mae: 21605.0449\n",
            "Epoch 240/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1281509248.0000 - mae: 19759.2344 - val_loss: 1026748544.0000 - val_mae: 21604.5723\n",
            "Epoch 241/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1279503616.0000 - mae: 19751.4238 - val_loss: 1025208832.0000 - val_mae: 21609.9902\n",
            "Epoch 242/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1277322240.0000 - mae: 19712.8203 - val_loss: 1024554432.0000 - val_mae: 21562.6719\n",
            "Epoch 243/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1275711872.0000 - mae: 19690.2754 - val_loss: 1022922496.0000 - val_mae: 21527.1973\n",
            "Epoch 244/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1274775808.0000 - mae: 19662.4199 - val_loss: 1021049344.0000 - val_mae: 21531.4961\n",
            "Epoch 245/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1272158336.0000 - mae: 19688.5977 - val_loss: 1018974784.0000 - val_mae: 21535.3594\n",
            "Epoch 246/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1270772096.0000 - mae: 19635.7422 - val_loss: 1017433600.0000 - val_mae: 21504.1660\n",
            "Epoch 247/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1270331776.0000 - mae: 19615.0801 - val_loss: 1017022464.0000 - val_mae: 21473.8184\n",
            "Epoch 248/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1266011136.0000 - mae: 19590.1445 - val_loss: 1015590528.0000 - val_mae: 21459.0801\n",
            "Epoch 249/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1269217152.0000 - mae: 19622.6348 - val_loss: 1010986880.0000 - val_mae: 21514.2793\n",
            "Epoch 250/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1260911744.0000 - mae: 19561.1855 - val_loss: 1013467648.0000 - val_mae: 21399.4297\n",
            "Epoch 251/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1260536192.0000 - mae: 19493.0449 - val_loss: 1016138112.0000 - val_mae: 21322.6035\n",
            "Epoch 252/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1259135360.0000 - mae: 19468.0371 - val_loss: 1013660864.0000 - val_mae: 21339.5098\n",
            "Epoch 253/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1257611648.0000 - mae: 19479.7871 - val_loss: 1009989120.0000 - val_mae: 21366.3555\n",
            "Epoch 254/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1256486528.0000 - mae: 19457.8867 - val_loss: 1011233600.0000 - val_mae: 21291.8809\n",
            "Epoch 255/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1253943552.0000 - mae: 19442.1914 - val_loss: 1007806848.0000 - val_mae: 21341.2656\n",
            "Epoch 256/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1251732992.0000 - mae: 19461.1348 - val_loss: 1005625536.0000 - val_mae: 21359.7539\n",
            "Epoch 257/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1251495808.0000 - mae: 19416.0684 - val_loss: 1004394240.0000 - val_mae: 21326.0176\n",
            "Epoch 258/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1249115904.0000 - mae: 19449.2383 - val_loss: 1002256000.0000 - val_mae: 21329.4668\n",
            "Epoch 259/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1247675136.0000 - mae: 19379.7812 - val_loss: 1003380992.0000 - val_mae: 21264.2754\n",
            "Epoch 260/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1243941888.0000 - mae: 19378.8105 - val_loss: 999219776.0000 - val_mae: 21319.5820\n",
            "Epoch 261/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1243950208.0000 - mae: 19371.8750 - val_loss: 999139200.0000 - val_mae: 21284.0430\n",
            "Epoch 262/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1241971328.0000 - mae: 19340.2070 - val_loss: 998432064.0000 - val_mae: 21255.1328\n",
            "Epoch 263/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1238898944.0000 - mae: 19383.8965 - val_loss: 992421376.0000 - val_mae: 21362.0566\n",
            "Epoch 264/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1240792192.0000 - mae: 19367.2656 - val_loss: 992565824.0000 - val_mae: 21318.8125\n",
            "Epoch 265/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1236404096.0000 - mae: 19389.3359 - val_loss: 988629760.0000 - val_mae: 21354.4492\n",
            "Epoch 266/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1234227968.0000 - mae: 19325.2363 - val_loss: 990063168.0000 - val_mae: 21240.9238\n",
            "Epoch 267/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1233689216.0000 - mae: 19328.6289 - val_loss: 986869312.0000 - val_mae: 21266.9922\n",
            "Epoch 268/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1230984832.0000 - mae: 19279.8184 - val_loss: 987807744.0000 - val_mae: 21207.5605\n",
            "Epoch 269/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1229452416.0000 - mae: 19251.0000 - val_loss: 986738304.0000 - val_mae: 21186.3496\n",
            "Epoch 270/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1226465664.0000 - mae: 19246.5352 - val_loss: 984223296.0000 - val_mae: 21218.0312\n",
            "Epoch 271/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1225999744.0000 - mae: 19273.1895 - val_loss: 982710144.0000 - val_mae: 21222.2656\n",
            "Epoch 272/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1223646592.0000 - mae: 19241.5781 - val_loss: 980936768.0000 - val_mae: 21188.9785\n",
            "Epoch 273/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1224532352.0000 - mae: 19194.9707 - val_loss: 980879936.0000 - val_mae: 21151.4238\n",
            "Epoch 274/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1220052608.0000 - mae: 19201.3223 - val_loss: 978685376.0000 - val_mae: 21149.8438\n",
            "Epoch 275/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1218829312.0000 - mae: 19177.5430 - val_loss: 978332480.0000 - val_mae: 21123.1191\n",
            "Epoch 276/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1218119296.0000 - mae: 19165.2480 - val_loss: 976122112.0000 - val_mae: 21133.3145\n",
            "Epoch 277/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1215647872.0000 - mae: 19156.8887 - val_loss: 975328512.0000 - val_mae: 21104.4434\n",
            "Epoch 278/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1214787200.0000 - mae: 19184.9688 - val_loss: 971115456.0000 - val_mae: 21165.0684\n",
            "Epoch 279/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1213187456.0000 - mae: 19175.2109 - val_loss: 970223168.0000 - val_mae: 21119.8926\n",
            "Epoch 280/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1213451776.0000 - mae: 19114.5977 - val_loss: 970770560.0000 - val_mae: 21094.3711\n",
            "Epoch 281/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1209228288.0000 - mae: 19121.3594 - val_loss: 969180352.0000 - val_mae: 21090.0449\n",
            "Epoch 282/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1209937536.0000 - mae: 19081.0117 - val_loss: 969149696.0000 - val_mae: 21050.7383\n",
            "Epoch 283/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1206732672.0000 - mae: 19068.9551 - val_loss: 968176256.0000 - val_mae: 21038.0469\n",
            "Epoch 284/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1206016384.0000 - mae: 19092.1582 - val_loss: 966103680.0000 - val_mae: 21042.7266\n",
            "Epoch 285/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1203701376.0000 - mae: 19063.2148 - val_loss: 965195392.0000 - val_mae: 21022.5547\n",
            "Epoch 286/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1200978560.0000 - mae: 19049.1621 - val_loss: 963042880.0000 - val_mae: 21030.5156\n",
            "Epoch 287/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1200750208.0000 - mae: 19022.8320 - val_loss: 963100800.0000 - val_mae: 20984.6543\n",
            "Epoch 288/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1199533312.0000 - mae: 19035.6602 - val_loss: 958518080.0000 - val_mae: 21038.2070\n",
            "Epoch 289/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1197019520.0000 - mae: 19000.4453 - val_loss: 962720960.0000 - val_mae: 20934.7910\n",
            "Epoch 290/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1195887232.0000 - mae: 18961.6738 - val_loss: 961586944.0000 - val_mae: 20933.8867\n",
            "Epoch 291/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1194366976.0000 - mae: 18980.8418 - val_loss: 958296960.0000 - val_mae: 20971.2168\n",
            "Epoch 292/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1193547136.0000 - mae: 18956.4336 - val_loss: 958231552.0000 - val_mae: 20921.0566\n",
            "Epoch 293/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1190619264.0000 - mae: 18952.4336 - val_loss: 955442688.0000 - val_mae: 20952.0332\n",
            "Epoch 294/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1190021376.0000 - mae: 18983.4805 - val_loss: 954083264.0000 - val_mae: 20933.9766\n",
            "Epoch 295/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1188322944.0000 - mae: 18936.9219 - val_loss: 953611712.0000 - val_mae: 20904.9258\n",
            "Epoch 296/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1187894912.0000 - mae: 18955.8555 - val_loss: 949544192.0000 - val_mae: 20985.7324\n",
            "Epoch 297/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1187036160.0000 - mae: 18915.8770 - val_loss: 950739648.0000 - val_mae: 20903.4551\n",
            "Epoch 298/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1184139136.0000 - mae: 18922.5156 - val_loss: 948550720.0000 - val_mae: 20919.0332\n",
            "Epoch 299/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1183683584.0000 - mae: 18962.4785 - val_loss: 945223168.0000 - val_mae: 20942.8379\n",
            "Epoch 300/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1181671296.0000 - mae: 18924.7090 - val_loss: 945594496.0000 - val_mae: 20892.2266\n",
            "Epoch 301/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1178855040.0000 - mae: 18856.2031 - val_loss: 945913600.0000 - val_mae: 20844.5352\n",
            "Epoch 302/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1178476800.0000 - mae: 18818.0977 - val_loss: 943530496.0000 - val_mae: 20848.2422\n",
            "Epoch 303/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1177073280.0000 - mae: 18841.5684 - val_loss: 943060672.0000 - val_mae: 20830.6543\n",
            "Epoch 304/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1179851392.0000 - mae: 18907.0859 - val_loss: 937705344.0000 - val_mae: 20951.0273\n",
            "Epoch 305/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1173375616.0000 - mae: 18848.5566 - val_loss: 940797824.0000 - val_mae: 20821.0801\n",
            "Epoch 306/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1172270720.0000 - mae: 18797.7305 - val_loss: 939635968.0000 - val_mae: 20802.8184\n",
            "Epoch 307/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1171550592.0000 - mae: 18776.9570 - val_loss: 939365440.0000 - val_mae: 20792.6660\n",
            "Epoch 308/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1169629312.0000 - mae: 18768.5781 - val_loss: 937141696.0000 - val_mae: 20811.6719\n",
            "Epoch 309/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1168816384.0000 - mae: 18803.1562 - val_loss: 934875904.0000 - val_mae: 20818.8281\n",
            "Epoch 310/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1167461120.0000 - mae: 18771.9922 - val_loss: 933900032.0000 - val_mae: 20803.6445\n",
            "Epoch 311/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1168149504.0000 - mae: 18722.4883 - val_loss: 934779584.0000 - val_mae: 20767.4707\n",
            "Epoch 312/1000\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 1165483904.0000 - mae: 18760.5625 - val_loss: 930813632.0000 - val_mae: 20813.9492\n",
            "Epoch 313/1000\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 1162889216.0000 - mae: 18753.2344 - val_loss: 931151360.0000 - val_mae: 20771.0547\n",
            "Epoch 314/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1163687936.0000 - mae: 18673.1445 - val_loss: 932292864.0000 - val_mae: 20711.2949\n",
            "Epoch 315/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1160834816.0000 - mae: 18664.1387 - val_loss: 930156480.0000 - val_mae: 20724.9043\n",
            "Epoch 316/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1160132608.0000 - mae: 18727.7930 - val_loss: 926758528.0000 - val_mae: 20765.7148\n",
            "Epoch 317/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1160249216.0000 - mae: 18683.4355 - val_loss: 925976576.0000 - val_mae: 20750.3828\n",
            "Epoch 318/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1158336384.0000 - mae: 18660.9082 - val_loss: 926621056.0000 - val_mae: 20711.4062\n",
            "Epoch 319/1000\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 1157858176.0000 - mae: 18713.9688 - val_loss: 921082496.0000 - val_mae: 20797.6641\n",
            "Epoch 320/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1154449280.0000 - mae: 18701.2598 - val_loss: 923048960.0000 - val_mae: 20716.6953\n",
            "Epoch 321/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1153035520.0000 - mae: 18633.5508 - val_loss: 923214080.0000 - val_mae: 20678.7871\n",
            "Epoch 322/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1152187776.0000 - mae: 18641.6016 - val_loss: 920576512.0000 - val_mae: 20710.9668\n",
            "Epoch 323/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1153357568.0000 - mae: 18697.4492 - val_loss: 919422912.0000 - val_mae: 20704.6602\n",
            "Epoch 324/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1149853696.0000 - mae: 18633.0371 - val_loss: 919905280.0000 - val_mae: 20667.5156\n",
            "Epoch 325/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1148436480.0000 - mae: 18607.0254 - val_loss: 917399040.0000 - val_mae: 20673.7559\n",
            "Epoch 326/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1146283904.0000 - mae: 18591.0059 - val_loss: 917330752.0000 - val_mae: 20655.0410\n",
            "Epoch 327/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1146799488.0000 - mae: 18626.9258 - val_loss: 914927808.0000 - val_mae: 20679.0176\n",
            "Epoch 328/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1143632384.0000 - mae: 18564.6055 - val_loss: 915829056.0000 - val_mae: 20612.7969\n",
            "Epoch 329/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1143002112.0000 - mae: 18555.6992 - val_loss: 914631296.0000 - val_mae: 20617.4180\n",
            "Epoch 330/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1142892928.0000 - mae: 18532.2148 - val_loss: 912520576.0000 - val_mae: 20628.5078\n",
            "Epoch 331/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1141950080.0000 - mae: 18546.0215 - val_loss: 914167680.0000 - val_mae: 20588.8848\n",
            "Epoch 332/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1140201856.0000 - mae: 18563.4043 - val_loss: 911215360.0000 - val_mae: 20630.8145\n",
            "Epoch 333/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1139982336.0000 - mae: 18604.9785 - val_loss: 908530368.0000 - val_mae: 20648.6484\n",
            "Epoch 334/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1139200768.0000 - mae: 18498.6582 - val_loss: 911878720.0000 - val_mae: 20557.8848\n",
            "Epoch 335/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1136310656.0000 - mae: 18482.2617 - val_loss: 908976640.0000 - val_mae: 20575.2949\n",
            "Epoch 336/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1134885248.0000 - mae: 18479.5859 - val_loss: 908946752.0000 - val_mae: 20557.2891\n",
            "Epoch 337/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1136658944.0000 - mae: 18530.2559 - val_loss: 903909120.0000 - val_mae: 20649.6406\n",
            "Epoch 338/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1132092032.0000 - mae: 18510.1465 - val_loss: 906788800.0000 - val_mae: 20554.5723\n",
            "Epoch 339/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1131919360.0000 - mae: 18451.7285 - val_loss: 905645824.0000 - val_mae: 20552.3105\n",
            "Epoch 340/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1132590464.0000 - mae: 18447.8262 - val_loss: 905609152.0000 - val_mae: 20527.5488\n",
            "Epoch 341/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1128948096.0000 - mae: 18445.5020 - val_loss: 903388224.0000 - val_mae: 20532.7832\n",
            "Epoch 342/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1129369472.0000 - mae: 18490.3301 - val_loss: 900810944.0000 - val_mae: 20576.8594\n",
            "Epoch 343/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1126968832.0000 - mae: 18513.8594 - val_loss: 898688256.0000 - val_mae: 20583.8477\n",
            "Epoch 344/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1126210816.0000 - mae: 18447.8926 - val_loss: 899284480.0000 - val_mae: 20544.4121\n",
            "Epoch 345/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1124645760.0000 - mae: 18451.7090 - val_loss: 898974848.0000 - val_mae: 20523.8906\n",
            "Epoch 346/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1122372608.0000 - mae: 18426.4258 - val_loss: 896995648.0000 - val_mae: 20541.3555\n",
            "Epoch 347/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1121678208.0000 - mae: 18432.5996 - val_loss: 895008320.0000 - val_mae: 20543.8711\n",
            "Epoch 348/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1123564544.0000 - mae: 18480.4414 - val_loss: 891667904.0000 - val_mae: 20588.1562\n",
            "Epoch 349/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1121785344.0000 - mae: 18427.9609 - val_loss: 894512640.0000 - val_mae: 20515.1855\n",
            "Epoch 350/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1118459264.0000 - mae: 18418.4980 - val_loss: 893192768.0000 - val_mae: 20516.6836\n",
            "Epoch 351/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1117793024.0000 - mae: 18381.0645 - val_loss: 892797824.0000 - val_mae: 20494.6602\n",
            "Epoch 352/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1117042688.0000 - mae: 18378.3047 - val_loss: 892829184.0000 - val_mae: 20456.4980\n",
            "Epoch 353/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1117000832.0000 - mae: 18412.2773 - val_loss: 889109376.0000 - val_mae: 20516.5000\n",
            "Epoch 354/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1120815360.0000 - mae: 18345.2871 - val_loss: 891360768.0000 - val_mae: 20434.2637\n",
            "Epoch 355/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1112651648.0000 - mae: 18372.4531 - val_loss: 888090624.0000 - val_mae: 20482.9336\n",
            "Epoch 356/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1113228544.0000 - mae: 18383.4297 - val_loss: 887957952.0000 - val_mae: 20462.4688\n",
            "Epoch 357/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1110788352.0000 - mae: 18372.8359 - val_loss: 886594560.0000 - val_mae: 20464.9629\n",
            "Epoch 358/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1112520320.0000 - mae: 18316.3340 - val_loss: 886794752.0000 - val_mae: 20433.2812\n",
            "Epoch 359/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1108575232.0000 - mae: 18335.6914 - val_loss: 884332608.0000 - val_mae: 20461.5723\n",
            "Epoch 360/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1111504640.0000 - mae: 18329.5352 - val_loss: 884518080.0000 - val_mae: 20432.2637\n",
            "Epoch 361/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1107557376.0000 - mae: 18359.4922 - val_loss: 882043520.0000 - val_mae: 20478.2930\n",
            "Epoch 362/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1106630016.0000 - mae: 18339.5801 - val_loss: 882849728.0000 - val_mae: 20429.7852\n",
            "Epoch 363/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1104668288.0000 - mae: 18312.6309 - val_loss: 880891648.0000 - val_mae: 20454.1543\n",
            "Epoch 364/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1104380160.0000 - mae: 18351.4453 - val_loss: 879503488.0000 - val_mae: 20455.8613\n",
            "Epoch 365/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1102849536.0000 - mae: 18305.8184 - val_loss: 880120256.0000 - val_mae: 20415.1973\n",
            "Epoch 366/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1105992832.0000 - mae: 18386.4023 - val_loss: 875642112.0000 - val_mae: 20497.6406\n",
            "Epoch 367/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1100615552.0000 - mae: 18291.1289 - val_loss: 878230464.0000 - val_mae: 20392.6387\n",
            "Epoch 368/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1099252224.0000 - mae: 18293.4824 - val_loss: 876913728.0000 - val_mae: 20399.5566\n",
            "Epoch 369/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1099888256.0000 - mae: 18261.1484 - val_loss: 875580864.0000 - val_mae: 20400.2617\n",
            "Epoch 370/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1096858496.0000 - mae: 18260.1484 - val_loss: 874162048.0000 - val_mae: 20402.6055\n",
            "Epoch 371/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1098433152.0000 - mae: 18267.2148 - val_loss: 873809216.0000 - val_mae: 20409.7539\n",
            "Epoch 372/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1097220224.0000 - mae: 18234.6758 - val_loss: 874422912.0000 - val_mae: 20362.8066\n",
            "Epoch 373/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1095068288.0000 - mae: 18261.1445 - val_loss: 870750592.0000 - val_mae: 20408.4277\n",
            "Epoch 374/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1094445696.0000 - mae: 18270.0547 - val_loss: 870841856.0000 - val_mae: 20385.9121\n",
            "Epoch 375/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1095344768.0000 - mae: 18213.1465 - val_loss: 872123008.0000 - val_mae: 20323.5020\n",
            "Epoch 376/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1091918464.0000 - mae: 18218.5215 - val_loss: 870447872.0000 - val_mae: 20335.5098\n",
            "Epoch 377/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1091226240.0000 - mae: 18246.8105 - val_loss: 867424960.0000 - val_mae: 20374.3457\n",
            "Epoch 378/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1089835136.0000 - mae: 18222.3320 - val_loss: 867969472.0000 - val_mae: 20337.1211\n",
            "Epoch 379/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1089588352.0000 - mae: 18198.0527 - val_loss: 868253696.0000 - val_mae: 20319.6504\n",
            "Epoch 380/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1087081728.0000 - mae: 18233.0020 - val_loss: 865477632.0000 - val_mae: 20352.0488\n",
            "Epoch 381/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1090322304.0000 - mae: 18329.7852 - val_loss: 862606464.0000 - val_mae: 20407.8281\n",
            "Epoch 382/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1088993280.0000 - mae: 18193.6133 - val_loss: 866249216.0000 - val_mae: 20282.9141\n",
            "Epoch 383/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1084040320.0000 - mae: 18164.5215 - val_loss: 863827840.0000 - val_mae: 20311.2188\n",
            "Epoch 384/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1085162624.0000 - mae: 18173.8652 - val_loss: 864493184.0000 - val_mae: 20277.2324\n",
            "Epoch 385/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1083153664.0000 - mae: 18215.1055 - val_loss: 861294528.0000 - val_mae: 20327.1016\n",
            "Epoch 386/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1082197376.0000 - mae: 18197.7910 - val_loss: 861779072.0000 - val_mae: 20296.0488\n",
            "Epoch 387/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1081188096.0000 - mae: 18174.7246 - val_loss: 860453312.0000 - val_mae: 20299.3770\n",
            "Epoch 388/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1081136512.0000 - mae: 18126.6074 - val_loss: 863293184.0000 - val_mae: 20215.0664\n",
            "Epoch 389/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1083124608.0000 - mae: 18200.3770 - val_loss: 857012736.0000 - val_mae: 20344.1973\n",
            "Epoch 390/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1078488192.0000 - mae: 18135.7773 - val_loss: 861241856.0000 - val_mae: 20217.0879\n",
            "Epoch 391/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1076867200.0000 - mae: 18124.2539 - val_loss: 858321600.0000 - val_mae: 20263.5938\n",
            "Epoch 392/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1076191104.0000 - mae: 18142.5195 - val_loss: 857914944.0000 - val_mae: 20250.2285\n",
            "Epoch 393/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1075302528.0000 - mae: 18094.2012 - val_loss: 857203840.0000 - val_mae: 20234.8574\n",
            "Epoch 394/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1074308736.0000 - mae: 18144.1523 - val_loss: 855323968.0000 - val_mae: 20272.1621\n",
            "Epoch 395/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1072526464.0000 - mae: 18137.8750 - val_loss: 855112896.0000 - val_mae: 20260.8672\n",
            "Epoch 396/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1072413696.0000 - mae: 18090.3594 - val_loss: 855871872.0000 - val_mae: 20193.3320\n",
            "Epoch 397/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1070592192.0000 - mae: 18091.8691 - val_loss: 853630336.0000 - val_mae: 20229.7324\n",
            "Epoch 398/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1070054848.0000 - mae: 18131.1426 - val_loss: 852439168.0000 - val_mae: 20249.7891\n",
            "Epoch 399/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1070081280.0000 - mae: 18086.1094 - val_loss: 851706304.0000 - val_mae: 20242.9180\n",
            "Epoch 400/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1069883200.0000 - mae: 18127.3203 - val_loss: 848896192.0000 - val_mae: 20307.0586\n",
            "Epoch 401/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1069607744.0000 - mae: 18185.6914 - val_loss: 849375936.0000 - val_mae: 20271.4883\n",
            "Epoch 402/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1065914560.0000 - mae: 18072.5566 - val_loss: 850861824.0000 - val_mae: 20194.9375\n",
            "Epoch 403/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1065448000.0000 - mae: 18060.0176 - val_loss: 849590080.0000 - val_mae: 20188.0664\n",
            "Epoch 404/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1067729856.0000 - mae: 18040.0000 - val_loss: 850058496.0000 - val_mae: 20163.3613\n",
            "Epoch 405/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1064047552.0000 - mae: 18059.0449 - val_loss: 848531712.0000 - val_mae: 20174.6719\n",
            "Epoch 406/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1062253056.0000 - mae: 18050.9082 - val_loss: 847801728.0000 - val_mae: 20177.8223\n",
            "Epoch 407/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1062036160.0000 - mae: 18062.2051 - val_loss: 846375360.0000 - val_mae: 20192.0664\n",
            "Epoch 408/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1061260672.0000 - mae: 18047.5078 - val_loss: 847503552.0000 - val_mae: 20135.5586\n",
            "Epoch 409/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1059582656.0000 - mae: 18007.5918 - val_loss: 845727552.0000 - val_mae: 20146.0254\n",
            "Epoch 410/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1060961344.0000 - mae: 18073.7598 - val_loss: 843049600.0000 - val_mae: 20200.1367\n",
            "Epoch 411/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1061158528.0000 - mae: 18020.8867 - val_loss: 846277696.0000 - val_mae: 20109.4062\n",
            "Epoch 412/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1058327424.0000 - mae: 18037.9297 - val_loss: 842372480.0000 - val_mae: 20187.2871\n",
            "Epoch 413/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1057289344.0000 - mae: 18010.2578 - val_loss: 844873920.0000 - val_mae: 20111.9629\n",
            "Epoch 414/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1055858368.0000 - mae: 18009.5703 - val_loss: 842625792.0000 - val_mae: 20144.2969\n",
            "Epoch 415/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1056014976.0000 - mae: 18055.5586 - val_loss: 840936704.0000 - val_mae: 20168.4668\n",
            "Epoch 416/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1053613440.0000 - mae: 17999.1562 - val_loss: 842688128.0000 - val_mae: 20099.8965\n",
            "Epoch 417/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1053253888.0000 - mae: 18009.7832 - val_loss: 840965376.0000 - val_mae: 20127.0820\n",
            "Epoch 418/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1054025920.0000 - mae: 17954.5801 - val_loss: 842867968.0000 - val_mae: 20061.1465\n",
            "Epoch 419/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1050839936.0000 - mae: 17983.5312 - val_loss: 838409664.0000 - val_mae: 20158.9824\n",
            "Epoch 420/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1051564800.0000 - mae: 18005.7891 - val_loss: 838138496.0000 - val_mae: 20142.1875\n",
            "Epoch 421/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1050142528.0000 - mae: 17985.6797 - val_loss: 838009792.0000 - val_mae: 20109.9473\n",
            "Epoch 422/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1048515712.0000 - mae: 18007.6523 - val_loss: 836321024.0000 - val_mae: 20137.0000\n",
            "Epoch 423/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1048923136.0000 - mae: 17982.2090 - val_loss: 837057472.0000 - val_mae: 20112.1504\n",
            "Epoch 424/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1046889600.0000 - mae: 17979.8438 - val_loss: 835871808.0000 - val_mae: 20115.2148\n",
            "Epoch 425/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1045752704.0000 - mae: 17967.9004 - val_loss: 835585216.0000 - val_mae: 20101.6113\n",
            "Epoch 426/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1046626560.0000 - mae: 17940.2520 - val_loss: 834603968.0000 - val_mae: 20098.8867\n",
            "Epoch 427/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1045120000.0000 - mae: 18000.5996 - val_loss: 833759936.0000 - val_mae: 20138.7207\n",
            "Epoch 428/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1044279104.0000 - mae: 17946.0938 - val_loss: 834787840.0000 - val_mae: 20058.1055\n",
            "Epoch 429/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1043329728.0000 - mae: 17937.4316 - val_loss: 834858496.0000 - val_mae: 20038.1777\n",
            "Epoch 430/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1042001728.0000 - mae: 17899.8145 - val_loss: 834136576.0000 - val_mae: 20049.6484\n",
            "Epoch 431/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1041590016.0000 - mae: 17919.5742 - val_loss: 834127040.0000 - val_mae: 20039.1094\n",
            "Epoch 432/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1041076544.0000 - mae: 17891.7422 - val_loss: 833873664.0000 - val_mae: 20023.4473\n",
            "Epoch 433/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1039198144.0000 - mae: 17916.7852 - val_loss: 831719872.0000 - val_mae: 20084.2930\n",
            "Epoch 434/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1040942592.0000 - mae: 17963.7930 - val_loss: 828930368.0000 - val_mae: 20127.3965\n",
            "Epoch 435/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1037224768.0000 - mae: 17933.4434 - val_loss: 830367040.0000 - val_mae: 20064.9902\n",
            "Epoch 436/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1036780736.0000 - mae: 17920.9453 - val_loss: 830601472.0000 - val_mae: 20039.4004\n",
            "Epoch 437/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1035486080.0000 - mae: 17888.3730 - val_loss: 829883200.0000 - val_mae: 20028.4551\n",
            "Epoch 438/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1034828288.0000 - mae: 17875.5430 - val_loss: 830366656.0000 - val_mae: 20003.2656\n",
            "Epoch 439/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1035224256.0000 - mae: 17852.8145 - val_loss: 829962752.0000 - val_mae: 19992.6328\n",
            "Epoch 440/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1034534272.0000 - mae: 17871.8809 - val_loss: 829215424.0000 - val_mae: 19993.8418\n",
            "Epoch 441/1000\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1033323072.0000 - mae: 17866.5469 - val_loss: 827827456.0000 - val_mae: 20022.5527\n",
            "Epoch 442/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1031976768.0000 - mae: 17893.2031 - val_loss: 827175616.0000 - val_mae: 20025.2949\n",
            "Epoch 443/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1032008064.0000 - mae: 17896.4043 - val_loss: 826306304.0000 - val_mae: 20017.8145\n",
            "Epoch 444/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1030171712.0000 - mae: 17865.4043 - val_loss: 827255360.0000 - val_mae: 19987.7793\n",
            "Epoch 445/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1030847616.0000 - mae: 17844.6602 - val_loss: 826458688.0000 - val_mae: 19986.4551\n",
            "Epoch 446/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1031220736.0000 - mae: 17850.5352 - val_loss: 825357184.0000 - val_mae: 19995.3555\n",
            "Epoch 447/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1028712576.0000 - mae: 17794.4434 - val_loss: 827683520.0000 - val_mae: 19911.3789\n",
            "Epoch 448/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1027366208.0000 - mae: 17803.9980 - val_loss: 826356544.0000 - val_mae: 19951.5625\n",
            "Epoch 449/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1029133120.0000 - mae: 17816.5254 - val_loss: 826596032.0000 - val_mae: 19928.6660\n",
            "Epoch 450/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1027008000.0000 - mae: 17830.5625 - val_loss: 824389824.0000 - val_mae: 19974.0098\n",
            "Epoch 451/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1027257216.0000 - mae: 17871.6035 - val_loss: 824124224.0000 - val_mae: 19963.5938\n",
            "Epoch 452/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1025707072.0000 - mae: 17900.9980 - val_loss: 822159040.0000 - val_mae: 20032.6504\n",
            "Epoch 453/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1023799936.0000 - mae: 17875.8301 - val_loss: 821277120.0000 - val_mae: 20010.5352\n",
            "Epoch 454/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1022078336.0000 - mae: 17837.4961 - val_loss: 823803904.0000 - val_mae: 19940.3906\n",
            "Epoch 455/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1021306048.0000 - mae: 17791.2422 - val_loss: 823856064.0000 - val_mae: 19906.9121\n",
            "Epoch 456/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1021356800.0000 - mae: 17789.6562 - val_loss: 822946112.0000 - val_mae: 19926.5645\n",
            "Epoch 457/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1021456384.0000 - mae: 17789.8691 - val_loss: 822971584.0000 - val_mae: 19914.2852\n",
            "Epoch 458/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1019910080.0000 - mae: 17801.8223 - val_loss: 822454144.0000 - val_mae: 19927.3418\n",
            "Epoch 459/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1019913344.0000 - mae: 17744.5078 - val_loss: 823694592.0000 - val_mae: 19862.7539\n",
            "Epoch 460/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1017068032.0000 - mae: 17749.4121 - val_loss: 821384576.0000 - val_mae: 19909.6191\n",
            "Epoch 461/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1019421888.0000 - mae: 17915.1875 - val_loss: 818047424.0000 - val_mae: 20021.6074\n",
            "Epoch 462/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1015938816.0000 - mae: 17816.7695 - val_loss: 818931904.0000 - val_mae: 19954.3105\n",
            "Epoch 463/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1015587072.0000 - mae: 17808.1602 - val_loss: 817587520.0000 - val_mae: 19967.2598\n",
            "Epoch 464/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1014974592.0000 - mae: 17802.9355 - val_loss: 817105216.0000 - val_mae: 19956.8516\n",
            "Epoch 465/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1013822976.0000 - mae: 17802.5449 - val_loss: 817169920.0000 - val_mae: 19955.9160\n",
            "Epoch 466/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1015968448.0000 - mae: 17761.8750 - val_loss: 818523840.0000 - val_mae: 19891.1055\n",
            "Epoch 467/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1015010432.0000 - mae: 17803.7578 - val_loss: 815131584.0000 - val_mae: 19983.6406\n",
            "Epoch 468/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1011585600.0000 - mae: 17778.8770 - val_loss: 816405120.0000 - val_mae: 19937.5410\n",
            "Epoch 469/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1014117184.0000 - mae: 17842.1016 - val_loss: 814524736.0000 - val_mae: 19951.8809\n",
            "Epoch 470/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1010310848.0000 - mae: 17740.5625 - val_loss: 817445376.0000 - val_mae: 19850.3457\n",
            "Epoch 471/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1010666560.0000 - mae: 17720.3379 - val_loss: 814737280.0000 - val_mae: 19898.2656\n",
            "Epoch 472/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1008982720.0000 - mae: 17767.2070 - val_loss: 814237504.0000 - val_mae: 19905.0996\n",
            "Epoch 473/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1007987520.0000 - mae: 17744.2285 - val_loss: 813341696.0000 - val_mae: 19911.6582\n",
            "Epoch 474/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1007968192.0000 - mae: 17766.0547 - val_loss: 812123776.0000 - val_mae: 19924.9277\n",
            "Epoch 475/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1006578368.0000 - mae: 17750.1992 - val_loss: 812194944.0000 - val_mae: 19898.3457\n",
            "Epoch 476/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1008283456.0000 - mae: 17733.4961 - val_loss: 812313664.0000 - val_mae: 19889.4980\n",
            "Epoch 477/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1006167296.0000 - mae: 17743.9336 - val_loss: 812275200.0000 - val_mae: 19877.0410\n",
            "Epoch 478/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1005643008.0000 - mae: 17709.1953 - val_loss: 811731456.0000 - val_mae: 19883.7773\n",
            "Epoch 479/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1004263808.0000 - mae: 17700.7480 - val_loss: 812743232.0000 - val_mae: 19846.8477\n",
            "Epoch 480/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1006638912.0000 - mae: 17678.0586 - val_loss: 813279744.0000 - val_mae: 19806.5273\n",
            "Epoch 481/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1001567360.0000 - mae: 17720.9785 - val_loss: 810305536.0000 - val_mae: 19892.8789\n",
            "Epoch 482/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1001334592.0000 - mae: 17750.3906 - val_loss: 808680960.0000 - val_mae: 19870.9629\n",
            "Epoch 483/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1001730880.0000 - mae: 17676.2734 - val_loss: 809578816.0000 - val_mae: 19826.6973\n",
            "Epoch 484/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1001702976.0000 - mae: 17733.1445 - val_loss: 807631424.0000 - val_mae: 19895.0371\n",
            "Epoch 485/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 999637568.0000 - mae: 17699.5605 - val_loss: 808991040.0000 - val_mae: 19813.2637\n",
            "Epoch 486/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 1000299264.0000 - mae: 17709.5469 - val_loss: 807627968.0000 - val_mae: 19836.7637\n",
            "Epoch 487/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 998807936.0000 - mae: 17725.3359 - val_loss: 807801344.0000 - val_mae: 19838.4219\n",
            "Epoch 488/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 997804544.0000 - mae: 17701.5742 - val_loss: 808154048.0000 - val_mae: 19811.9004\n",
            "Epoch 489/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 996844480.0000 - mae: 17681.4062 - val_loss: 807554624.0000 - val_mae: 19805.3633\n",
            "Epoch 490/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 995997568.0000 - mae: 17654.5566 - val_loss: 807376832.0000 - val_mae: 19790.8926\n",
            "Epoch 491/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 994913920.0000 - mae: 17662.6270 - val_loss: 806623616.0000 - val_mae: 19812.4883\n",
            "Epoch 492/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 997171200.0000 - mae: 17732.6895 - val_loss: 805484288.0000 - val_mae: 19831.2129\n",
            "Epoch 493/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 995824000.0000 - mae: 17730.6895 - val_loss: 803301504.0000 - val_mae: 19861.1641\n",
            "Epoch 494/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 995044736.0000 - mae: 17649.8203 - val_loss: 806162944.0000 - val_mae: 19774.7480\n",
            "Epoch 495/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 993244800.0000 - mae: 17649.0176 - val_loss: 805475648.0000 - val_mae: 19776.8301\n",
            "Epoch 496/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 991667008.0000 - mae: 17645.2832 - val_loss: 805909440.0000 - val_mae: 19762.5742\n",
            "Epoch 497/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 991034432.0000 - mae: 17619.4727 - val_loss: 804224320.0000 - val_mae: 19772.9102\n",
            "Epoch 498/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 990117888.0000 - mae: 17663.3281 - val_loss: 803821824.0000 - val_mae: 19797.2891\n",
            "Epoch 499/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 989717824.0000 - mae: 17695.7227 - val_loss: 802862080.0000 - val_mae: 19827.9844\n",
            "Epoch 500/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 989988480.0000 - mae: 17648.0996 - val_loss: 803604992.0000 - val_mae: 19762.1797\n",
            "Epoch 501/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 989658176.0000 - mae: 17678.6094 - val_loss: 802439744.0000 - val_mae: 19797.4688\n",
            "Epoch 502/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 986885120.0000 - mae: 17622.6465 - val_loss: 804901312.0000 - val_mae: 19715.4844\n",
            "Epoch 503/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 987324736.0000 - mae: 17593.6934 - val_loss: 805527040.0000 - val_mae: 19688.2246\n",
            "Epoch 504/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 989362560.0000 - mae: 17622.5273 - val_loss: 802072896.0000 - val_mae: 19766.1699\n",
            "Epoch 505/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 984824000.0000 - mae: 17600.0605 - val_loss: 804062912.0000 - val_mae: 19705.5742\n",
            "Epoch 506/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 985125184.0000 - mae: 17586.9922 - val_loss: 803683968.0000 - val_mae: 19707.1855\n",
            "Epoch 507/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 985163968.0000 - mae: 17586.5605 - val_loss: 802852992.0000 - val_mae: 19718.5781\n",
            "Epoch 508/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 984091392.0000 - mae: 17624.2148 - val_loss: 800822208.0000 - val_mae: 19747.8418\n",
            "Epoch 509/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 984505024.0000 - mae: 17577.5488 - val_loss: 801733888.0000 - val_mae: 19711.3457\n",
            "Epoch 510/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 982363968.0000 - mae: 17618.7969 - val_loss: 800504128.0000 - val_mae: 19731.2031\n",
            "Epoch 511/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 983512512.0000 - mae: 17574.9160 - val_loss: 801245568.0000 - val_mae: 19706.4961\n",
            "Epoch 512/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 982669504.0000 - mae: 17627.5449 - val_loss: 797916800.0000 - val_mae: 19805.9316\n",
            "Epoch 513/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 979849280.0000 - mae: 17633.5801 - val_loss: 799724864.0000 - val_mae: 19723.7148\n",
            "Epoch 514/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 979833408.0000 - mae: 17572.0508 - val_loss: 800532416.0000 - val_mae: 19685.0078\n",
            "Epoch 515/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 979319680.0000 - mae: 17608.7520 - val_loss: 798280064.0000 - val_mae: 19743.0195\n",
            "Epoch 516/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 978521856.0000 - mae: 17622.0566 - val_loss: 797231104.0000 - val_mae: 19750.6484\n",
            "Epoch 517/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 976764608.0000 - mae: 17602.2734 - val_loss: 797899392.0000 - val_mae: 19714.8340\n",
            "Epoch 518/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 979099840.0000 - mae: 17535.9785 - val_loss: 801238336.0000 - val_mae: 19626.4473\n",
            "Epoch 519/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 975483200.0000 - mae: 17524.9883 - val_loss: 798403840.0000 - val_mae: 19683.7109\n",
            "Epoch 520/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 974860480.0000 - mae: 17579.3047 - val_loss: 797407296.0000 - val_mae: 19709.6602\n",
            "Epoch 521/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 975889408.0000 - mae: 17592.0996 - val_loss: 796656000.0000 - val_mae: 19716.7148\n",
            "Epoch 522/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 977540736.0000 - mae: 17663.9219 - val_loss: 794931840.0000 - val_mae: 19753.6406\n",
            "Epoch 523/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 974954112.0000 - mae: 17527.1133 - val_loss: 797492224.0000 - val_mae: 19658.8535\n",
            "Epoch 524/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 973907712.0000 - mae: 17569.6953 - val_loss: 796259712.0000 - val_mae: 19683.9844\n",
            "Epoch 525/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 972493056.0000 - mae: 17557.9805 - val_loss: 796560704.0000 - val_mae: 19679.0098\n",
            "Epoch 526/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 971447296.0000 - mae: 17541.2910 - val_loss: 796297536.0000 - val_mae: 19648.5254\n",
            "Epoch 527/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 971880960.0000 - mae: 17538.8652 - val_loss: 796435008.0000 - val_mae: 19652.7812\n",
            "Epoch 528/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 971406336.0000 - mae: 17533.6758 - val_loss: 795931072.0000 - val_mae: 19665.9160\n",
            "Epoch 529/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 970458240.0000 - mae: 17539.3789 - val_loss: 795940288.0000 - val_mae: 19672.2090\n",
            "Epoch 530/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 971428544.0000 - mae: 17637.2773 - val_loss: 792768320.0000 - val_mae: 19730.2148\n",
            "Epoch 531/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 970184896.0000 - mae: 17548.1875 - val_loss: 795788416.0000 - val_mae: 19607.1934\n",
            "Epoch 532/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 969983744.0000 - mae: 17615.1250 - val_loss: 791228352.0000 - val_mae: 19792.3047\n",
            "Epoch 533/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 966564672.0000 - mae: 17627.9414 - val_loss: 792062912.0000 - val_mae: 19703.7129\n",
            "Epoch 534/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 967366720.0000 - mae: 17530.7422 - val_loss: 792055808.0000 - val_mae: 19674.4531\n",
            "Epoch 535/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 965926976.0000 - mae: 17550.9531 - val_loss: 793108288.0000 - val_mae: 19662.3496\n",
            "Epoch 536/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 964983552.0000 - mae: 17509.4648 - val_loss: 793265408.0000 - val_mae: 19614.8496\n",
            "Epoch 537/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 966245440.0000 - mae: 17484.1523 - val_loss: 793416192.0000 - val_mae: 19628.8926\n",
            "Epoch 538/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 964235456.0000 - mae: 17507.1172 - val_loss: 792910272.0000 - val_mae: 19630.0332\n",
            "Epoch 539/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 965409536.0000 - mae: 17615.2910 - val_loss: 790443648.0000 - val_mae: 19715.0996\n",
            "Epoch 540/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 966997440.0000 - mae: 17494.2598 - val_loss: 792984512.0000 - val_mae: 19602.1230\n",
            "Epoch 541/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 962246784.0000 - mae: 17546.5117 - val_loss: 790234816.0000 - val_mae: 19683.3223\n",
            "Epoch 542/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 962940416.0000 - mae: 17565.4258 - val_loss: 788973504.0000 - val_mae: 19685.9902\n",
            "Epoch 543/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 960438336.0000 - mae: 17517.3262 - val_loss: 790808000.0000 - val_mae: 19628.3809\n",
            "Epoch 544/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 962342912.0000 - mae: 17557.7793 - val_loss: 790292864.0000 - val_mae: 19629.5078\n",
            "Epoch 545/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 960205312.0000 - mae: 17542.1387 - val_loss: 790896064.0000 - val_mae: 19621.7363\n",
            "Epoch 546/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 959429312.0000 - mae: 17510.4863 - val_loss: 790098880.0000 - val_mae: 19622.8066\n",
            "Epoch 547/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 958279168.0000 - mae: 17498.6133 - val_loss: 789343744.0000 - val_mae: 19609.9980\n",
            "Epoch 548/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 958922368.0000 - mae: 17510.0234 - val_loss: 789401856.0000 - val_mae: 19624.3711\n",
            "Epoch 549/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 957163648.0000 - mae: 17489.3867 - val_loss: 789058240.0000 - val_mae: 19604.7539\n",
            "Epoch 550/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 958367936.0000 - mae: 17447.2285 - val_loss: 790959232.0000 - val_mae: 19542.2715\n",
            "Epoch 551/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 957650112.0000 - mae: 17507.6074 - val_loss: 789718528.0000 - val_mae: 19587.0977\n",
            "Epoch 552/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 955714048.0000 - mae: 17526.0801 - val_loss: 788472192.0000 - val_mae: 19606.4258\n",
            "Epoch 553/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 954075648.0000 - mae: 17473.6719 - val_loss: 789572544.0000 - val_mae: 19559.4824\n",
            "Epoch 554/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 955519936.0000 - mae: 17443.3086 - val_loss: 789242624.0000 - val_mae: 19571.8887\n",
            "Epoch 555/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 955954304.0000 - mae: 17560.4258 - val_loss: 786551936.0000 - val_mae: 19663.5156\n",
            "Epoch 556/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 953183424.0000 - mae: 17479.4492 - val_loss: 788404928.0000 - val_mae: 19560.3223\n",
            "Epoch 557/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 952733760.0000 - mae: 17454.5000 - val_loss: 789104256.0000 - val_mae: 19546.0977\n",
            "Epoch 558/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 952382080.0000 - mae: 17548.0996 - val_loss: 786951040.0000 - val_mae: 19646.7852\n",
            "Epoch 559/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 951017472.0000 - mae: 17497.4688 - val_loss: 786963456.0000 - val_mae: 19577.8750\n",
            "Epoch 560/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 950531648.0000 - mae: 17459.7305 - val_loss: 787436032.0000 - val_mae: 19560.1465\n",
            "Epoch 561/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 951440832.0000 - mae: 17495.1152 - val_loss: 787541888.0000 - val_mae: 19534.1836\n",
            "Epoch 562/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 948469440.0000 - mae: 17462.4160 - val_loss: 785868992.0000 - val_mae: 19574.4961\n",
            "Epoch 563/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 948311808.0000 - mae: 17549.1895 - val_loss: 784392128.0000 - val_mae: 19675.7363\n",
            "Epoch 564/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 949806528.0000 - mae: 17485.1445 - val_loss: 785291840.0000 - val_mae: 19576.8027\n",
            "Epoch 565/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 947343616.0000 - mae: 17474.0547 - val_loss: 785081472.0000 - val_mae: 19587.8008\n",
            "Epoch 566/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 946528576.0000 - mae: 17484.4551 - val_loss: 785103424.0000 - val_mae: 19563.0078\n",
            "Epoch 567/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 946790144.0000 - mae: 17475.1074 - val_loss: 785445568.0000 - val_mae: 19542.9102\n",
            "Epoch 568/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 947482368.0000 - mae: 17557.4648 - val_loss: 782474560.0000 - val_mae: 19663.8535\n",
            "Epoch 569/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 944074752.0000 - mae: 17497.7324 - val_loss: 783734400.0000 - val_mae: 19568.7793\n",
            "Epoch 570/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 944643712.0000 - mae: 17446.2520 - val_loss: 783961024.0000 - val_mae: 19549.6934\n",
            "Epoch 571/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 943584256.0000 - mae: 17462.9062 - val_loss: 783633856.0000 - val_mae: 19556.4219\n",
            "Epoch 572/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 944157824.0000 - mae: 17484.8223 - val_loss: 782249728.0000 - val_mae: 19594.5723\n",
            "Epoch 573/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 945884672.0000 - mae: 17408.0020 - val_loss: 785697280.0000 - val_mae: 19475.0566\n",
            "Epoch 574/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 941327872.0000 - mae: 17469.1113 - val_loss: 782251776.0000 - val_mae: 19597.8750\n",
            "Epoch 575/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 942517952.0000 - mae: 17512.2324 - val_loss: 780692224.0000 - val_mae: 19620.1191\n",
            "Epoch 576/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 943121984.0000 - mae: 17417.2031 - val_loss: 787194752.0000 - val_mae: 19428.0488\n",
            "Epoch 577/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 939571584.0000 - mae: 17407.8652 - val_loss: 783528192.0000 - val_mae: 19505.7559\n",
            "Epoch 578/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 939564672.0000 - mae: 17460.0918 - val_loss: 781633536.0000 - val_mae: 19547.2676\n",
            "Epoch 579/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 938925440.0000 - mae: 17452.4629 - val_loss: 783980160.0000 - val_mae: 19493.5117\n",
            "Epoch 580/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 937762304.0000 - mae: 17415.6445 - val_loss: 783788224.0000 - val_mae: 19485.7891\n",
            "Epoch 581/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 937545664.0000 - mae: 17413.2969 - val_loss: 783331968.0000 - val_mae: 19500.4629\n",
            "Epoch 582/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 938546048.0000 - mae: 17407.9648 - val_loss: 783843456.0000 - val_mae: 19474.8867\n",
            "Epoch 583/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 936873984.0000 - mae: 17412.8398 - val_loss: 783041792.0000 - val_mae: 19501.9824\n",
            "Epoch 584/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 936678528.0000 - mae: 17431.7285 - val_loss: 782965504.0000 - val_mae: 19467.0254\n",
            "Epoch 585/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 936344896.0000 - mae: 17472.1348 - val_loss: 780696256.0000 - val_mae: 19568.2969\n",
            "Epoch 586/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 936132416.0000 - mae: 17428.8770 - val_loss: 783219392.0000 - val_mae: 19436.8438\n",
            "Epoch 587/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 935029312.0000 - mae: 17415.6895 - val_loss: 781521920.0000 - val_mae: 19520.9062\n",
            "Epoch 588/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 934132416.0000 - mae: 17452.4941 - val_loss: 781184512.0000 - val_mae: 19508.4961\n",
            "Epoch 589/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 932557312.0000 - mae: 17422.8594 - val_loss: 781305664.0000 - val_mae: 19483.7129\n",
            "Epoch 590/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 934013184.0000 - mae: 17485.0371 - val_loss: 779871360.0000 - val_mae: 19520.7266\n",
            "Epoch 591/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 932231104.0000 - mae: 17352.7773 - val_loss: 785062592.0000 - val_mae: 19387.7598\n",
            "Epoch 592/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 931675264.0000 - mae: 17355.2520 - val_loss: 783955584.0000 - val_mae: 19405.6680\n",
            "Epoch 593/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 930593152.0000 - mae: 17350.6797 - val_loss: 782592512.0000 - val_mae: 19428.7148\n",
            "Epoch 594/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 930617792.0000 - mae: 17367.2168 - val_loss: 781928320.0000 - val_mae: 19445.7324\n",
            "Epoch 595/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 932159808.0000 - mae: 17475.4863 - val_loss: 781247808.0000 - val_mae: 19470.9668\n",
            "Epoch 596/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 930675904.0000 - mae: 17367.3789 - val_loss: 782457792.0000 - val_mae: 19379.1777\n",
            "Epoch 597/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 929669184.0000 - mae: 17407.3301 - val_loss: 781298688.0000 - val_mae: 19422.9453\n",
            "Epoch 598/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 928533312.0000 - mae: 17377.1035 - val_loss: 781612480.0000 - val_mae: 19430.5645\n",
            "Epoch 599/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 927817024.0000 - mae: 17406.0488 - val_loss: 780102208.0000 - val_mae: 19453.4824\n",
            "Epoch 600/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 927081088.0000 - mae: 17383.7051 - val_loss: 781023040.0000 - val_mae: 19422.2422\n",
            "Epoch 601/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 927883456.0000 - mae: 17424.3164 - val_loss: 779599808.0000 - val_mae: 19455.6719\n",
            "Epoch 602/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 927817088.0000 - mae: 17351.2285 - val_loss: 781060480.0000 - val_mae: 19415.5781\n",
            "Epoch 603/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 925062144.0000 - mae: 17376.6309 - val_loss: 780539200.0000 - val_mae: 19411.9512\n",
            "Epoch 604/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 924633472.0000 - mae: 17404.3926 - val_loss: 779347968.0000 - val_mae: 19465.0391\n",
            "Epoch 605/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 924602752.0000 - mae: 17439.1172 - val_loss: 779217408.0000 - val_mae: 19493.5215\n",
            "Epoch 606/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 923370816.0000 - mae: 17381.2793 - val_loss: 778806720.0000 - val_mae: 19437.5156\n",
            "Epoch 607/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 923893952.0000 - mae: 17358.3633 - val_loss: 780379392.0000 - val_mae: 19388.8281\n",
            "Epoch 608/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 923118400.0000 - mae: 17374.7891 - val_loss: 777949504.0000 - val_mae: 19447.6289\n",
            "Epoch 609/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 922823104.0000 - mae: 17360.1328 - val_loss: 777774912.0000 - val_mae: 19437.1250\n",
            "Epoch 610/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 921511488.0000 - mae: 17391.3770 - val_loss: 777385856.0000 - val_mae: 19449.4766\n",
            "Epoch 611/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 920960128.0000 - mae: 17360.2324 - val_loss: 778898944.0000 - val_mae: 19382.5391\n",
            "Epoch 612/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 922254656.0000 - mae: 17392.6836 - val_loss: 778409664.0000 - val_mae: 19397.6230\n",
            "Epoch 613/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 920164736.0000 - mae: 17359.3730 - val_loss: 778028992.0000 - val_mae: 19424.1055\n",
            "Epoch 614/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 918622848.0000 - mae: 17363.8770 - val_loss: 778312064.0000 - val_mae: 19408.3164\n",
            "Epoch 615/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 919515776.0000 - mae: 17318.4414 - val_loss: 778996480.0000 - val_mae: 19369.1270\n",
            "Epoch 616/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 917788736.0000 - mae: 17333.5879 - val_loss: 778371712.0000 - val_mae: 19388.9180\n",
            "Epoch 617/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 918089216.0000 - mae: 17386.0020 - val_loss: 776840192.0000 - val_mae: 19474.8066\n",
            "Epoch 618/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 917678656.0000 - mae: 17360.3633 - val_loss: 777516736.0000 - val_mae: 19388.1875\n",
            "Epoch 619/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 916070400.0000 - mae: 17338.5547 - val_loss: 777274944.0000 - val_mae: 19404.0586\n",
            "Epoch 620/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 916579008.0000 - mae: 17336.7324 - val_loss: 777508736.0000 - val_mae: 19371.2246\n",
            "Epoch 621/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 915605120.0000 - mae: 17334.1465 - val_loss: 777682624.0000 - val_mae: 19404.4785\n",
            "Epoch 622/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 914801216.0000 - mae: 17321.6445 - val_loss: 777534080.0000 - val_mae: 19351.5781\n",
            "Epoch 623/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 914985216.0000 - mae: 17332.5840 - val_loss: 776970944.0000 - val_mae: 19414.8887\n",
            "Epoch 624/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 913751040.0000 - mae: 17366.9590 - val_loss: 776934528.0000 - val_mae: 19422.0742\n",
            "Epoch 625/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 912932544.0000 - mae: 17354.2012 - val_loss: 776390144.0000 - val_mae: 19391.5117\n",
            "Epoch 626/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 912954880.0000 - mae: 17331.9902 - val_loss: 775564992.0000 - val_mae: 19389.1074\n",
            "Epoch 627/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 914334912.0000 - mae: 17305.0332 - val_loss: 777286016.0000 - val_mae: 19342.0215\n",
            "Epoch 628/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 914442496.0000 - mae: 17378.0586 - val_loss: 774995136.0000 - val_mae: 19424.4844\n",
            "Epoch 629/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 911433344.0000 - mae: 17326.5469 - val_loss: 776058752.0000 - val_mae: 19367.7598\n",
            "Epoch 630/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 912237248.0000 - mae: 17314.3945 - val_loss: 774336768.0000 - val_mae: 19383.0430\n",
            "Epoch 631/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 911008896.0000 - mae: 17317.8770 - val_loss: 776274496.0000 - val_mae: 19352.2441\n",
            "Epoch 632/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 909496896.0000 - mae: 17297.5391 - val_loss: 776491328.0000 - val_mae: 19338.9453\n",
            "Epoch 633/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 909099392.0000 - mae: 17263.3965 - val_loss: 776688960.0000 - val_mae: 19302.4082\n",
            "Epoch 634/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 908733632.0000 - mae: 17302.1855 - val_loss: 775401920.0000 - val_mae: 19373.5137\n",
            "Epoch 635/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 908341632.0000 - mae: 17312.9043 - val_loss: 775610688.0000 - val_mae: 19327.4512\n",
            "Epoch 636/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 909222272.0000 - mae: 17326.2773 - val_loss: 774199872.0000 - val_mae: 19366.6152\n",
            "Epoch 637/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 910271936.0000 - mae: 17281.6914 - val_loss: 776484352.0000 - val_mae: 19295.0801\n",
            "Epoch 638/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 905847296.0000 - mae: 17274.5977 - val_loss: 774538112.0000 - val_mae: 19383.0684\n",
            "Epoch 639/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 906312256.0000 - mae: 17327.8379 - val_loss: 774433664.0000 - val_mae: 19359.7539\n",
            "Epoch 640/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 906144576.0000 - mae: 17301.7578 - val_loss: 774694272.0000 - val_mae: 19319.1406\n",
            "Epoch 641/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 905011584.0000 - mae: 17290.9395 - val_loss: 774105472.0000 - val_mae: 19368.5527\n",
            "Epoch 642/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 905642816.0000 - mae: 17274.7461 - val_loss: 774335872.0000 - val_mae: 19368.7266\n",
            "Epoch 643/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 905124736.0000 - mae: 17347.8086 - val_loss: 772797696.0000 - val_mae: 19435.1875\n",
            "Epoch 644/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 904353024.0000 - mae: 17274.9863 - val_loss: 775518464.0000 - val_mae: 19291.7949\n",
            "Epoch 645/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 905948544.0000 - mae: 17318.9316 - val_loss: 772822976.0000 - val_mae: 19390.1094\n",
            "Epoch 646/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 903440512.0000 - mae: 17275.2520 - val_loss: 773267008.0000 - val_mae: 19341.8340\n",
            "Epoch 647/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 903766272.0000 - mae: 17327.6270 - val_loss: 771573248.0000 - val_mae: 19433.7441\n",
            "Epoch 648/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 900668416.0000 - mae: 17272.5840 - val_loss: 774821632.0000 - val_mae: 19297.8027\n",
            "Epoch 649/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 902460288.0000 - mae: 17310.7871 - val_loss: 773734656.0000 - val_mae: 19351.1270\n",
            "Epoch 650/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 900557632.0000 - mae: 17245.3555 - val_loss: 775629632.0000 - val_mae: 19265.5586\n",
            "Epoch 651/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 899720704.0000 - mae: 17228.2988 - val_loss: 775418112.0000 - val_mae: 19280.5762\n",
            "Epoch 652/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 899163328.0000 - mae: 17262.4629 - val_loss: 773710336.0000 - val_mae: 19326.2656\n",
            "Epoch 653/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 898844224.0000 - mae: 17277.9121 - val_loss: 774230528.0000 - val_mae: 19312.7070\n",
            "Epoch 654/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 899615168.0000 - mae: 17307.8340 - val_loss: 772262016.0000 - val_mae: 19423.5469\n",
            "Epoch 655/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 898433920.0000 - mae: 17344.3184 - val_loss: 772247744.0000 - val_mae: 19393.0488\n",
            "Epoch 656/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 897416000.0000 - mae: 17282.6523 - val_loss: 773247552.0000 - val_mae: 19330.1699\n",
            "Epoch 657/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 897904320.0000 - mae: 17248.1191 - val_loss: 772342528.0000 - val_mae: 19342.5098\n",
            "Epoch 658/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 897001216.0000 - mae: 17261.8105 - val_loss: 772451264.0000 - val_mae: 19343.0410\n",
            "Epoch 659/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 895175808.0000 - mae: 17263.0449 - val_loss: 772733760.0000 - val_mae: 19347.4883\n",
            "Epoch 660/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 895465344.0000 - mae: 17257.0078 - val_loss: 772872832.0000 - val_mae: 19317.6875\n",
            "Epoch 661/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 895528768.0000 - mae: 17295.7910 - val_loss: 771644800.0000 - val_mae: 19348.9668\n",
            "Epoch 662/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 894552960.0000 - mae: 17299.0859 - val_loss: 772116864.0000 - val_mae: 19358.9355\n",
            "Epoch 663/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 894150528.0000 - mae: 17237.1836 - val_loss: 772712640.0000 - val_mae: 19295.8984\n",
            "Epoch 664/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 894690304.0000 - mae: 17260.7871 - val_loss: 771661312.0000 - val_mae: 19315.6914\n",
            "Epoch 665/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 892282624.0000 - mae: 17263.4824 - val_loss: 771197376.0000 - val_mae: 19361.9355\n",
            "Epoch 666/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 893001216.0000 - mae: 17287.2559 - val_loss: 770355968.0000 - val_mae: 19386.7031\n",
            "Epoch 667/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 891890880.0000 - mae: 17250.6934 - val_loss: 771490496.0000 - val_mae: 19312.3281\n",
            "Epoch 668/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 891468800.0000 - mae: 17257.5195 - val_loss: 771512128.0000 - val_mae: 19332.0215\n",
            "Epoch 669/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 890881920.0000 - mae: 17246.3418 - val_loss: 771831872.0000 - val_mae: 19307.7695\n",
            "Epoch 670/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 891589120.0000 - mae: 17253.9668 - val_loss: 771113024.0000 - val_mae: 19327.0625\n",
            "Epoch 671/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 890282304.0000 - mae: 17240.3887 - val_loss: 771884736.0000 - val_mae: 19295.5215\n",
            "Epoch 672/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 889629120.0000 - mae: 17221.7188 - val_loss: 771006528.0000 - val_mae: 19334.3594\n",
            "Epoch 673/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 889939136.0000 - mae: 17241.7090 - val_loss: 771696576.0000 - val_mae: 19291.1094\n",
            "Epoch 674/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 890471552.0000 - mae: 17268.8086 - val_loss: 769318528.0000 - val_mae: 19398.2500\n",
            "Epoch 675/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 887669248.0000 - mae: 17243.1484 - val_loss: 771004096.0000 - val_mae: 19283.2305\n",
            "Epoch 676/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 888850688.0000 - mae: 17267.6660 - val_loss: 770136256.0000 - val_mae: 19356.9219\n",
            "Epoch 677/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 887091136.0000 - mae: 17265.3594 - val_loss: 770718848.0000 - val_mae: 19322.0176\n",
            "Epoch 678/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 886577664.0000 - mae: 17194.5742 - val_loss: 770677824.0000 - val_mae: 19282.6270\n",
            "Epoch 679/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 886730560.0000 - mae: 17215.8555 - val_loss: 770045184.0000 - val_mae: 19316.2910\n",
            "Epoch 680/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 885433600.0000 - mae: 17223.8828 - val_loss: 770215296.0000 - val_mae: 19302.9395\n",
            "Epoch 681/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 885435776.0000 - mae: 17195.3008 - val_loss: 771724864.0000 - val_mae: 19260.8281\n",
            "Epoch 682/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 884939648.0000 - mae: 17200.7480 - val_loss: 770960000.0000 - val_mae: 19309.7148\n",
            "Epoch 683/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 884359744.0000 - mae: 17245.7773 - val_loss: 770281984.0000 - val_mae: 19322.8789\n",
            "Epoch 684/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 883847360.0000 - mae: 17191.3281 - val_loss: 770926848.0000 - val_mae: 19278.7910\n",
            "Epoch 685/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 883359040.0000 - mae: 17189.7988 - val_loss: 770624768.0000 - val_mae: 19266.5176\n",
            "Epoch 686/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 883422784.0000 - mae: 17244.1699 - val_loss: 768881984.0000 - val_mae: 19349.6426\n",
            "Epoch 687/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 881969088.0000 - mae: 17208.2910 - val_loss: 770274432.0000 - val_mae: 19276.0840\n",
            "Epoch 688/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 883102592.0000 - mae: 17166.9102 - val_loss: 770914432.0000 - val_mae: 19271.0273\n",
            "Epoch 689/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 881472128.0000 - mae: 17199.2188 - val_loss: 769511232.0000 - val_mae: 19287.7500\n",
            "Epoch 690/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 882742144.0000 - mae: 17224.3125 - val_loss: 768748992.0000 - val_mae: 19308.1172\n",
            "Epoch 691/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 881233920.0000 - mae: 17182.2383 - val_loss: 769809600.0000 - val_mae: 19261.5957\n",
            "Epoch 692/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 881592128.0000 - mae: 17152.3301 - val_loss: 771455808.0000 - val_mae: 19228.3535\n",
            "Epoch 693/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 882115904.0000 - mae: 17210.8340 - val_loss: 768897856.0000 - val_mae: 19314.6406\n",
            "Epoch 694/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 880115136.0000 - mae: 17167.1348 - val_loss: 770356672.0000 - val_mae: 19225.0684\n",
            "Epoch 695/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 878512960.0000 - mae: 17163.0664 - val_loss: 769586304.0000 - val_mae: 19263.9844\n",
            "Epoch 696/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 879338368.0000 - mae: 17153.5898 - val_loss: 770089600.0000 - val_mae: 19259.8984\n",
            "Epoch 697/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 879953408.0000 - mae: 17239.7031 - val_loss: 768647360.0000 - val_mae: 19307.7812\n",
            "Epoch 698/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 876554048.0000 - mae: 17179.7324 - val_loss: 769586816.0000 - val_mae: 19253.6719\n",
            "Epoch 699/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 877442816.0000 - mae: 17133.1250 - val_loss: 770628416.0000 - val_mae: 19247.3906\n",
            "Epoch 700/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 877118592.0000 - mae: 17147.5430 - val_loss: 770423168.0000 - val_mae: 19261.6895\n",
            "Epoch 701/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 876020736.0000 - mae: 17196.3145 - val_loss: 769444352.0000 - val_mae: 19300.5273\n",
            "Epoch 702/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 875519104.0000 - mae: 17179.9395 - val_loss: 768604864.0000 - val_mae: 19260.9883\n",
            "Epoch 703/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 875381760.0000 - mae: 17123.9180 - val_loss: 769691712.0000 - val_mae: 19216.1094\n",
            "Epoch 704/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 878960960.0000 - mae: 17222.1895 - val_loss: 767262912.0000 - val_mae: 19389.5293\n",
            "Epoch 705/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 874793472.0000 - mae: 17163.5020 - val_loss: 769135168.0000 - val_mae: 19255.7617\n",
            "Epoch 706/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 873481024.0000 - mae: 17147.9258 - val_loss: 767942848.0000 - val_mae: 19265.4570\n",
            "Epoch 707/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 872709760.0000 - mae: 17169.3867 - val_loss: 767976000.0000 - val_mae: 19283.2949\n",
            "Epoch 708/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 873191232.0000 - mae: 17143.4238 - val_loss: 769714176.0000 - val_mae: 19216.5137\n",
            "Epoch 709/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 872133120.0000 - mae: 17122.6074 - val_loss: 768413440.0000 - val_mae: 19285.2109\n",
            "Epoch 710/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 872260736.0000 - mae: 17203.6035 - val_loss: 767321856.0000 - val_mae: 19318.1289\n",
            "Epoch 711/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 870844288.0000 - mae: 17178.8809 - val_loss: 767965568.0000 - val_mae: 19271.5781\n",
            "Epoch 712/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 871850560.0000 - mae: 17124.3594 - val_loss: 769216512.0000 - val_mae: 19226.0156\n",
            "Epoch 713/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 870113600.0000 - mae: 17126.7617 - val_loss: 767577536.0000 - val_mae: 19264.3789\n",
            "Epoch 714/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 870023680.0000 - mae: 17143.6348 - val_loss: 768062080.0000 - val_mae: 19271.0625\n",
            "Epoch 715/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 869210304.0000 - mae: 17137.2910 - val_loss: 768115712.0000 - val_mae: 19229.7031\n",
            "Epoch 716/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 869341056.0000 - mae: 17099.0898 - val_loss: 768368448.0000 - val_mae: 19257.3594\n",
            "Epoch 717/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 868487424.0000 - mae: 17159.8809 - val_loss: 767506752.0000 - val_mae: 19330.4863\n",
            "Epoch 718/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 870636224.0000 - mae: 17142.5625 - val_loss: 768718464.0000 - val_mae: 19226.4824\n",
            "Epoch 719/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 867776000.0000 - mae: 17169.9004 - val_loss: 766818048.0000 - val_mae: 19322.0059\n",
            "Epoch 720/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 869860544.0000 - mae: 17147.9043 - val_loss: 767844608.0000 - val_mae: 19214.6074\n",
            "Epoch 721/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 869533760.0000 - mae: 17140.9844 - val_loss: 767692992.0000 - val_mae: 19230.3398\n",
            "Epoch 722/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 866781696.0000 - mae: 17182.7090 - val_loss: 766717440.0000 - val_mae: 19343.5605\n",
            "Epoch 723/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 867080576.0000 - mae: 17180.8574 - val_loss: 766189504.0000 - val_mae: 19262.5918\n",
            "Epoch 724/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 865509632.0000 - mae: 17177.4590 - val_loss: 765873472.0000 - val_mae: 19322.7012\n",
            "Epoch 725/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 865507456.0000 - mae: 17169.3965 - val_loss: 765431168.0000 - val_mae: 19339.5430\n",
            "Epoch 726/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 864954752.0000 - mae: 17160.3516 - val_loss: 765100928.0000 - val_mae: 19249.6836\n",
            "Epoch 727/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 864790592.0000 - mae: 17104.5449 - val_loss: 766509056.0000 - val_mae: 19225.4375\n",
            "Epoch 728/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 863671872.0000 - mae: 17139.4980 - val_loss: 765466112.0000 - val_mae: 19279.7344\n",
            "Epoch 729/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 862467072.0000 - mae: 17106.5703 - val_loss: 766295424.0000 - val_mae: 19230.1133\n",
            "Epoch 730/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 862534336.0000 - mae: 17099.3965 - val_loss: 767009152.0000 - val_mae: 19214.4746\n",
            "Epoch 731/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 864024064.0000 - mae: 17136.0469 - val_loss: 765752128.0000 - val_mae: 19240.0078\n",
            "Epoch 732/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 861892992.0000 - mae: 17123.5312 - val_loss: 765794816.0000 - val_mae: 19260.8828\n",
            "Epoch 733/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 862978240.0000 - mae: 17166.9297 - val_loss: 765132544.0000 - val_mae: 19285.3984\n",
            "Epoch 734/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 860608448.0000 - mae: 17068.4453 - val_loss: 769389248.0000 - val_mae: 19150.0527\n",
            "Epoch 735/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 862156224.0000 - mae: 17086.7090 - val_loss: 766885376.0000 - val_mae: 19227.4395\n",
            "Epoch 736/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 859457024.0000 - mae: 17069.5703 - val_loss: 768695296.0000 - val_mae: 19181.0664\n",
            "Epoch 737/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 860725888.0000 - mae: 17100.4316 - val_loss: 767200320.0000 - val_mae: 19244.3594\n",
            "Epoch 738/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 859867200.0000 - mae: 17104.2598 - val_loss: 766729600.0000 - val_mae: 19270.2188\n",
            "Epoch 739/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 860799936.0000 - mae: 17057.3906 - val_loss: 768524672.0000 - val_mae: 19179.4668\n",
            "Epoch 740/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 858274496.0000 - mae: 17089.3750 - val_loss: 766408448.0000 - val_mae: 19268.8418\n",
            "Epoch 741/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 857993920.0000 - mae: 17130.2812 - val_loss: 768139520.0000 - val_mae: 19244.3828\n",
            "Epoch 742/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 857977408.0000 - mae: 17043.5957 - val_loss: 771094272.0000 - val_mae: 19139.2344\n",
            "Epoch 743/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 857508736.0000 - mae: 17026.6172 - val_loss: 770422016.0000 - val_mae: 19188.7383\n",
            "Epoch 744/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 857870848.0000 - mae: 17121.0312 - val_loss: 768449088.0000 - val_mae: 19305.1426\n",
            "Epoch 745/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 855901504.0000 - mae: 17124.1016 - val_loss: 768286720.0000 - val_mae: 19250.6699\n",
            "Epoch 746/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 855716992.0000 - mae: 17052.8945 - val_loss: 768762176.0000 - val_mae: 19198.8066\n",
            "Epoch 747/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 856443456.0000 - mae: 17080.9531 - val_loss: 769107584.0000 - val_mae: 19224.7949\n",
            "Epoch 748/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 855154496.0000 - mae: 17083.2441 - val_loss: 767574848.0000 - val_mae: 19259.3203\n",
            "Epoch 749/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 854418368.0000 - mae: 17065.7109 - val_loss: 768699968.0000 - val_mae: 19203.5020\n",
            "Epoch 750/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 853821824.0000 - mae: 17064.7637 - val_loss: 768854528.0000 - val_mae: 19239.4844\n",
            "Epoch 751/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 853095936.0000 - mae: 17066.3477 - val_loss: 767453696.0000 - val_mae: 19227.5234\n",
            "Epoch 752/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 852746176.0000 - mae: 17045.0898 - val_loss: 767969280.0000 - val_mae: 19217.3438\n",
            "Epoch 753/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 853606080.0000 - mae: 17067.1699 - val_loss: 766509632.0000 - val_mae: 19272.7969\n",
            "Epoch 754/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 851960448.0000 - mae: 17051.8496 - val_loss: 767794944.0000 - val_mae: 19189.7246\n",
            "Epoch 755/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 850682752.0000 - mae: 17063.8340 - val_loss: 767024192.0000 - val_mae: 19268.3965\n",
            "Epoch 756/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 851315840.0000 - mae: 17095.2734 - val_loss: 766167232.0000 - val_mae: 19249.8535\n",
            "Epoch 757/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 851451584.0000 - mae: 17079.5898 - val_loss: 766517120.0000 - val_mae: 19269.1211\n",
            "Epoch 758/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 851116864.0000 - mae: 17059.6406 - val_loss: 767637888.0000 - val_mae: 19216.9844\n",
            "Epoch 759/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 849927680.0000 - mae: 17057.8730 - val_loss: 767240832.0000 - val_mae: 19218.8438\n",
            "Epoch 760/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 849379840.0000 - mae: 17062.1426 - val_loss: 766906752.0000 - val_mae: 19242.2324\n",
            "Epoch 761/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 849340544.0000 - mae: 17053.0078 - val_loss: 767416384.0000 - val_mae: 19215.5078\n",
            "Epoch 762/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 848731648.0000 - mae: 17026.8750 - val_loss: 767379776.0000 - val_mae: 19214.6797\n",
            "Epoch 763/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 851057088.0000 - mae: 17082.3145 - val_loss: 766035456.0000 - val_mae: 19261.1094\n",
            "Epoch 764/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 847903872.0000 - mae: 17053.2852 - val_loss: 767105536.0000 - val_mae: 19205.9648\n",
            "Epoch 765/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 847987648.0000 - mae: 17008.6855 - val_loss: 768032832.0000 - val_mae: 19184.3203\n",
            "Epoch 766/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 848957632.0000 - mae: 17044.3145 - val_loss: 767898496.0000 - val_mae: 19200.7344\n",
            "Epoch 767/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 847558848.0000 - mae: 17066.0117 - val_loss: 767422656.0000 - val_mae: 19229.0742\n",
            "Epoch 768/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 846718848.0000 - mae: 17018.9805 - val_loss: 768059392.0000 - val_mae: 19187.9453\n",
            "Epoch 769/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 847535552.0000 - mae: 17083.5703 - val_loss: 766619200.0000 - val_mae: 19277.1270\n",
            "Epoch 770/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 846868416.0000 - mae: 17022.1758 - val_loss: 766792768.0000 - val_mae: 19199.3828\n",
            "Epoch 771/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 844669824.0000 - mae: 17023.9297 - val_loss: 766965504.0000 - val_mae: 19251.5195\n",
            "Epoch 772/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 844915008.0000 - mae: 17076.4473 - val_loss: 766286592.0000 - val_mae: 19309.7285\n",
            "Epoch 773/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 845216000.0000 - mae: 17034.8379 - val_loss: 767426944.0000 - val_mae: 19183.5234\n",
            "Epoch 774/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 844213632.0000 - mae: 17043.7012 - val_loss: 766473984.0000 - val_mae: 19264.9297\n",
            "Epoch 775/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 844061440.0000 - mae: 17030.0508 - val_loss: 765621952.0000 - val_mae: 19263.6758\n",
            "Epoch 776/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 846504640.0000 - mae: 16998.7324 - val_loss: 767979392.0000 - val_mae: 19162.7930\n",
            "Epoch 777/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 841951360.0000 - mae: 17001.1523 - val_loss: 765601344.0000 - val_mae: 19243.7617\n",
            "Epoch 778/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 842346752.0000 - mae: 17069.4414 - val_loss: 765787072.0000 - val_mae: 19271.2695\n",
            "Epoch 779/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 841782848.0000 - mae: 17036.2578 - val_loss: 766032832.0000 - val_mae: 19220.5273\n",
            "Epoch 780/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 842174784.0000 - mae: 17025.3145 - val_loss: 766234048.0000 - val_mae: 19248.9531\n",
            "Epoch 781/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 841652416.0000 - mae: 17050.4727 - val_loss: 765034944.0000 - val_mae: 19259.2090\n",
            "Epoch 782/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 840692992.0000 - mae: 17037.4199 - val_loss: 764877440.0000 - val_mae: 19228.5703\n",
            "Epoch 783/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 839885824.0000 - mae: 17009.0605 - val_loss: 765455616.0000 - val_mae: 19187.7812\n",
            "Epoch 784/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 841364352.0000 - mae: 16983.7773 - val_loss: 766606016.0000 - val_mae: 19187.2246\n",
            "Epoch 785/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 840120256.0000 - mae: 17009.2344 - val_loss: 765541568.0000 - val_mae: 19231.4258\n",
            "Epoch 786/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 838960960.0000 - mae: 17015.5234 - val_loss: 765557312.0000 - val_mae: 19210.5664\n",
            "Epoch 787/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 838272960.0000 - mae: 17007.4902 - val_loss: 765839872.0000 - val_mae: 19233.2363\n",
            "Epoch 788/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 838150208.0000 - mae: 17055.1602 - val_loss: 764810496.0000 - val_mae: 19307.5371\n",
            "Epoch 789/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 838274688.0000 - mae: 17019.1973 - val_loss: 764938048.0000 - val_mae: 19252.1523\n",
            "Epoch 790/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 837174720.0000 - mae: 17004.3359 - val_loss: 765117376.0000 - val_mae: 19232.4277\n",
            "Epoch 791/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 836646464.0000 - mae: 17000.5430 - val_loss: 765211456.0000 - val_mae: 19195.8848\n",
            "Epoch 792/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 836789504.0000 - mae: 17005.5254 - val_loss: 764537728.0000 - val_mae: 19242.3164\n",
            "Epoch 793/1000\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 836094144.0000 - mae: 16999.8633 - val_loss: 765567808.0000 - val_mae: 19205.3340\n",
            "Epoch 794/1000\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 836121600.0000 - mae: 16994.6270 - val_loss: 765544768.0000 - val_mae: 19210.1328\n",
            "Epoch 795/1000\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 838411200.0000 - mae: 17047.6523 - val_loss: 764702720.0000 - val_mae: 19221.2500\n",
            "Epoch 796/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 835150784.0000 - mae: 16973.6250 - val_loss: 766261952.0000 - val_mae: 19169.5781\n",
            "Epoch 797/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 834737984.0000 - mae: 16986.9688 - val_loss: 765254848.0000 - val_mae: 19219.5273\n",
            "Epoch 798/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 835301376.0000 - mae: 17005.1250 - val_loss: 763941504.0000 - val_mae: 19250.7793\n",
            "Epoch 799/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 834394176.0000 - mae: 16961.6934 - val_loss: 765625984.0000 - val_mae: 19164.0605\n",
            "Epoch 800/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 833601344.0000 - mae: 16984.2188 - val_loss: 764872384.0000 - val_mae: 19226.0215\n",
            "Epoch 801/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 835598464.0000 - mae: 16994.6367 - val_loss: 764422848.0000 - val_mae: 19244.7227\n",
            "Epoch 802/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 836547136.0000 - mae: 16985.2559 - val_loss: 767359808.0000 - val_mae: 19181.7129\n",
            "Epoch 803/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 832969792.0000 - mae: 16973.9824 - val_loss: 767107648.0000 - val_mae: 19215.8691\n",
            "Epoch 804/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 832586944.0000 - mae: 16985.9551 - val_loss: 767193024.0000 - val_mae: 19220.7070\n",
            "Epoch 805/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 832442880.0000 - mae: 17028.1816 - val_loss: 765580288.0000 - val_mae: 19279.4492\n",
            "Epoch 806/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 830961600.0000 - mae: 16967.4219 - val_loss: 767837568.0000 - val_mae: 19154.3203\n",
            "Epoch 807/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 830064192.0000 - mae: 16959.8086 - val_loss: 767146496.0000 - val_mae: 19185.3594\n",
            "Epoch 808/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 830172288.0000 - mae: 16978.8301 - val_loss: 766199296.0000 - val_mae: 19212.4082\n",
            "Epoch 809/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 830011520.0000 - mae: 16977.2441 - val_loss: 765702784.0000 - val_mae: 19213.4570\n",
            "Epoch 810/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 830083072.0000 - mae: 16965.9355 - val_loss: 766602304.0000 - val_mae: 19225.5156\n",
            "Epoch 811/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 831238144.0000 - mae: 17022.6133 - val_loss: 766001664.0000 - val_mae: 19240.3711\n",
            "Epoch 812/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 828635200.0000 - mae: 16999.7285 - val_loss: 765484096.0000 - val_mae: 19233.7266\n",
            "Epoch 813/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 827740736.0000 - mae: 16998.0371 - val_loss: 766217728.0000 - val_mae: 19260.0859\n",
            "Epoch 814/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 828757760.0000 - mae: 16975.6152 - val_loss: 766498880.0000 - val_mae: 19195.5215\n",
            "Epoch 815/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 830182848.0000 - mae: 17010.5645 - val_loss: 764887232.0000 - val_mae: 19333.1738\n",
            "Epoch 816/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 826214144.0000 - mae: 16977.2559 - val_loss: 765865216.0000 - val_mae: 19201.9688\n",
            "Epoch 817/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 826058176.0000 - mae: 16947.0059 - val_loss: 765654784.0000 - val_mae: 19199.7754\n",
            "Epoch 818/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 825771584.0000 - mae: 16943.4941 - val_loss: 765888448.0000 - val_mae: 19224.8945\n",
            "Epoch 819/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 825436992.0000 - mae: 16959.2344 - val_loss: 764734912.0000 - val_mae: 19241.0195\n",
            "Epoch 820/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 826106688.0000 - mae: 17013.0469 - val_loss: 764509632.0000 - val_mae: 19266.1641\n",
            "Epoch 821/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 825631296.0000 - mae: 16956.9219 - val_loss: 765990080.0000 - val_mae: 19171.5996\n",
            "Epoch 822/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 825439040.0000 - mae: 16952.4277 - val_loss: 765748288.0000 - val_mae: 19244.6016\n",
            "Epoch 823/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 825038144.0000 - mae: 16939.7324 - val_loss: 765312320.0000 - val_mae: 19208.2168\n",
            "Epoch 824/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 823557952.0000 - mae: 16966.8535 - val_loss: 765007104.0000 - val_mae: 19262.7754\n",
            "Epoch 825/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 823835200.0000 - mae: 16958.8047 - val_loss: 765500928.0000 - val_mae: 19231.8750\n",
            "Epoch 826/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 822770048.0000 - mae: 16955.0000 - val_loss: 764730432.0000 - val_mae: 19270.1348\n",
            "Epoch 827/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 824327168.0000 - mae: 16996.7656 - val_loss: 763880640.0000 - val_mae: 19264.4434\n",
            "Epoch 828/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 824796608.0000 - mae: 16946.7285 - val_loss: 768337024.0000 - val_mae: 19141.7344\n",
            "Epoch 829/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 822817984.0000 - mae: 16937.2793 - val_loss: 766642304.0000 - val_mae: 19222.7715\n",
            "Epoch 830/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 820864128.0000 - mae: 16937.5684 - val_loss: 766393920.0000 - val_mae: 19226.9082\n",
            "Epoch 831/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 820974400.0000 - mae: 16940.6641 - val_loss: 766319360.0000 - val_mae: 19223.4668\n",
            "Epoch 832/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 820848064.0000 - mae: 16949.7539 - val_loss: 766051968.0000 - val_mae: 19259.1133\n",
            "Epoch 833/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 822370624.0000 - mae: 16924.2031 - val_loss: 766605056.0000 - val_mae: 19195.2051\n",
            "Epoch 834/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 819513856.0000 - mae: 16937.4785 - val_loss: 765539008.0000 - val_mae: 19242.9629\n",
            "Epoch 835/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 819386176.0000 - mae: 16938.9238 - val_loss: 765520384.0000 - val_mae: 19237.0410\n",
            "Epoch 836/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 819022592.0000 - mae: 16943.3379 - val_loss: 766243968.0000 - val_mae: 19221.8652\n",
            "Epoch 837/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 819780160.0000 - mae: 16949.8496 - val_loss: 765804032.0000 - val_mae: 19205.2578\n",
            "Epoch 838/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 819267840.0000 - mae: 16919.9121 - val_loss: 764967936.0000 - val_mae: 19210.2871\n",
            "Epoch 839/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 818488640.0000 - mae: 16934.7227 - val_loss: 764988736.0000 - val_mae: 19232.2949\n",
            "Epoch 840/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 818465920.0000 - mae: 16917.5410 - val_loss: 766534464.0000 - val_mae: 19203.1934\n",
            "Epoch 841/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 817278720.0000 - mae: 16929.9453 - val_loss: 765669248.0000 - val_mae: 19222.7031\n",
            "Epoch 842/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 818286912.0000 - mae: 16912.5195 - val_loss: 766083904.0000 - val_mae: 19159.7090\n",
            "Epoch 843/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 816282944.0000 - mae: 16914.8438 - val_loss: 765700736.0000 - val_mae: 19231.2871\n",
            "Epoch 844/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 816431808.0000 - mae: 16932.3965 - val_loss: 765089280.0000 - val_mae: 19244.3516\n",
            "Epoch 845/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 816008064.0000 - mae: 16918.3047 - val_loss: 765188928.0000 - val_mae: 19245.0293\n",
            "Epoch 846/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 815376768.0000 - mae: 16928.9590 - val_loss: 765105664.0000 - val_mae: 19274.3125\n",
            "Epoch 847/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 815142080.0000 - mae: 16927.8301 - val_loss: 764724096.0000 - val_mae: 19249.9395\n",
            "Epoch 848/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 815666688.0000 - mae: 16911.9121 - val_loss: 764842496.0000 - val_mae: 19232.4609\n",
            "Epoch 849/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 814650304.0000 - mae: 16928.2441 - val_loss: 765892928.0000 - val_mae: 19195.8906\n",
            "Epoch 850/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 814728512.0000 - mae: 16892.8066 - val_loss: 766473536.0000 - val_mae: 19183.0977\n",
            "Epoch 851/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 816036736.0000 - mae: 16880.8809 - val_loss: 766674624.0000 - val_mae: 19182.9590\n",
            "Epoch 852/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 812939072.0000 - mae: 16943.0098 - val_loss: 766079488.0000 - val_mae: 19273.3359\n",
            "Epoch 853/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 813743616.0000 - mae: 16930.3809 - val_loss: 765755456.0000 - val_mae: 19215.8535\n",
            "Epoch 854/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 812905984.0000 - mae: 16927.7949 - val_loss: 765067328.0000 - val_mae: 19286.8711\n",
            "Epoch 855/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 812936640.0000 - mae: 16929.0059 - val_loss: 765222592.0000 - val_mae: 19221.0723\n",
            "Epoch 856/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 815352896.0000 - mae: 16901.1328 - val_loss: 766160192.0000 - val_mae: 19140.7695\n",
            "Epoch 857/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 813254720.0000 - mae: 16879.3105 - val_loss: 765227264.0000 - val_mae: 19238.6270\n",
            "Epoch 858/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 810731904.0000 - mae: 16915.6504 - val_loss: 764907200.0000 - val_mae: 19284.8945\n",
            "Epoch 859/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 810985280.0000 - mae: 16908.5430 - val_loss: 764749824.0000 - val_mae: 19257.2441\n",
            "Epoch 860/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 809933696.0000 - mae: 16896.8555 - val_loss: 764297984.0000 - val_mae: 19223.4258\n",
            "Epoch 861/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 811179776.0000 - mae: 16918.4688 - val_loss: 763638208.0000 - val_mae: 19245.9805\n",
            "Epoch 862/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 811178048.0000 - mae: 16866.9395 - val_loss: 764992128.0000 - val_mae: 19168.3223\n",
            "Epoch 863/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 809654464.0000 - mae: 16869.9258 - val_loss: 765233536.0000 - val_mae: 19175.7520\n",
            "Epoch 864/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 811286464.0000 - mae: 16911.8984 - val_loss: 764910656.0000 - val_mae: 19275.2129\n",
            "Epoch 865/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 809594944.0000 - mae: 16882.8867 - val_loss: 766006912.0000 - val_mae: 19172.0566\n",
            "Epoch 866/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 808313664.0000 - mae: 16873.0039 - val_loss: 765234624.0000 - val_mae: 19225.5488\n",
            "Epoch 867/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 807705408.0000 - mae: 16875.9141 - val_loss: 764782464.0000 - val_mae: 19217.8652\n",
            "Epoch 868/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 806893504.0000 - mae: 16870.3398 - val_loss: 764692736.0000 - val_mae: 19208.6445\n",
            "Epoch 869/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 806882176.0000 - mae: 16896.1113 - val_loss: 765081728.0000 - val_mae: 19285.1758\n",
            "Epoch 870/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 806901248.0000 - mae: 16908.1191 - val_loss: 765107648.0000 - val_mae: 19228.7012\n",
            "Epoch 871/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 806016512.0000 - mae: 16879.7949 - val_loss: 764411136.0000 - val_mae: 19259.2383\n",
            "Epoch 872/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 808250560.0000 - mae: 16875.1875 - val_loss: 765230272.0000 - val_mae: 19190.2012\n",
            "Epoch 873/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 805754688.0000 - mae: 16880.8535 - val_loss: 763897408.0000 - val_mae: 19218.4395\n",
            "Epoch 874/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 805385728.0000 - mae: 16914.1035 - val_loss: 763186752.0000 - val_mae: 19277.9922\n",
            "Epoch 875/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 807470016.0000 - mae: 16861.9082 - val_loss: 764922240.0000 - val_mae: 19178.1621\n",
            "Epoch 876/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 805004928.0000 - mae: 16895.2891 - val_loss: 763494016.0000 - val_mae: 19271.5508\n",
            "Epoch 877/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 806636928.0000 - mae: 16852.1621 - val_loss: 766611776.0000 - val_mae: 19161.9707\n",
            "Epoch 878/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 804294336.0000 - mae: 16840.4141 - val_loss: 766867392.0000 - val_mae: 19153.0664\n",
            "Epoch 879/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 803603136.0000 - mae: 16840.6719 - val_loss: 766491456.0000 - val_mae: 19206.2246\n",
            "Epoch 880/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 803713728.0000 - mae: 16906.6621 - val_loss: 765340992.0000 - val_mae: 19268.5039\n",
            "Epoch 881/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 802734656.0000 - mae: 16876.8379 - val_loss: 765435648.0000 - val_mae: 19230.6641\n",
            "Epoch 882/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 802637440.0000 - mae: 16847.3594 - val_loss: 764937472.0000 - val_mae: 19233.1543\n",
            "Epoch 883/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 802287424.0000 - mae: 16862.0449 - val_loss: 766100672.0000 - val_mae: 19220.0703\n",
            "Epoch 884/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 801097600.0000 - mae: 16844.0840 - val_loss: 765405568.0000 - val_mae: 19213.2227\n",
            "Epoch 885/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 801521024.0000 - mae: 16875.5312 - val_loss: 764387520.0000 - val_mae: 19275.3125\n",
            "Epoch 886/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 801645056.0000 - mae: 16883.2910 - val_loss: 764483008.0000 - val_mae: 19267.5840\n",
            "Epoch 887/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 800176320.0000 - mae: 16832.3105 - val_loss: 764941568.0000 - val_mae: 19187.7559\n",
            "Epoch 888/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 801363904.0000 - mae: 16846.5742 - val_loss: 764086528.0000 - val_mae: 19240.7910\n",
            "Epoch 889/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 799368512.0000 - mae: 16852.3496 - val_loss: 764984896.0000 - val_mae: 19211.7070\n",
            "Epoch 890/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 802188480.0000 - mae: 16833.0879 - val_loss: 766104064.0000 - val_mae: 19154.6250\n",
            "Epoch 891/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 800949696.0000 - mae: 16878.0117 - val_loss: 764567360.0000 - val_mae: 19279.2773\n",
            "Epoch 892/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 799240768.0000 - mae: 16835.6230 - val_loss: 763992192.0000 - val_mae: 19202.8379\n",
            "Epoch 893/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 799029760.0000 - mae: 16854.0449 - val_loss: 764629440.0000 - val_mae: 19235.5742\n",
            "Epoch 894/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 797992384.0000 - mae: 16826.6406 - val_loss: 764777280.0000 - val_mae: 19211.9531\n",
            "Epoch 895/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 797520896.0000 - mae: 16847.0605 - val_loss: 764751360.0000 - val_mae: 19230.4512\n",
            "Epoch 896/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 799816128.0000 - mae: 16829.2617 - val_loss: 765942336.0000 - val_mae: 19177.7227\n",
            "Epoch 897/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 796309440.0000 - mae: 16820.8867 - val_loss: 764467456.0000 - val_mae: 19273.9473\n",
            "Epoch 898/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 797799040.0000 - mae: 16887.3652 - val_loss: 764124224.0000 - val_mae: 19255.4668\n",
            "Epoch 899/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 796711360.0000 - mae: 16828.8359 - val_loss: 764215872.0000 - val_mae: 19214.0840\n",
            "Epoch 900/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 796981952.0000 - mae: 16830.3516 - val_loss: 763202496.0000 - val_mae: 19257.6016\n",
            "Epoch 901/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 796050880.0000 - mae: 16814.1797 - val_loss: 764913728.0000 - val_mae: 19199.9453\n",
            "Epoch 902/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 796150592.0000 - mae: 16820.4922 - val_loss: 766021120.0000 - val_mae: 19233.2852\n",
            "Epoch 903/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 795762944.0000 - mae: 16849.3398 - val_loss: 764903296.0000 - val_mae: 19263.0332\n",
            "Epoch 904/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 795122048.0000 - mae: 16802.7344 - val_loss: 765312896.0000 - val_mae: 19163.7168\n",
            "Epoch 905/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 794671552.0000 - mae: 16828.9043 - val_loss: 764968576.0000 - val_mae: 19240.2031\n",
            "Epoch 906/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 793617024.0000 - mae: 16829.8770 - val_loss: 765061248.0000 - val_mae: 19229.1035\n",
            "Epoch 907/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 795078592.0000 - mae: 16820.2305 - val_loss: 766085056.0000 - val_mae: 19202.0352\n",
            "Epoch 908/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 794367936.0000 - mae: 16849.9297 - val_loss: 765171648.0000 - val_mae: 19271.7500\n",
            "Epoch 909/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 793234176.0000 - mae: 16802.2637 - val_loss: 765462144.0000 - val_mae: 19200.4238\n",
            "Epoch 910/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 792689408.0000 - mae: 16824.3594 - val_loss: 765687808.0000 - val_mae: 19232.5742\n",
            "Epoch 911/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 796117760.0000 - mae: 16827.7461 - val_loss: 765038464.0000 - val_mae: 19267.6074\n",
            "Epoch 912/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 792275648.0000 - mae: 16811.7617 - val_loss: 766250816.0000 - val_mae: 19201.1406\n",
            "Epoch 913/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 791782016.0000 - mae: 16807.4609 - val_loss: 766399488.0000 - val_mae: 19188.3770\n",
            "Epoch 914/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 793502720.0000 - mae: 16845.5840 - val_loss: 764763648.0000 - val_mae: 19264.7715\n",
            "Epoch 915/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 793390912.0000 - mae: 16810.2031 - val_loss: 765884928.0000 - val_mae: 19197.5879\n",
            "Epoch 916/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 790360256.0000 - mae: 16799.8594 - val_loss: 765516032.0000 - val_mae: 19199.2871\n",
            "Epoch 917/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 790170688.0000 - mae: 16813.1660 - val_loss: 765497856.0000 - val_mae: 19241.3594\n",
            "Epoch 918/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 792458560.0000 - mae: 16780.5254 - val_loss: 766295040.0000 - val_mae: 19182.7285\n",
            "Epoch 919/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 789208064.0000 - mae: 16806.5410 - val_loss: 765644288.0000 - val_mae: 19264.7168\n",
            "Epoch 920/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 788983104.0000 - mae: 16811.8105 - val_loss: 765286848.0000 - val_mae: 19237.7969\n",
            "Epoch 921/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 788955776.0000 - mae: 16816.6992 - val_loss: 764423808.0000 - val_mae: 19242.1602\n",
            "Epoch 922/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 788305344.0000 - mae: 16802.9199 - val_loss: 764640576.0000 - val_mae: 19252.4355\n",
            "Epoch 923/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 787429312.0000 - mae: 16809.2031 - val_loss: 764460736.0000 - val_mae: 19256.4062\n",
            "Epoch 924/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 787939584.0000 - mae: 16807.1680 - val_loss: 763775488.0000 - val_mae: 19234.7695\n",
            "Epoch 925/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 787416512.0000 - mae: 16784.9590 - val_loss: 764139264.0000 - val_mae: 19237.5469\n",
            "Epoch 926/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 788008128.0000 - mae: 16776.3359 - val_loss: 764594240.0000 - val_mae: 19207.5195\n",
            "Epoch 927/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 787282368.0000 - mae: 16772.1426 - val_loss: 764686848.0000 - val_mae: 19193.0879\n",
            "Epoch 928/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 785821504.0000 - mae: 16822.1270 - val_loss: 764774656.0000 - val_mae: 19317.7246\n",
            "Epoch 929/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 786008896.0000 - mae: 16834.2773 - val_loss: 763814720.0000 - val_mae: 19270.4688\n",
            "Epoch 930/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 786279744.0000 - mae: 16782.3672 - val_loss: 763805376.0000 - val_mae: 19203.7578\n",
            "Epoch 931/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 785454656.0000 - mae: 16782.2617 - val_loss: 763939712.0000 - val_mae: 19233.4844\n",
            "Epoch 932/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 787308864.0000 - mae: 16759.1484 - val_loss: 764890496.0000 - val_mae: 19189.7910\n",
            "Epoch 933/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 785867136.0000 - mae: 16808.9492 - val_loss: 764049152.0000 - val_mae: 19257.8145\n",
            "Epoch 934/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 785314432.0000 - mae: 16771.4883 - val_loss: 764677504.0000 - val_mae: 19184.8457\n",
            "Epoch 935/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 784288640.0000 - mae: 16764.5938 - val_loss: 764227136.0000 - val_mae: 19214.8906\n",
            "Epoch 936/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 784703104.0000 - mae: 16794.3828 - val_loss: 762778816.0000 - val_mae: 19243.9258\n",
            "Epoch 937/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 785997760.0000 - mae: 16783.0840 - val_loss: 763841728.0000 - val_mae: 19212.9141\n",
            "Epoch 938/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 783178432.0000 - mae: 16805.8125 - val_loss: 763822464.0000 - val_mae: 19284.1348\n",
            "Epoch 939/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 782408128.0000 - mae: 16796.1914 - val_loss: 763069568.0000 - val_mae: 19242.7852\n",
            "Epoch 940/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 783723200.0000 - mae: 16763.5410 - val_loss: 763985792.0000 - val_mae: 19213.4395\n",
            "Epoch 941/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 782585152.0000 - mae: 16780.9258 - val_loss: 763055424.0000 - val_mae: 19238.0957\n",
            "Epoch 942/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 783407488.0000 - mae: 16782.7363 - val_loss: 763585920.0000 - val_mae: 19175.0820\n",
            "Epoch 943/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 781044928.0000 - mae: 16750.4824 - val_loss: 763209280.0000 - val_mae: 19226.9062\n",
            "Epoch 944/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 782335296.0000 - mae: 16791.4316 - val_loss: 762672128.0000 - val_mae: 19273.9277\n",
            "Epoch 945/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 780125312.0000 - mae: 16760.5488 - val_loss: 763108160.0000 - val_mae: 19210.4375\n",
            "Epoch 946/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 780571328.0000 - mae: 16750.2129 - val_loss: 764395008.0000 - val_mae: 19191.7754\n",
            "Epoch 947/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 780451008.0000 - mae: 16762.6230 - val_loss: 764008256.0000 - val_mae: 19212.2500\n",
            "Epoch 948/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 780492288.0000 - mae: 16775.1523 - val_loss: 763101760.0000 - val_mae: 19239.4961\n",
            "Epoch 949/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 779596672.0000 - mae: 16750.7578 - val_loss: 762568640.0000 - val_mae: 19206.9863\n",
            "Epoch 950/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 778700736.0000 - mae: 16744.2363 - val_loss: 763887872.0000 - val_mae: 19198.2969\n",
            "Epoch 951/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 779553472.0000 - mae: 16765.0488 - val_loss: 762854528.0000 - val_mae: 19213.5488\n",
            "Epoch 952/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 778510976.0000 - mae: 16736.6621 - val_loss: 764135744.0000 - val_mae: 19162.3926\n",
            "Epoch 953/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 778384576.0000 - mae: 16728.4551 - val_loss: 763649728.0000 - val_mae: 19165.5254\n",
            "Epoch 954/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 778571200.0000 - mae: 16776.2500 - val_loss: 763709120.0000 - val_mae: 19231.1367\n",
            "Epoch 955/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 780031552.0000 - mae: 16749.3770 - val_loss: 763982848.0000 - val_mae: 19184.5547\n",
            "Epoch 956/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 777044800.0000 - mae: 16729.1426 - val_loss: 763627072.0000 - val_mae: 19211.5703\n",
            "Epoch 957/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 777055680.0000 - mae: 16758.2148 - val_loss: 763430656.0000 - val_mae: 19240.3770\n",
            "Epoch 958/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 780490560.0000 - mae: 16822.2188 - val_loss: 762585856.0000 - val_mae: 19281.5723\n",
            "Epoch 959/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 781331136.0000 - mae: 16719.9023 - val_loss: 763903424.0000 - val_mae: 19155.7656\n",
            "Epoch 960/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 776844736.0000 - mae: 16800.7637 - val_loss: 763169408.0000 - val_mae: 19286.2480\n",
            "Epoch 961/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 775837184.0000 - mae: 16756.6602 - val_loss: 762749632.0000 - val_mae: 19206.6895\n",
            "Epoch 962/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 777626560.0000 - mae: 16778.1855 - val_loss: 762223168.0000 - val_mae: 19242.8184\n",
            "Epoch 963/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 775301184.0000 - mae: 16742.7188 - val_loss: 762217792.0000 - val_mae: 19229.8047\n",
            "Epoch 964/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 774632384.0000 - mae: 16713.5879 - val_loss: 763095744.0000 - val_mae: 19185.0176\n",
            "Epoch 965/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 775112960.0000 - mae: 16713.9570 - val_loss: 763702464.0000 - val_mae: 19197.0508\n",
            "Epoch 966/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 774505664.0000 - mae: 16726.4297 - val_loss: 763510272.0000 - val_mae: 19226.1348\n",
            "Epoch 967/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 774374080.0000 - mae: 16718.0684 - val_loss: 763280320.0000 - val_mae: 19204.8379\n",
            "Epoch 968/1000\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 773349120.0000 - mae: 16714.5820 - val_loss: 762981952.0000 - val_mae: 19186.7246\n",
            "Epoch 969/1000\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 774640960.0000 - mae: 16711.4023 - val_loss: 763091456.0000 - val_mae: 19192.8809\n",
            "Epoch 970/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 772425856.0000 - mae: 16719.5859 - val_loss: 762171584.0000 - val_mae: 19224.6504\n",
            "Epoch 971/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 775794496.0000 - mae: 16726.6348 - val_loss: 763231168.0000 - val_mae: 19226.5078\n",
            "Epoch 972/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 771637952.0000 - mae: 16740.3516 - val_loss: 762795520.0000 - val_mae: 19242.0664\n",
            "Epoch 973/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 771827648.0000 - mae: 16720.9121 - val_loss: 762325376.0000 - val_mae: 19188.3691\n",
            "Epoch 974/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 771976896.0000 - mae: 16707.9004 - val_loss: 762188672.0000 - val_mae: 19196.3633\n",
            "Epoch 975/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 770960064.0000 - mae: 16719.2910 - val_loss: 762419072.0000 - val_mae: 19201.8711\n",
            "Epoch 976/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 770734336.0000 - mae: 16715.0840 - val_loss: 762217216.0000 - val_mae: 19189.3848\n",
            "Epoch 977/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 771305280.0000 - mae: 16705.3438 - val_loss: 760830464.0000 - val_mae: 19189.4492\n",
            "Epoch 978/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 771255040.0000 - mae: 16692.8125 - val_loss: 763329792.0000 - val_mae: 19134.1035\n",
            "Epoch 979/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 769975104.0000 - mae: 16683.2715 - val_loss: 763449024.0000 - val_mae: 19166.3027\n",
            "Epoch 980/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 769331456.0000 - mae: 16715.9980 - val_loss: 762961344.0000 - val_mae: 19219.2461\n",
            "Epoch 981/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 769229056.0000 - mae: 16716.8438 - val_loss: 762804480.0000 - val_mae: 19184.1270\n",
            "Epoch 982/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 770488832.0000 - mae: 16729.7441 - val_loss: 762103680.0000 - val_mae: 19212.4648\n",
            "Epoch 983/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 769773952.0000 - mae: 16756.0957 - val_loss: 761970240.0000 - val_mae: 19223.2344\n",
            "Epoch 984/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 768303040.0000 - mae: 16707.4141 - val_loss: 761753536.0000 - val_mae: 19198.2832\n",
            "Epoch 985/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 768009536.0000 - mae: 16707.4219 - val_loss: 762538432.0000 - val_mae: 19174.7246\n",
            "Epoch 986/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 767573632.0000 - mae: 16687.3301 - val_loss: 762567744.0000 - val_mae: 19172.8672\n",
            "Epoch 987/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 769217152.0000 - mae: 16736.0215 - val_loss: 762018112.0000 - val_mae: 19209.8105\n",
            "Epoch 988/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 766677696.0000 - mae: 16688.2031 - val_loss: 761945792.0000 - val_mae: 19181.6094\n",
            "Epoch 989/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 768646016.0000 - mae: 16697.4375 - val_loss: 763401280.0000 - val_mae: 19187.5664\n",
            "Epoch 990/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 766665088.0000 - mae: 16722.4395 - val_loss: 763656000.0000 - val_mae: 19208.8184\n",
            "Epoch 991/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 766035776.0000 - mae: 16693.5312 - val_loss: 762673408.0000 - val_mae: 19182.4355\n",
            "Epoch 992/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 765525504.0000 - mae: 16687.5410 - val_loss: 763110400.0000 - val_mae: 19201.1953\n",
            "Epoch 993/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 765565696.0000 - mae: 16689.1758 - val_loss: 763418816.0000 - val_mae: 19191.0078\n",
            "Epoch 994/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 764992192.0000 - mae: 16690.2520 - val_loss: 762963840.0000 - val_mae: 19226.4043\n",
            "Epoch 995/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 764443712.0000 - mae: 16704.2617 - val_loss: 762492160.0000 - val_mae: 19222.3164\n",
            "Epoch 996/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 765642880.0000 - mae: 16679.1445 - val_loss: 763298880.0000 - val_mae: 19190.1406\n",
            "Epoch 997/1000\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 766007360.0000 - mae: 16739.4258 - val_loss: 762517440.0000 - val_mae: 19236.7930\n",
            "Epoch 998/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 763778688.0000 - mae: 16691.0938 - val_loss: 762444032.0000 - val_mae: 19191.3008\n",
            "Epoch 999/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 763274368.0000 - mae: 16674.3340 - val_loss: 762244224.0000 - val_mae: 19187.9043\n",
            "Epoch 1000/1000\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 763922368.0000 - mae: 16664.0215 - val_loss: 762387520.0000 - val_mae: 19171.1270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergl(y=history.history['loss'],\n",
        "                    name='Train'))\n",
        "fig.add_trace(go.Scattergl(y=history.history['val_loss'],\n",
        "                    name='Valid'))\n",
        "fig.update_layout(height=500, width=700,\n",
        "                  xaxis_title='Epoch',\n",
        "                  yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5_sCqEXHUGtq",
        "outputId": "adc66ff9-74ed-45cc-9218-b487b031244f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"8e38a43f-6e39-4033-9403-9d824faa93d8\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8e38a43f-6e39-4033-9403-9d824faa93d8\")) {                    Plotly.newPlot(                        \"8e38a43f-6e39-4033-9403-9d824faa93d8\",                        [{\"name\":\"Train\",\"y\":[39685058560.0,39681732608.0,39672213504.0,39651520512.0,39613923328.0,39551729664.0,39459250176.0,39328985088.0,39155503104.0,38930198528.0,38644809728.0,38295056384.0,37874466816.0,37385089024.0,36811100160.0,36167720960.0,35441287168.0,34636738560.0,33740261376.0,32770197504.0,31729709056.0,30602199040.0,29413847040.0,28172412928.0,26861262848.0,25522769920.0,24140306432.0,22733977600.0,21308973056.0,19880419328.0,18464251904.0,17055075328.0,15683969024.0,14346945536.0,13079038976.0,11855013888.0,10692134912.0,9613779968.0,8611247104.0,7704344064.0,6863136256.0,6130608128.0,5473202176.0,4902282752.0,4395658752.0,3965850624.0,3613607168.0,3295740928.0,3047649280.0,2846365440.0,2683763200.0,2546123776.0,2440450560.0,2362082304.0,2289885440.0,2237263360.0,2194477312.0,2156861952.0,2127857024.0,2102905344.0,2083392512.0,2063045376.0,2048369664.0,2031343872.0,2018280704.0,2004858368.0,1992425344.0,1981538816.0,1970271104.0,1958798336.0,1949184128.0,1938722304.0,1928284032.0,1919236736.0,1910554240.0,1901668096.0,1891511296.0,1882788736.0,1874739968.0,1866724480.0,1859343232.0,1852448128.0,1843680896.0,1836247040.0,1829621632.0,1822966400.0,1814814720.0,1808192512.0,1802131072.0,1796900736.0,1788724864.0,1782622720.0,1775546112.0,1770726016.0,1764312448.0,1757966208.0,1753773824.0,1746891264.0,1740382720.0,1735142016.0,1730427008.0,1723205376.0,1716750336.0,1711894016.0,1707380224.0,1701351936.0,1697201024.0,1691425024.0,1686385152.0,1682097920.0,1675647360.0,1671362816.0,1667617152.0,1662102784.0,1656838272.0,1652261888.0,1647032320.0,1644432384.0,1638912896.0,1634978048.0,1630026752.0,1628633088.0,1620791680.0,1616713472.0,1614965248.0,1606758016.0,1604851968.0,1600050176.0,1598253056.0,1590764544.0,1587315968.0,1584387840.0,1580199680.0,1575739904.0,1572111744.0,1569603968.0,1564999552.0,1561599232.0,1558303104.0,1553285120.0,1551286656.0,1546385664.0,1543079296.0,1538521856.0,1535173248.0,1533351936.0,1529736320.0,1528499968.0,1521187712.0,1517856640.0,1515766784.0,1515410176.0,1509192064.0,1504615680.0,1501895552.0,1497292928.0,1495589888.0,1491524352.0,1488016256.0,1485912320.0,1481811200.0,1479989504.0,1475760512.0,1470813056.0,1468875904.0,1469758976.0,1463402624.0,1460216448.0,1457257088.0,1454293504.0,1454590976.0,1448185088.0,1444895616.0,1443159552.0,1438557568.0,1437451008.0,1433208192.0,1431880064.0,1428669696.0,1423890048.0,1422712960.0,1418989440.0,1418082048.0,1413348864.0,1410167040.0,1407927936.0,1405717376.0,1402720768.0,1398931072.0,1397352704.0,1393751168.0,1391734912.0,1389241600.0,1386243328.0,1384962048.0,1382752896.0,1378888960.0,1375900544.0,1378943488.0,1372023808.0,1371065216.0,1366588288.0,1365641600.0,1362487936.0,1358274048.0,1358674688.0,1358560512.0,1352274176.0,1352573056.0,1348313728.0,1344196096.0,1342003328.0,1341597056.0,1337890176.0,1334986624.0,1332867072.0,1332434048.0,1328608640.0,1326458112.0,1323890688.0,1321756928.0,1324064384.0,1317827072.0,1314852480.0,1312391552.0,1310340096.0,1310297344.0,1306380032.0,1303461248.0,1302897024.0,1302208640.0,1298877952.0,1295620736.0,1293464960.0,1292994560.0,1291243392.0,1287504896.0,1288425984.0,1282815616.0,1281509248.0,1279503616.0,1277322240.0,1275711872.0,1274775808.0,1272158336.0,1270772096.0,1270331776.0,1266011136.0,1269217152.0,1260911744.0,1260536192.0,1259135360.0,1257611648.0,1256486528.0,1253943552.0,1251732992.0,1251495808.0,1249115904.0,1247675136.0,1243941888.0,1243950208.0,1241971328.0,1238898944.0,1240792192.0,1236404096.0,1234227968.0,1233689216.0,1230984832.0,1229452416.0,1226465664.0,1225999744.0,1223646592.0,1224532352.0,1220052608.0,1218829312.0,1218119296.0,1215647872.0,1214787200.0,1213187456.0,1213451776.0,1209228288.0,1209937536.0,1206732672.0,1206016384.0,1203701376.0,1200978560.0,1200750208.0,1199533312.0,1197019520.0,1195887232.0,1194366976.0,1193547136.0,1190619264.0,1190021376.0,1188322944.0,1187894912.0,1187036160.0,1184139136.0,1183683584.0,1181671296.0,1178855040.0,1178476800.0,1177073280.0,1179851392.0,1173375616.0,1172270720.0,1171550592.0,1169629312.0,1168816384.0,1167461120.0,1168149504.0,1165483904.0,1162889216.0,1163687936.0,1160834816.0,1160132608.0,1160249216.0,1158336384.0,1157858176.0,1154449280.0,1153035520.0,1152187776.0,1153357568.0,1149853696.0,1148436480.0,1146283904.0,1146799488.0,1143632384.0,1143002112.0,1142892928.0,1141950080.0,1140201856.0,1139982336.0,1139200768.0,1136310656.0,1134885248.0,1136658944.0,1132092032.0,1131919360.0,1132590464.0,1128948096.0,1129369472.0,1126968832.0,1126210816.0,1124645760.0,1122372608.0,1121678208.0,1123564544.0,1121785344.0,1118459264.0,1117793024.0,1117042688.0,1117000832.0,1120815360.0,1112651648.0,1113228544.0,1110788352.0,1112520320.0,1108575232.0,1111504640.0,1107557376.0,1106630016.0,1104668288.0,1104380160.0,1102849536.0,1105992832.0,1100615552.0,1099252224.0,1099888256.0,1096858496.0,1098433152.0,1097220224.0,1095068288.0,1094445696.0,1095344768.0,1091918464.0,1091226240.0,1089835136.0,1089588352.0,1087081728.0,1090322304.0,1088993280.0,1084040320.0,1085162624.0,1083153664.0,1082197376.0,1081188096.0,1081136512.0,1083124608.0,1078488192.0,1076867200.0,1076191104.0,1075302528.0,1074308736.0,1072526464.0,1072413696.0,1070592192.0,1070054848.0,1070081280.0,1069883200.0,1069607744.0,1065914560.0,1065448000.0,1067729856.0,1064047552.0,1062253056.0,1062036160.0,1061260672.0,1059582656.0,1060961344.0,1061158528.0,1058327424.0,1057289344.0,1055858368.0,1056014976.0,1053613440.0,1053253888.0,1054025920.0,1050839936.0,1051564800.0,1050142528.0,1048515712.0,1048923136.0,1046889600.0,1045752704.0,1046626560.0,1045120000.0,1044279104.0,1043329728.0,1042001728.0,1041590016.0,1041076544.0,1039198144.0,1040942592.0,1037224768.0,1036780736.0,1035486080.0,1034828288.0,1035224256.0,1034534272.0,1033323072.0,1031976768.0,1032008064.0,1030171712.0,1030847616.0,1031220736.0,1028712576.0,1027366208.0,1029133120.0,1027008000.0,1027257216.0,1025707072.0,1023799936.0,1022078336.0,1021306048.0,1021356800.0,1021456384.0,1019910080.0,1019913344.0,1017068032.0,1019421888.0,1015938816.0,1015587072.0,1014974592.0,1013822976.0,1015968448.0,1015010432.0,1011585600.0,1014117184.0,1010310848.0,1010666560.0,1008982720.0,1007987520.0,1007968192.0,1006578368.0,1008283456.0,1006167296.0,1005643008.0,1004263808.0,1006638912.0,1001567360.0,1001334592.0,1001730880.0,1001702976.0,999637568.0,1000299264.0,998807936.0,997804544.0,996844480.0,995997568.0,994913920.0,997171200.0,995824000.0,995044736.0,993244800.0,991667008.0,991034432.0,990117888.0,989717824.0,989988480.0,989658176.0,986885120.0,987324736.0,989362560.0,984824000.0,985125184.0,985163968.0,984091392.0,984505024.0,982363968.0,983512512.0,982669504.0,979849280.0,979833408.0,979319680.0,978521856.0,976764608.0,979099840.0,975483200.0,974860480.0,975889408.0,977540736.0,974954112.0,973907712.0,972493056.0,971447296.0,971880960.0,971406336.0,970458240.0,971428544.0,970184896.0,969983744.0,966564672.0,967366720.0,965926976.0,964983552.0,966245440.0,964235456.0,965409536.0,966997440.0,962246784.0,962940416.0,960438336.0,962342912.0,960205312.0,959429312.0,958279168.0,958922368.0,957163648.0,958367936.0,957650112.0,955714048.0,954075648.0,955519936.0,955954304.0,953183424.0,952733760.0,952382080.0,951017472.0,950531648.0,951440832.0,948469440.0,948311808.0,949806528.0,947343616.0,946528576.0,946790144.0,947482368.0,944074752.0,944643712.0,943584256.0,944157824.0,945884672.0,941327872.0,942517952.0,943121984.0,939571584.0,939564672.0,938925440.0,937762304.0,937545664.0,938546048.0,936873984.0,936678528.0,936344896.0,936132416.0,935029312.0,934132416.0,932557312.0,934013184.0,932231104.0,931675264.0,930593152.0,930617792.0,932159808.0,930675904.0,929669184.0,928533312.0,927817024.0,927081088.0,927883456.0,927817088.0,925062144.0,924633472.0,924602752.0,923370816.0,923893952.0,923118400.0,922823104.0,921511488.0,920960128.0,922254656.0,920164736.0,918622848.0,919515776.0,917788736.0,918089216.0,917678656.0,916070400.0,916579008.0,915605120.0,914801216.0,914985216.0,913751040.0,912932544.0,912954880.0,914334912.0,914442496.0,911433344.0,912237248.0,911008896.0,909496896.0,909099392.0,908733632.0,908341632.0,909222272.0,910271936.0,905847296.0,906312256.0,906144576.0,905011584.0,905642816.0,905124736.0,904353024.0,905948544.0,903440512.0,903766272.0,900668416.0,902460288.0,900557632.0,899720704.0,899163328.0,898844224.0,899615168.0,898433920.0,897416000.0,897904320.0,897001216.0,895175808.0,895465344.0,895528768.0,894552960.0,894150528.0,894690304.0,892282624.0,893001216.0,891890880.0,891468800.0,890881920.0,891589120.0,890282304.0,889629120.0,889939136.0,890471552.0,887669248.0,888850688.0,887091136.0,886577664.0,886730560.0,885433600.0,885435776.0,884939648.0,884359744.0,883847360.0,883359040.0,883422784.0,881969088.0,883102592.0,881472128.0,882742144.0,881233920.0,881592128.0,882115904.0,880115136.0,878512960.0,879338368.0,879953408.0,876554048.0,877442816.0,877118592.0,876020736.0,875519104.0,875381760.0,878960960.0,874793472.0,873481024.0,872709760.0,873191232.0,872133120.0,872260736.0,870844288.0,871850560.0,870113600.0,870023680.0,869210304.0,869341056.0,868487424.0,870636224.0,867776000.0,869860544.0,869533760.0,866781696.0,867080576.0,865509632.0,865507456.0,864954752.0,864790592.0,863671872.0,862467072.0,862534336.0,864024064.0,861892992.0,862978240.0,860608448.0,862156224.0,859457024.0,860725888.0,859867200.0,860799936.0,858274496.0,857993920.0,857977408.0,857508736.0,857870848.0,855901504.0,855716992.0,856443456.0,855154496.0,854418368.0,853821824.0,853095936.0,852746176.0,853606080.0,851960448.0,850682752.0,851315840.0,851451584.0,851116864.0,849927680.0,849379840.0,849340544.0,848731648.0,851057088.0,847903872.0,847987648.0,848957632.0,847558848.0,846718848.0,847535552.0,846868416.0,844669824.0,844915008.0,845216000.0,844213632.0,844061440.0,846504640.0,841951360.0,842346752.0,841782848.0,842174784.0,841652416.0,840692992.0,839885824.0,841364352.0,840120256.0,838960960.0,838272960.0,838150208.0,838274688.0,837174720.0,836646464.0,836789504.0,836094144.0,836121600.0,838411200.0,835150784.0,834737984.0,835301376.0,834394176.0,833601344.0,835598464.0,836547136.0,832969792.0,832586944.0,832442880.0,830961600.0,830064192.0,830172288.0,830011520.0,830083072.0,831238144.0,828635200.0,827740736.0,828757760.0,830182848.0,826214144.0,826058176.0,825771584.0,825436992.0,826106688.0,825631296.0,825439040.0,825038144.0,823557952.0,823835200.0,822770048.0,824327168.0,824796608.0,822817984.0,820864128.0,820974400.0,820848064.0,822370624.0,819513856.0,819386176.0,819022592.0,819780160.0,819267840.0,818488640.0,818465920.0,817278720.0,818286912.0,816282944.0,816431808.0,816008064.0,815376768.0,815142080.0,815666688.0,814650304.0,814728512.0,816036736.0,812939072.0,813743616.0,812905984.0,812936640.0,815352896.0,813254720.0,810731904.0,810985280.0,809933696.0,811179776.0,811178048.0,809654464.0,811286464.0,809594944.0,808313664.0,807705408.0,806893504.0,806882176.0,806901248.0,806016512.0,808250560.0,805754688.0,805385728.0,807470016.0,805004928.0,806636928.0,804294336.0,803603136.0,803713728.0,802734656.0,802637440.0,802287424.0,801097600.0,801521024.0,801645056.0,800176320.0,801363904.0,799368512.0,802188480.0,800949696.0,799240768.0,799029760.0,797992384.0,797520896.0,799816128.0,796309440.0,797799040.0,796711360.0,796981952.0,796050880.0,796150592.0,795762944.0,795122048.0,794671552.0,793617024.0,795078592.0,794367936.0,793234176.0,792689408.0,796117760.0,792275648.0,791782016.0,793502720.0,793390912.0,790360256.0,790170688.0,792458560.0,789208064.0,788983104.0,788955776.0,788305344.0,787429312.0,787939584.0,787416512.0,788008128.0,787282368.0,785821504.0,786008896.0,786279744.0,785454656.0,787308864.0,785867136.0,785314432.0,784288640.0,784703104.0,785997760.0,783178432.0,782408128.0,783723200.0,782585152.0,783407488.0,781044928.0,782335296.0,780125312.0,780571328.0,780451008.0,780492288.0,779596672.0,778700736.0,779553472.0,778510976.0,778384576.0,778571200.0,780031552.0,777044800.0,777055680.0,780490560.0,781331136.0,776844736.0,775837184.0,777626560.0,775301184.0,774632384.0,775112960.0,774505664.0,774374080.0,773349120.0,774640960.0,772425856.0,775794496.0,771637952.0,771827648.0,771976896.0,770960064.0,770734336.0,771305280.0,771255040.0,769975104.0,769331456.0,769229056.0,770488832.0,769773952.0,768303040.0,768009536.0,767573632.0,769217152.0,766677696.0,768646016.0,766665088.0,766035776.0,765525504.0,765565696.0,764992192.0,764443712.0,765642880.0,766007360.0,763778688.0,763274368.0,763922368.0],\"type\":\"scattergl\"},{\"name\":\"Valid\",\"y\":[39713689600.0,39707979776.0,39693369344.0,39664386048.0,39615225856.0,39538978816.0,39427059712.0,39274987520.0,39076270080.0,38822633472.0,38506393600.0,38120742912.0,37664534528.0,37127028736.0,36525211648.0,35836977152.0,35069140992.0,34221361152.0,33297141760.0,32287830016.0,31191465984.0,30045356032.0,28843257856.0,27550148608.0,26224175104.0,24836765696.0,23451764736.0,22025256960.0,20593268736.0,19168563200.0,17753774080.0,16343020544.0,14977058816.0,13675037696.0,12404798464.0,11209111552.0,10095564800.0,9026323456.0,8039577600.0,7134054912.0,6357978112.0,5640355840.0,5005343232.0,4440055808.0,3965748480.0,3554913024.0,3180669184.0,2899933440.0,2662587136.0,2456724992.0,2285106944.0,2158413056.0,2056321152.0,1966965248.0,1901318528.0,1846351360.0,1794193920.0,1754715008.0,1723919872.0,1696911232.0,1665114880.0,1646928384.0,1626026880.0,1611672960.0,1596500352.0,1583296768.0,1570607744.0,1555982592.0,1544447232.0,1535268864.0,1522877568.0,1512141056.0,1504659328.0,1496589824.0,1488067584.0,1478326144.0,1470703232.0,1462300288.0,1453296128.0,1446463104.0,1438109312.0,1429523200.0,1424489344.0,1420770176.0,1412896896.0,1410601344.0,1403857920.0,1398227456.0,1393273600.0,1383826816.0,1380618368.0,1375764992.0,1371143936.0,1366372352.0,1361343360.0,1355085696.0,1348749824.0,1350268672.0,1346354304.0,1339764480.0,1334527232.0,1328822016.0,1326852992.0,1324020992.0,1320859648.0,1316517888.0,1309674368.0,1308515584.0,1304698240.0,1297937408.0,1296466944.0,1293410688.0,1289170944.0,1286380672.0,1285260416.0,1282105600.0,1276638720.0,1275118080.0,1270871808.0,1267568896.0,1264374144.0,1259520768.0,1257536512.0,1257059840.0,1255988224.0,1250528128.0,1245606656.0,1242163968.0,1243904384.0,1236952832.0,1234116224.0,1232738176.0,1229172992.0,1229099008.0,1227425152.0,1224020608.0,1220773376.0,1217915648.0,1219320832.0,1214651648.0,1213987712.0,1209675264.0,1204850688.0,1205250176.0,1203731968.0,1199172480.0,1197107456.0,1199340672.0,1193816832.0,1191717504.0,1190659200.0,1186507776.0,1187232896.0,1182938496.0,1179407104.0,1177395072.0,1176565504.0,1173731072.0,1172294144.0,1168447232.0,1166506112.0,1162214400.0,1160578432.0,1162032512.0,1160299136.0,1159723136.0,1154957952.0,1153258752.0,1152439424.0,1150456064.0,1152187520.0,1147186688.0,1146886784.0,1145392512.0,1141238400.0,1139639936.0,1137507968.0,1137978496.0,1135435904.0,1130254464.0,1126113280.0,1129529856.0,1124235520.0,1125107712.0,1122857344.0,1120739968.0,1117768064.0,1114602496.0,1114155776.0,1110631168.0,1111308544.0,1107813376.0,1106496000.0,1105548544.0,1102268544.0,1104300800.0,1098883456.0,1098439936.0,1093867008.0,1093681152.0,1094164352.0,1089360128.0,1090258816.0,1085517312.0,1084050048.0,1083948928.0,1078022656.0,1078125440.0,1084310016.0,1079596672.0,1076548096.0,1075212288.0,1069104896.0,1073510528.0,1070331200.0,1071755008.0,1065342016.0,1067625152.0,1065319616.0,1061536256.0,1060356096.0,1056829184.0,1055088640.0,1055500288.0,1052339392.0,1050706496.0,1049672512.0,1046507136.0,1046242624.0,1043213504.0,1045309056.0,1042608960.0,1039797312.0,1035920832.0,1033641728.0,1035794432.0,1032930240.0,1032660032.0,1029196736.0,1026748544.0,1025208832.0,1024554432.0,1022922496.0,1021049344.0,1018974784.0,1017433600.0,1017022464.0,1015590528.0,1010986880.0,1013467648.0,1016138112.0,1013660864.0,1009989120.0,1011233600.0,1007806848.0,1005625536.0,1004394240.0,1002256000.0,1003380992.0,999219776.0,999139200.0,998432064.0,992421376.0,992565824.0,988629760.0,990063168.0,986869312.0,987807744.0,986738304.0,984223296.0,982710144.0,980936768.0,980879936.0,978685376.0,978332480.0,976122112.0,975328512.0,971115456.0,970223168.0,970770560.0,969180352.0,969149696.0,968176256.0,966103680.0,965195392.0,963042880.0,963100800.0,958518080.0,962720960.0,961586944.0,958296960.0,958231552.0,955442688.0,954083264.0,953611712.0,949544192.0,950739648.0,948550720.0,945223168.0,945594496.0,945913600.0,943530496.0,943060672.0,937705344.0,940797824.0,939635968.0,939365440.0,937141696.0,934875904.0,933900032.0,934779584.0,930813632.0,931151360.0,932292864.0,930156480.0,926758528.0,925976576.0,926621056.0,921082496.0,923048960.0,923214080.0,920576512.0,919422912.0,919905280.0,917399040.0,917330752.0,914927808.0,915829056.0,914631296.0,912520576.0,914167680.0,911215360.0,908530368.0,911878720.0,908976640.0,908946752.0,903909120.0,906788800.0,905645824.0,905609152.0,903388224.0,900810944.0,898688256.0,899284480.0,898974848.0,896995648.0,895008320.0,891667904.0,894512640.0,893192768.0,892797824.0,892829184.0,889109376.0,891360768.0,888090624.0,887957952.0,886594560.0,886794752.0,884332608.0,884518080.0,882043520.0,882849728.0,880891648.0,879503488.0,880120256.0,875642112.0,878230464.0,876913728.0,875580864.0,874162048.0,873809216.0,874422912.0,870750592.0,870841856.0,872123008.0,870447872.0,867424960.0,867969472.0,868253696.0,865477632.0,862606464.0,866249216.0,863827840.0,864493184.0,861294528.0,861779072.0,860453312.0,863293184.0,857012736.0,861241856.0,858321600.0,857914944.0,857203840.0,855323968.0,855112896.0,855871872.0,853630336.0,852439168.0,851706304.0,848896192.0,849375936.0,850861824.0,849590080.0,850058496.0,848531712.0,847801728.0,846375360.0,847503552.0,845727552.0,843049600.0,846277696.0,842372480.0,844873920.0,842625792.0,840936704.0,842688128.0,840965376.0,842867968.0,838409664.0,838138496.0,838009792.0,836321024.0,837057472.0,835871808.0,835585216.0,834603968.0,833759936.0,834787840.0,834858496.0,834136576.0,834127040.0,833873664.0,831719872.0,828930368.0,830367040.0,830601472.0,829883200.0,830366656.0,829962752.0,829215424.0,827827456.0,827175616.0,826306304.0,827255360.0,826458688.0,825357184.0,827683520.0,826356544.0,826596032.0,824389824.0,824124224.0,822159040.0,821277120.0,823803904.0,823856064.0,822946112.0,822971584.0,822454144.0,823694592.0,821384576.0,818047424.0,818931904.0,817587520.0,817105216.0,817169920.0,818523840.0,815131584.0,816405120.0,814524736.0,817445376.0,814737280.0,814237504.0,813341696.0,812123776.0,812194944.0,812313664.0,812275200.0,811731456.0,812743232.0,813279744.0,810305536.0,808680960.0,809578816.0,807631424.0,808991040.0,807627968.0,807801344.0,808154048.0,807554624.0,807376832.0,806623616.0,805484288.0,803301504.0,806162944.0,805475648.0,805909440.0,804224320.0,803821824.0,802862080.0,803604992.0,802439744.0,804901312.0,805527040.0,802072896.0,804062912.0,803683968.0,802852992.0,800822208.0,801733888.0,800504128.0,801245568.0,797916800.0,799724864.0,800532416.0,798280064.0,797231104.0,797899392.0,801238336.0,798403840.0,797407296.0,796656000.0,794931840.0,797492224.0,796259712.0,796560704.0,796297536.0,796435008.0,795931072.0,795940288.0,792768320.0,795788416.0,791228352.0,792062912.0,792055808.0,793108288.0,793265408.0,793416192.0,792910272.0,790443648.0,792984512.0,790234816.0,788973504.0,790808000.0,790292864.0,790896064.0,790098880.0,789343744.0,789401856.0,789058240.0,790959232.0,789718528.0,788472192.0,789572544.0,789242624.0,786551936.0,788404928.0,789104256.0,786951040.0,786963456.0,787436032.0,787541888.0,785868992.0,784392128.0,785291840.0,785081472.0,785103424.0,785445568.0,782474560.0,783734400.0,783961024.0,783633856.0,782249728.0,785697280.0,782251776.0,780692224.0,787194752.0,783528192.0,781633536.0,783980160.0,783788224.0,783331968.0,783843456.0,783041792.0,782965504.0,780696256.0,783219392.0,781521920.0,781184512.0,781305664.0,779871360.0,785062592.0,783955584.0,782592512.0,781928320.0,781247808.0,782457792.0,781298688.0,781612480.0,780102208.0,781023040.0,779599808.0,781060480.0,780539200.0,779347968.0,779217408.0,778806720.0,780379392.0,777949504.0,777774912.0,777385856.0,778898944.0,778409664.0,778028992.0,778312064.0,778996480.0,778371712.0,776840192.0,777516736.0,777274944.0,777508736.0,777682624.0,777534080.0,776970944.0,776934528.0,776390144.0,775564992.0,777286016.0,774995136.0,776058752.0,774336768.0,776274496.0,776491328.0,776688960.0,775401920.0,775610688.0,774199872.0,776484352.0,774538112.0,774433664.0,774694272.0,774105472.0,774335872.0,772797696.0,775518464.0,772822976.0,773267008.0,771573248.0,774821632.0,773734656.0,775629632.0,775418112.0,773710336.0,774230528.0,772262016.0,772247744.0,773247552.0,772342528.0,772451264.0,772733760.0,772872832.0,771644800.0,772116864.0,772712640.0,771661312.0,771197376.0,770355968.0,771490496.0,771512128.0,771831872.0,771113024.0,771884736.0,771006528.0,771696576.0,769318528.0,771004096.0,770136256.0,770718848.0,770677824.0,770045184.0,770215296.0,771724864.0,770960000.0,770281984.0,770926848.0,770624768.0,768881984.0,770274432.0,770914432.0,769511232.0,768748992.0,769809600.0,771455808.0,768897856.0,770356672.0,769586304.0,770089600.0,768647360.0,769586816.0,770628416.0,770423168.0,769444352.0,768604864.0,769691712.0,767262912.0,769135168.0,767942848.0,767976000.0,769714176.0,768413440.0,767321856.0,767965568.0,769216512.0,767577536.0,768062080.0,768115712.0,768368448.0,767506752.0,768718464.0,766818048.0,767844608.0,767692992.0,766717440.0,766189504.0,765873472.0,765431168.0,765100928.0,766509056.0,765466112.0,766295424.0,767009152.0,765752128.0,765794816.0,765132544.0,769389248.0,766885376.0,768695296.0,767200320.0,766729600.0,768524672.0,766408448.0,768139520.0,771094272.0,770422016.0,768449088.0,768286720.0,768762176.0,769107584.0,767574848.0,768699968.0,768854528.0,767453696.0,767969280.0,766509632.0,767794944.0,767024192.0,766167232.0,766517120.0,767637888.0,767240832.0,766906752.0,767416384.0,767379776.0,766035456.0,767105536.0,768032832.0,767898496.0,767422656.0,768059392.0,766619200.0,766792768.0,766965504.0,766286592.0,767426944.0,766473984.0,765621952.0,767979392.0,765601344.0,765787072.0,766032832.0,766234048.0,765034944.0,764877440.0,765455616.0,766606016.0,765541568.0,765557312.0,765839872.0,764810496.0,764938048.0,765117376.0,765211456.0,764537728.0,765567808.0,765544768.0,764702720.0,766261952.0,765254848.0,763941504.0,765625984.0,764872384.0,764422848.0,767359808.0,767107648.0,767193024.0,765580288.0,767837568.0,767146496.0,766199296.0,765702784.0,766602304.0,766001664.0,765484096.0,766217728.0,766498880.0,764887232.0,765865216.0,765654784.0,765888448.0,764734912.0,764509632.0,765990080.0,765748288.0,765312320.0,765007104.0,765500928.0,764730432.0,763880640.0,768337024.0,766642304.0,766393920.0,766319360.0,766051968.0,766605056.0,765539008.0,765520384.0,766243968.0,765804032.0,764967936.0,764988736.0,766534464.0,765669248.0,766083904.0,765700736.0,765089280.0,765188928.0,765105664.0,764724096.0,764842496.0,765892928.0,766473536.0,766674624.0,766079488.0,765755456.0,765067328.0,765222592.0,766160192.0,765227264.0,764907200.0,764749824.0,764297984.0,763638208.0,764992128.0,765233536.0,764910656.0,766006912.0,765234624.0,764782464.0,764692736.0,765081728.0,765107648.0,764411136.0,765230272.0,763897408.0,763186752.0,764922240.0,763494016.0,766611776.0,766867392.0,766491456.0,765340992.0,765435648.0,764937472.0,766100672.0,765405568.0,764387520.0,764483008.0,764941568.0,764086528.0,764984896.0,766104064.0,764567360.0,763992192.0,764629440.0,764777280.0,764751360.0,765942336.0,764467456.0,764124224.0,764215872.0,763202496.0,764913728.0,766021120.0,764903296.0,765312896.0,764968576.0,765061248.0,766085056.0,765171648.0,765462144.0,765687808.0,765038464.0,766250816.0,766399488.0,764763648.0,765884928.0,765516032.0,765497856.0,766295040.0,765644288.0,765286848.0,764423808.0,764640576.0,764460736.0,763775488.0,764139264.0,764594240.0,764686848.0,764774656.0,763814720.0,763805376.0,763939712.0,764890496.0,764049152.0,764677504.0,764227136.0,762778816.0,763841728.0,763822464.0,763069568.0,763985792.0,763055424.0,763585920.0,763209280.0,762672128.0,763108160.0,764395008.0,764008256.0,763101760.0,762568640.0,763887872.0,762854528.0,764135744.0,763649728.0,763709120.0,763982848.0,763627072.0,763430656.0,762585856.0,763903424.0,763169408.0,762749632.0,762223168.0,762217792.0,763095744.0,763702464.0,763510272.0,763280320.0,762981952.0,763091456.0,762171584.0,763231168.0,762795520.0,762325376.0,762188672.0,762419072.0,762217216.0,760830464.0,763329792.0,763449024.0,762961344.0,762804480.0,762103680.0,761970240.0,761753536.0,762538432.0,762567744.0,762018112.0,761945792.0,763401280.0,763656000.0,762673408.0,763110400.0,763418816.0,762963840.0,762492160.0,763298880.0,762517440.0,762444032.0,762244224.0,762387520.0],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"height\":500,\"width\":700,\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8e38a43f-6e39-4033-9403-9d824faa93d8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=200, validation_split=0.25)"
      ],
      "metadata": {
        "id": "gX-3ScnxZVR7",
        "outputId": "27f4a874-fcc3-4f41-c6f8-b5e7a7d3b443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 763301824.0000 - mae: 16662.0332 - val_loss: 763198656.0000 - val_mae: 19189.0137\n",
            "Epoch 2/200\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 763943488.0000 - mae: 16713.5801 - val_loss: 762896320.0000 - val_mae: 19178.1094\n",
            "Epoch 3/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 763311552.0000 - mae: 16719.9355 - val_loss: 762772864.0000 - val_mae: 19242.4961\n",
            "Epoch 4/200\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 762017536.0000 - mae: 16687.5449 - val_loss: 762822400.0000 - val_mae: 19202.2344\n",
            "Epoch 5/200\n",
            "26/26 [==============================] - 0s 12ms/step - loss: 761501632.0000 - mae: 16662.6367 - val_loss: 763156096.0000 - val_mae: 19163.2773\n",
            "Epoch 6/200\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 762340864.0000 - mae: 16691.0078 - val_loss: 763140224.0000 - val_mae: 19211.0977\n",
            "Epoch 7/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 761332096.0000 - mae: 16684.3594 - val_loss: 763044608.0000 - val_mae: 19196.3848\n",
            "Epoch 8/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 760335872.0000 - mae: 16651.6875 - val_loss: 763350592.0000 - val_mae: 19162.6035\n",
            "Epoch 9/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 760979072.0000 - mae: 16657.6777 - val_loss: 763317312.0000 - val_mae: 19170.2422\n",
            "Epoch 10/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 760177856.0000 - mae: 16666.9766 - val_loss: 762986752.0000 - val_mae: 19208.5430\n",
            "Epoch 11/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 759950656.0000 - mae: 16676.7344 - val_loss: 762823872.0000 - val_mae: 19214.5410\n",
            "Epoch 12/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 759797568.0000 - mae: 16689.0332 - val_loss: 762648640.0000 - val_mae: 19232.3691\n",
            "Epoch 13/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 760067008.0000 - mae: 16675.2734 - val_loss: 763018048.0000 - val_mae: 19175.3789\n",
            "Epoch 14/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 758926144.0000 - mae: 16663.1699 - val_loss: 762625088.0000 - val_mae: 19216.1094\n",
            "Epoch 15/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 758224832.0000 - mae: 16678.8184 - val_loss: 762780160.0000 - val_mae: 19250.8477\n",
            "Epoch 16/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 758295616.0000 - mae: 16676.9590 - val_loss: 761663808.0000 - val_mae: 19215.5391\n",
            "Epoch 17/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 758820160.0000 - mae: 16658.8262 - val_loss: 762539520.0000 - val_mae: 19185.9043\n",
            "Epoch 18/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 758139392.0000 - mae: 16684.3496 - val_loss: 762467008.0000 - val_mae: 19223.0820\n",
            "Epoch 19/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 757646208.0000 - mae: 16677.3105 - val_loss: 761715328.0000 - val_mae: 19229.9238\n",
            "Epoch 20/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 757203008.0000 - mae: 16645.7031 - val_loss: 762324992.0000 - val_mae: 19162.4180\n",
            "Epoch 21/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 757058368.0000 - mae: 16653.9551 - val_loss: 762769408.0000 - val_mae: 19201.4922\n",
            "Epoch 22/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 757271552.0000 - mae: 16658.3730 - val_loss: 762584640.0000 - val_mae: 19228.9551\n",
            "Epoch 23/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 755745344.0000 - mae: 16661.2871 - val_loss: 762406720.0000 - val_mae: 19215.6387\n",
            "Epoch 24/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 755692416.0000 - mae: 16648.2969 - val_loss: 762254464.0000 - val_mae: 19183.8105\n",
            "Epoch 25/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 756541696.0000 - mae: 16631.1719 - val_loss: 763196224.0000 - val_mae: 19173.8438\n",
            "Epoch 26/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 755105600.0000 - mae: 16649.1465 - val_loss: 762425856.0000 - val_mae: 19225.0469\n",
            "Epoch 27/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 755137920.0000 - mae: 16644.7988 - val_loss: 762073856.0000 - val_mae: 19180.5898\n",
            "Epoch 28/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 755078336.0000 - mae: 16649.1191 - val_loss: 761696256.0000 - val_mae: 19225.7793\n",
            "Epoch 29/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 755097408.0000 - mae: 16674.9707 - val_loss: 762528128.0000 - val_mae: 19255.4570\n",
            "Epoch 30/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 754938688.0000 - mae: 16663.4199 - val_loss: 761635904.0000 - val_mae: 19210.9863\n",
            "Epoch 31/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 753754176.0000 - mae: 16632.4922 - val_loss: 761762432.0000 - val_mae: 19202.6367\n",
            "Epoch 32/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 753521216.0000 - mae: 16637.0020 - val_loss: 761889600.0000 - val_mae: 19210.8105\n",
            "Epoch 33/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 753626560.0000 - mae: 16622.2168 - val_loss: 762123008.0000 - val_mae: 19194.3066\n",
            "Epoch 34/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 753776384.0000 - mae: 16672.4219 - val_loss: 762585792.0000 - val_mae: 19245.0312\n",
            "Epoch 35/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 753287488.0000 - mae: 16639.6133 - val_loss: 762084608.0000 - val_mae: 19195.4180\n",
            "Epoch 36/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 752702080.0000 - mae: 16650.9844 - val_loss: 762244864.0000 - val_mae: 19231.5762\n",
            "Epoch 37/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 752297728.0000 - mae: 16626.7520 - val_loss: 762183296.0000 - val_mae: 19192.2168\n",
            "Epoch 38/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 755342016.0000 - mae: 16651.1523 - val_loss: 761733760.0000 - val_mae: 19236.9922\n",
            "Epoch 39/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 751491328.0000 - mae: 16625.3438 - val_loss: 762191360.0000 - val_mae: 19201.3281\n",
            "Epoch 40/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 751576704.0000 - mae: 16622.7383 - val_loss: 761594048.0000 - val_mae: 19190.0605\n",
            "Epoch 41/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 751372864.0000 - mae: 16610.6758 - val_loss: 761012160.0000 - val_mae: 19195.2051\n",
            "Epoch 42/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 750822016.0000 - mae: 16599.7285 - val_loss: 761402816.0000 - val_mae: 19193.8379\n",
            "Epoch 43/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 750961984.0000 - mae: 16606.8340 - val_loss: 762280128.0000 - val_mae: 19210.6035\n",
            "Epoch 44/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 749984576.0000 - mae: 16618.9453 - val_loss: 762065024.0000 - val_mae: 19198.5508\n",
            "Epoch 45/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 749649408.0000 - mae: 16625.0488 - val_loss: 762515264.0000 - val_mae: 19199.4512\n",
            "Epoch 46/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 749585728.0000 - mae: 16634.5781 - val_loss: 761488064.0000 - val_mae: 19202.9297\n",
            "Epoch 47/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 749197440.0000 - mae: 16619.0684 - val_loss: 761478656.0000 - val_mae: 19201.0352\n",
            "Epoch 48/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 749128832.0000 - mae: 16609.4531 - val_loss: 762218112.0000 - val_mae: 19185.1328\n",
            "Epoch 49/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 749930880.0000 - mae: 16614.2441 - val_loss: 761107648.0000 - val_mae: 19221.3398\n",
            "Epoch 50/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 747856704.0000 - mae: 16598.5215 - val_loss: 762101120.0000 - val_mae: 19174.8594\n",
            "Epoch 51/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 748664448.0000 - mae: 16618.6426 - val_loss: 761045184.0000 - val_mae: 19202.4902\n",
            "Epoch 52/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 749059072.0000 - mae: 16602.8965 - val_loss: 762054336.0000 - val_mae: 19209.3535\n",
            "Epoch 53/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 750006080.0000 - mae: 16612.0000 - val_loss: 761498752.0000 - val_mae: 19210.4121\n",
            "Epoch 54/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 748915264.0000 - mae: 16600.8730 - val_loss: 762778368.0000 - val_mae: 19176.6172\n",
            "Epoch 55/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 748194880.0000 - mae: 16606.4023 - val_loss: 762190080.0000 - val_mae: 19163.8828\n",
            "Epoch 56/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 746328448.0000 - mae: 16586.9551 - val_loss: 762072192.0000 - val_mae: 19211.4414\n",
            "Epoch 57/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 746433024.0000 - mae: 16576.8828 - val_loss: 761943296.0000 - val_mae: 19188.0039\n",
            "Epoch 58/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 745813824.0000 - mae: 16588.7051 - val_loss: 761938432.0000 - val_mae: 19194.0469\n",
            "Epoch 59/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 745103936.0000 - mae: 16591.2168 - val_loss: 761728768.0000 - val_mae: 19227.6367\n",
            "Epoch 60/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 745154304.0000 - mae: 16608.9102 - val_loss: 762001216.0000 - val_mae: 19218.1602\n",
            "Epoch 61/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 744825792.0000 - mae: 16596.5820 - val_loss: 761422400.0000 - val_mae: 19215.6562\n",
            "Epoch 62/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 747025984.0000 - mae: 16578.5078 - val_loss: 761804864.0000 - val_mae: 19166.1465\n",
            "Epoch 63/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 744541632.0000 - mae: 16564.9531 - val_loss: 762223040.0000 - val_mae: 19192.2344\n",
            "Epoch 64/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 746250880.0000 - mae: 16620.6855 - val_loss: 761194624.0000 - val_mae: 19246.7637\n",
            "Epoch 65/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 744028864.0000 - mae: 16591.8262 - val_loss: 761681088.0000 - val_mae: 19216.4258\n",
            "Epoch 66/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 743429248.0000 - mae: 16579.5254 - val_loss: 761409152.0000 - val_mae: 19196.5820\n",
            "Epoch 67/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 744149632.0000 - mae: 16599.8594 - val_loss: 760525504.0000 - val_mae: 19239.6230\n",
            "Epoch 68/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 741540224.0000 - mae: 16569.8867 - val_loss: 762143744.0000 - val_mae: 19170.8965\n",
            "Epoch 69/200\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 744115968.0000 - mae: 16588.6426 - val_loss: 763192832.0000 - val_mae: 19199.6523\n",
            "Epoch 70/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 744180928.0000 - mae: 16590.3574 - val_loss: 762337280.0000 - val_mae: 19147.2422\n",
            "Epoch 71/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 741799744.0000 - mae: 16570.0918 - val_loss: 762647744.0000 - val_mae: 19206.2754\n",
            "Epoch 72/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 742098560.0000 - mae: 16601.3262 - val_loss: 762267136.0000 - val_mae: 19245.2891\n",
            "Epoch 73/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 742083968.0000 - mae: 16583.2051 - val_loss: 761463296.0000 - val_mae: 19202.8145\n",
            "Epoch 74/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 741068096.0000 - mae: 16571.3125 - val_loss: 762591232.0000 - val_mae: 19203.5312\n",
            "Epoch 75/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 741662464.0000 - mae: 16583.1953 - val_loss: 762396736.0000 - val_mae: 19219.7207\n",
            "Epoch 76/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 741566528.0000 - mae: 16564.9629 - val_loss: 762343040.0000 - val_mae: 19190.7793\n",
            "Epoch 77/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 740529344.0000 - mae: 16552.7773 - val_loss: 762387840.0000 - val_mae: 19181.4609\n",
            "Epoch 78/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 745872704.0000 - mae: 16659.0352 - val_loss: 762077568.0000 - val_mae: 19293.3184\n",
            "Epoch 79/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 741281472.0000 - mae: 16543.4863 - val_loss: 762607104.0000 - val_mae: 19134.8594\n",
            "Epoch 80/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 740230464.0000 - mae: 16560.6504 - val_loss: 762016896.0000 - val_mae: 19196.1426\n",
            "Epoch 81/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 739294272.0000 - mae: 16557.1953 - val_loss: 761548928.0000 - val_mae: 19199.6016\n",
            "Epoch 82/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 739288704.0000 - mae: 16553.7988 - val_loss: 761273664.0000 - val_mae: 19192.0801\n",
            "Epoch 83/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 739191616.0000 - mae: 16564.4453 - val_loss: 760882176.0000 - val_mae: 19184.5430\n",
            "Epoch 84/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 738751616.0000 - mae: 16574.3418 - val_loss: 761664640.0000 - val_mae: 19218.2422\n",
            "Epoch 85/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 738477568.0000 - mae: 16557.7988 - val_loss: 761619136.0000 - val_mae: 19181.8867\n",
            "Epoch 86/200\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 738278784.0000 - mae: 16552.8633 - val_loss: 760435136.0000 - val_mae: 19207.2930\n",
            "Epoch 87/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 737405120.0000 - mae: 16548.3984 - val_loss: 761414208.0000 - val_mae: 19184.8789\n",
            "Epoch 88/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 741475200.0000 - mae: 16611.3203 - val_loss: 760566656.0000 - val_mae: 19243.2188\n",
            "Epoch 89/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 739156480.0000 - mae: 16534.1992 - val_loss: 761592000.0000 - val_mae: 19162.3535\n",
            "Epoch 90/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 736860672.0000 - mae: 16541.2695 - val_loss: 761726912.0000 - val_mae: 19210.2891\n",
            "Epoch 91/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 736687040.0000 - mae: 16558.9707 - val_loss: 762009408.0000 - val_mae: 19208.0391\n",
            "Epoch 92/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 736433088.0000 - mae: 16562.5176 - val_loss: 761176000.0000 - val_mae: 19259.2832\n",
            "Epoch 93/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 738136960.0000 - mae: 16597.1113 - val_loss: 761047296.0000 - val_mae: 19225.1445\n",
            "Epoch 94/200\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 736824000.0000 - mae: 16574.9785 - val_loss: 761038464.0000 - val_mae: 19211.3535\n",
            "Epoch 95/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 735967296.0000 - mae: 16524.0312 - val_loss: 761464448.0000 - val_mae: 19145.7637\n",
            "Epoch 96/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 735802560.0000 - mae: 16549.4004 - val_loss: 760901760.0000 - val_mae: 19210.6641\n",
            "Epoch 97/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 735562752.0000 - mae: 16535.3496 - val_loss: 761734080.0000 - val_mae: 19185.7559\n",
            "Epoch 98/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 734849920.0000 - mae: 16541.9395 - val_loss: 761189184.0000 - val_mae: 19211.1641\n",
            "Epoch 99/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 736281280.0000 - mae: 16567.0566 - val_loss: 760515328.0000 - val_mae: 19256.9980\n",
            "Epoch 100/200\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 733273216.0000 - mae: 16503.0059 - val_loss: 762478272.0000 - val_mae: 19135.2539\n",
            "Epoch 101/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 734291584.0000 - mae: 16524.2578 - val_loss: 762606144.0000 - val_mae: 19183.9199\n",
            "Epoch 102/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 737109120.0000 - mae: 16535.4805 - val_loss: 762991616.0000 - val_mae: 19132.4590\n",
            "Epoch 103/200\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 733979584.0000 - mae: 16535.2520 - val_loss: 761876928.0000 - val_mae: 19246.4121\n",
            "Epoch 104/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 735328704.0000 - mae: 16537.3848 - val_loss: 762314240.0000 - val_mae: 19210.4707\n",
            "Epoch 105/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 734575808.0000 - mae: 16562.5703 - val_loss: 761970880.0000 - val_mae: 19206.4531\n",
            "Epoch 106/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 732776384.0000 - mae: 16520.2578 - val_loss: 761590336.0000 - val_mae: 19178.4531\n",
            "Epoch 107/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 732500160.0000 - mae: 16508.6133 - val_loss: 760734976.0000 - val_mae: 19186.6836\n",
            "Epoch 108/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 732525568.0000 - mae: 16519.1621 - val_loss: 761878912.0000 - val_mae: 19205.9238\n",
            "Epoch 109/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 731237376.0000 - mae: 16524.4297 - val_loss: 761681856.0000 - val_mae: 19222.3789\n",
            "Epoch 110/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 732331456.0000 - mae: 16520.5781 - val_loss: 761499776.0000 - val_mae: 19165.3164\n",
            "Epoch 111/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 733311808.0000 - mae: 16564.1035 - val_loss: 761133952.0000 - val_mae: 19252.1836\n",
            "Epoch 112/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 731946368.0000 - mae: 16517.4863 - val_loss: 761554240.0000 - val_mae: 19186.5898\n",
            "Epoch 113/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 731365888.0000 - mae: 16539.3809 - val_loss: 760820288.0000 - val_mae: 19236.8066\n",
            "Epoch 114/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 733848704.0000 - mae: 16499.1035 - val_loss: 760945920.0000 - val_mae: 19197.8906\n",
            "Epoch 115/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 730093632.0000 - mae: 16508.7324 - val_loss: 761390528.0000 - val_mae: 19198.9727\n",
            "Epoch 116/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 730556992.0000 - mae: 16528.2910 - val_loss: 760770816.0000 - val_mae: 19245.2188\n",
            "Epoch 117/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 729751872.0000 - mae: 16516.0020 - val_loss: 761261952.0000 - val_mae: 19206.3340\n",
            "Epoch 118/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 728939264.0000 - mae: 16502.9199 - val_loss: 760991040.0000 - val_mae: 19198.1445\n",
            "Epoch 119/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 728630848.0000 - mae: 16512.1191 - val_loss: 761506688.0000 - val_mae: 19243.8496\n",
            "Epoch 120/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 728707456.0000 - mae: 16514.6270 - val_loss: 760913664.0000 - val_mae: 19201.4336\n",
            "Epoch 121/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 728558592.0000 - mae: 16513.3711 - val_loss: 761074816.0000 - val_mae: 19215.0430\n",
            "Epoch 122/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 728240192.0000 - mae: 16493.5547 - val_loss: 760583680.0000 - val_mae: 19210.7129\n",
            "Epoch 123/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 728925440.0000 - mae: 16538.3789 - val_loss: 760926720.0000 - val_mae: 19233.8730\n",
            "Epoch 124/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 729144320.0000 - mae: 16492.8867 - val_loss: 761250304.0000 - val_mae: 19150.9082\n",
            "Epoch 125/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 726626240.0000 - mae: 16479.9434 - val_loss: 761816384.0000 - val_mae: 19245.4277\n",
            "Epoch 126/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 727089536.0000 - mae: 16522.0977 - val_loss: 761756736.0000 - val_mae: 19279.4980\n",
            "Epoch 127/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 727003328.0000 - mae: 16523.0508 - val_loss: 761052544.0000 - val_mae: 19247.4922\n",
            "Epoch 128/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 726484864.0000 - mae: 16491.5781 - val_loss: 761060032.0000 - val_mae: 19185.4844\n",
            "Epoch 129/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 726063360.0000 - mae: 16478.7227 - val_loss: 761556352.0000 - val_mae: 19187.1523\n",
            "Epoch 130/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 726641152.0000 - mae: 16511.5938 - val_loss: 762032448.0000 - val_mae: 19266.8359\n",
            "Epoch 131/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 725769280.0000 - mae: 16493.6484 - val_loss: 760528896.0000 - val_mae: 19236.0371\n",
            "Epoch 132/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 726419840.0000 - mae: 16474.5742 - val_loss: 760903168.0000 - val_mae: 19176.5684\n",
            "Epoch 133/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 725125504.0000 - mae: 16472.5352 - val_loss: 761863744.0000 - val_mae: 19226.4922\n",
            "Epoch 134/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 725221952.0000 - mae: 16495.4785 - val_loss: 761277760.0000 - val_mae: 19224.8906\n",
            "Epoch 135/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 726136768.0000 - mae: 16492.7324 - val_loss: 761349376.0000 - val_mae: 19179.0137\n",
            "Epoch 136/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 725039360.0000 - mae: 16490.5879 - val_loss: 762375936.0000 - val_mae: 19251.9395\n",
            "Epoch 137/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 725415808.0000 - mae: 16523.8711 - val_loss: 761670080.0000 - val_mae: 19236.7656\n",
            "Epoch 138/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 723627968.0000 - mae: 16468.2559 - val_loss: 761035648.0000 - val_mae: 19216.3828\n",
            "Epoch 139/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 724635136.0000 - mae: 16478.1797 - val_loss: 760622976.0000 - val_mae: 19244.9922\n",
            "Epoch 140/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 723123264.0000 - mae: 16473.4199 - val_loss: 761010240.0000 - val_mae: 19206.4531\n",
            "Epoch 141/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 722660672.0000 - mae: 16459.0566 - val_loss: 763060672.0000 - val_mae: 19211.5410\n",
            "Epoch 142/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 722445952.0000 - mae: 16465.3828 - val_loss: 763487232.0000 - val_mae: 19227.4434\n",
            "Epoch 143/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 723116608.0000 - mae: 16490.9902 - val_loss: 762786368.0000 - val_mae: 19256.5645\n",
            "Epoch 144/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 722675968.0000 - mae: 16474.2871 - val_loss: 762899136.0000 - val_mae: 19231.3398\n",
            "Epoch 145/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 721571904.0000 - mae: 16475.3594 - val_loss: 763359040.0000 - val_mae: 19248.8359\n",
            "Epoch 146/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 722020416.0000 - mae: 16488.6445 - val_loss: 762251584.0000 - val_mae: 19249.6816\n",
            "Epoch 147/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 722849792.0000 - mae: 16502.0801 - val_loss: 762439552.0000 - val_mae: 19292.0820\n",
            "Epoch 148/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 721133312.0000 - mae: 16463.2207 - val_loss: 761434752.0000 - val_mae: 19226.0469\n",
            "Epoch 149/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 722126720.0000 - mae: 16483.9531 - val_loss: 761525760.0000 - val_mae: 19226.2441\n",
            "Epoch 150/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 720548544.0000 - mae: 16445.6172 - val_loss: 762274304.0000 - val_mae: 19209.8359\n",
            "Epoch 151/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 721656576.0000 - mae: 16459.3770 - val_loss: 761489280.0000 - val_mae: 19274.3359\n",
            "Epoch 152/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 721120960.0000 - mae: 16465.9980 - val_loss: 762220672.0000 - val_mae: 19230.7422\n",
            "Epoch 153/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 720206400.0000 - mae: 16448.0977 - val_loss: 762408000.0000 - val_mae: 19214.3340\n",
            "Epoch 154/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 720387392.0000 - mae: 16470.2715 - val_loss: 762109632.0000 - val_mae: 19284.9707\n",
            "Epoch 155/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 722005952.0000 - mae: 16437.0664 - val_loss: 762751488.0000 - val_mae: 19237.9043\n",
            "Epoch 156/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 720936576.0000 - mae: 16498.9785 - val_loss: 762388288.0000 - val_mae: 19270.0566\n",
            "Epoch 157/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 719190464.0000 - mae: 16455.8711 - val_loss: 762274432.0000 - val_mae: 19243.5098\n",
            "Epoch 158/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 718398976.0000 - mae: 16432.1250 - val_loss: 762131968.0000 - val_mae: 19212.8301\n",
            "Epoch 159/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 718384832.0000 - mae: 16438.9160 - val_loss: 761850944.0000 - val_mae: 19243.6309\n",
            "Epoch 160/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 718348608.0000 - mae: 16451.4297 - val_loss: 761888640.0000 - val_mae: 19292.4414\n",
            "Epoch 161/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 718285504.0000 - mae: 16461.8887 - val_loss: 761785664.0000 - val_mae: 19259.6953\n",
            "Epoch 162/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 717487936.0000 - mae: 16434.2871 - val_loss: 762213120.0000 - val_mae: 19225.2617\n",
            "Epoch 163/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 719029696.0000 - mae: 16463.1992 - val_loss: 761329920.0000 - val_mae: 19275.7637\n",
            "Epoch 164/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 717057856.0000 - mae: 16415.7559 - val_loss: 761220160.0000 - val_mae: 19212.9492\n",
            "Epoch 165/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 717240768.0000 - mae: 16451.2773 - val_loss: 762549312.0000 - val_mae: 19244.6230\n",
            "Epoch 166/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 717800064.0000 - mae: 16447.4922 - val_loss: 761974848.0000 - val_mae: 19276.1543\n",
            "Epoch 167/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 716976320.0000 - mae: 16441.9746 - val_loss: 760680384.0000 - val_mae: 19236.6016\n",
            "Epoch 168/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 717371264.0000 - mae: 16414.2305 - val_loss: 762212608.0000 - val_mae: 19192.5547\n",
            "Epoch 169/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 715504448.0000 - mae: 16417.5117 - val_loss: 762224256.0000 - val_mae: 19233.4258\n",
            "Epoch 170/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 715769280.0000 - mae: 16457.2422 - val_loss: 762276672.0000 - val_mae: 19319.1035\n",
            "Epoch 171/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 715645888.0000 - mae: 16435.8867 - val_loss: 761502016.0000 - val_mae: 19218.2402\n",
            "Epoch 172/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 715474752.0000 - mae: 16444.1094 - val_loss: 761407488.0000 - val_mae: 19262.9980\n",
            "Epoch 173/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 714573312.0000 - mae: 16424.1172 - val_loss: 761425216.0000 - val_mae: 19229.5508\n",
            "Epoch 174/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 714596096.0000 - mae: 16419.7910 - val_loss: 761399680.0000 - val_mae: 19239.1406\n",
            "Epoch 175/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 714962176.0000 - mae: 16414.5898 - val_loss: 761776320.0000 - val_mae: 19294.5703\n",
            "Epoch 176/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 714475968.0000 - mae: 16449.0117 - val_loss: 760648704.0000 - val_mae: 19275.6934\n",
            "Epoch 177/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 713636416.0000 - mae: 16417.3691 - val_loss: 761104000.0000 - val_mae: 19231.0723\n",
            "Epoch 178/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 713290752.0000 - mae: 16396.6113 - val_loss: 760662784.0000 - val_mae: 19236.7695\n",
            "Epoch 179/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 712968064.0000 - mae: 16415.7129 - val_loss: 761042048.0000 - val_mae: 19261.9824\n",
            "Epoch 180/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 715516160.0000 - mae: 16411.3730 - val_loss: 761826048.0000 - val_mae: 19179.7949\n",
            "Epoch 181/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 710910016.0000 - mae: 16420.1602 - val_loss: 762832960.0000 - val_mae: 19350.2656\n",
            "Epoch 182/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 712495488.0000 - mae: 16443.6855 - val_loss: 761369280.0000 - val_mae: 19300.7656\n",
            "Epoch 183/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 713366976.0000 - mae: 16423.7266 - val_loss: 761608256.0000 - val_mae: 19319.7578\n",
            "Epoch 184/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 712268544.0000 - mae: 16418.7656 - val_loss: 761074496.0000 - val_mae: 19306.2441\n",
            "Epoch 185/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 712051136.0000 - mae: 16400.0723 - val_loss: 760326400.0000 - val_mae: 19268.0137\n",
            "Epoch 186/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 712318976.0000 - mae: 16383.5098 - val_loss: 761294016.0000 - val_mae: 19235.0684\n",
            "Epoch 187/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 714131584.0000 - mae: 16463.8438 - val_loss: 761232448.0000 - val_mae: 19314.2070\n",
            "Epoch 188/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 711062720.0000 - mae: 16406.1543 - val_loss: 761043328.0000 - val_mae: 19248.6426\n",
            "Epoch 189/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 710638272.0000 - mae: 16377.6982 - val_loss: 761962240.0000 - val_mae: 19209.7012\n",
            "Epoch 190/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 710222976.0000 - mae: 16379.5811 - val_loss: 762139904.0000 - val_mae: 19263.7500\n",
            "Epoch 191/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 710299136.0000 - mae: 16383.0771 - val_loss: 762301056.0000 - val_mae: 19264.6250\n",
            "Epoch 192/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 711272576.0000 - mae: 16395.4121 - val_loss: 762527872.0000 - val_mae: 19258.6523\n",
            "Epoch 193/200\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 709622272.0000 - mae: 16427.1602 - val_loss: 762204544.0000 - val_mae: 19315.1367\n",
            "Epoch 194/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 710650752.0000 - mae: 16399.7090 - val_loss: 762198208.0000 - val_mae: 19284.5195\n",
            "Epoch 195/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 709485056.0000 - mae: 16374.4482 - val_loss: 760752256.0000 - val_mae: 19259.4746\n",
            "Epoch 196/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 708912640.0000 - mae: 16369.6162 - val_loss: 762527616.0000 - val_mae: 19225.6914\n",
            "Epoch 197/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 708717568.0000 - mae: 16383.9570 - val_loss: 762936192.0000 - val_mae: 19292.1387\n",
            "Epoch 198/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 708354240.0000 - mae: 16411.3242 - val_loss: 762569984.0000 - val_mae: 19311.1230\n",
            "Epoch 199/200\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 709575360.0000 - mae: 16388.0488 - val_loss: 762848512.0000 - val_mae: 19236.4180\n",
            "Epoch 200/200\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 708054016.0000 - mae: 16407.8594 - val_loss: 763012992.0000 - val_mae: 19345.0508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergl(y=history.history['loss'],\n",
        "                    name='Train'))\n",
        "fig.add_trace(go.Scattergl(y=history.history['val_loss'],\n",
        "                    name='Valid'))\n",
        "fig.update_layout(height=500, width=700,\n",
        "                  xaxis_title='Epoch',\n",
        "                  yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Kn1LXeIaZen_",
        "outputId": "1c2b2f7b-fb7f-49b5-b245-a4e99e5d3463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ff421a86-7d4d-43f5-990b-b33da788d736\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff421a86-7d4d-43f5-990b-b33da788d736\")) {                    Plotly.newPlot(                        \"ff421a86-7d4d-43f5-990b-b33da788d736\",                        [{\"name\":\"Train\",\"y\":[763301824.0,763943488.0,763311552.0,762017536.0,761501632.0,762340864.0,761332096.0,760335872.0,760979072.0,760177856.0,759950656.0,759797568.0,760067008.0,758926144.0,758224832.0,758295616.0,758820160.0,758139392.0,757646208.0,757203008.0,757058368.0,757271552.0,755745344.0,755692416.0,756541696.0,755105600.0,755137920.0,755078336.0,755097408.0,754938688.0,753754176.0,753521216.0,753626560.0,753776384.0,753287488.0,752702080.0,752297728.0,755342016.0,751491328.0,751576704.0,751372864.0,750822016.0,750961984.0,749984576.0,749649408.0,749585728.0,749197440.0,749128832.0,749930880.0,747856704.0,748664448.0,749059072.0,750006080.0,748915264.0,748194880.0,746328448.0,746433024.0,745813824.0,745103936.0,745154304.0,744825792.0,747025984.0,744541632.0,746250880.0,744028864.0,743429248.0,744149632.0,741540224.0,744115968.0,744180928.0,741799744.0,742098560.0,742083968.0,741068096.0,741662464.0,741566528.0,740529344.0,745872704.0,741281472.0,740230464.0,739294272.0,739288704.0,739191616.0,738751616.0,738477568.0,738278784.0,737405120.0,741475200.0,739156480.0,736860672.0,736687040.0,736433088.0,738136960.0,736824000.0,735967296.0,735802560.0,735562752.0,734849920.0,736281280.0,733273216.0,734291584.0,737109120.0,733979584.0,735328704.0,734575808.0,732776384.0,732500160.0,732525568.0,731237376.0,732331456.0,733311808.0,731946368.0,731365888.0,733848704.0,730093632.0,730556992.0,729751872.0,728939264.0,728630848.0,728707456.0,728558592.0,728240192.0,728925440.0,729144320.0,726626240.0,727089536.0,727003328.0,726484864.0,726063360.0,726641152.0,725769280.0,726419840.0,725125504.0,725221952.0,726136768.0,725039360.0,725415808.0,723627968.0,724635136.0,723123264.0,722660672.0,722445952.0,723116608.0,722675968.0,721571904.0,722020416.0,722849792.0,721133312.0,722126720.0,720548544.0,721656576.0,721120960.0,720206400.0,720387392.0,722005952.0,720936576.0,719190464.0,718398976.0,718384832.0,718348608.0,718285504.0,717487936.0,719029696.0,717057856.0,717240768.0,717800064.0,716976320.0,717371264.0,715504448.0,715769280.0,715645888.0,715474752.0,714573312.0,714596096.0,714962176.0,714475968.0,713636416.0,713290752.0,712968064.0,715516160.0,710910016.0,712495488.0,713366976.0,712268544.0,712051136.0,712318976.0,714131584.0,711062720.0,710638272.0,710222976.0,710299136.0,711272576.0,709622272.0,710650752.0,709485056.0,708912640.0,708717568.0,708354240.0,709575360.0,708054016.0],\"type\":\"scattergl\"},{\"name\":\"Valid\",\"y\":[763198656.0,762896320.0,762772864.0,762822400.0,763156096.0,763140224.0,763044608.0,763350592.0,763317312.0,762986752.0,762823872.0,762648640.0,763018048.0,762625088.0,762780160.0,761663808.0,762539520.0,762467008.0,761715328.0,762324992.0,762769408.0,762584640.0,762406720.0,762254464.0,763196224.0,762425856.0,762073856.0,761696256.0,762528128.0,761635904.0,761762432.0,761889600.0,762123008.0,762585792.0,762084608.0,762244864.0,762183296.0,761733760.0,762191360.0,761594048.0,761012160.0,761402816.0,762280128.0,762065024.0,762515264.0,761488064.0,761478656.0,762218112.0,761107648.0,762101120.0,761045184.0,762054336.0,761498752.0,762778368.0,762190080.0,762072192.0,761943296.0,761938432.0,761728768.0,762001216.0,761422400.0,761804864.0,762223040.0,761194624.0,761681088.0,761409152.0,760525504.0,762143744.0,763192832.0,762337280.0,762647744.0,762267136.0,761463296.0,762591232.0,762396736.0,762343040.0,762387840.0,762077568.0,762607104.0,762016896.0,761548928.0,761273664.0,760882176.0,761664640.0,761619136.0,760435136.0,761414208.0,760566656.0,761592000.0,761726912.0,762009408.0,761176000.0,761047296.0,761038464.0,761464448.0,760901760.0,761734080.0,761189184.0,760515328.0,762478272.0,762606144.0,762991616.0,761876928.0,762314240.0,761970880.0,761590336.0,760734976.0,761878912.0,761681856.0,761499776.0,761133952.0,761554240.0,760820288.0,760945920.0,761390528.0,760770816.0,761261952.0,760991040.0,761506688.0,760913664.0,761074816.0,760583680.0,760926720.0,761250304.0,761816384.0,761756736.0,761052544.0,761060032.0,761556352.0,762032448.0,760528896.0,760903168.0,761863744.0,761277760.0,761349376.0,762375936.0,761670080.0,761035648.0,760622976.0,761010240.0,763060672.0,763487232.0,762786368.0,762899136.0,763359040.0,762251584.0,762439552.0,761434752.0,761525760.0,762274304.0,761489280.0,762220672.0,762408000.0,762109632.0,762751488.0,762388288.0,762274432.0,762131968.0,761850944.0,761888640.0,761785664.0,762213120.0,761329920.0,761220160.0,762549312.0,761974848.0,760680384.0,762212608.0,762224256.0,762276672.0,761502016.0,761407488.0,761425216.0,761399680.0,761776320.0,760648704.0,761104000.0,760662784.0,761042048.0,761826048.0,762832960.0,761369280.0,761608256.0,761074496.0,760326400.0,761294016.0,761232448.0,761043328.0,761962240.0,762139904.0,762301056.0,762527872.0,762204544.0,762198208.0,760752256.0,762527616.0,762936192.0,762569984.0,762848512.0,763012992.0],\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"height\":500,\"width\":700,\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ff421a86-7d4d-43f5-990b-b33da788d736');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house_nn_test_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "T3PtVI0QaQ1e",
        "outputId": "6e516979-4275-42da-b555-201e5abd793c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSwpyOQZ3i0C",
        "outputId": "41896815-5fde-4e7c-ce56-1d7be142385f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Kpi\n",
        "print(\"R2 (explained variance):\", round(metrics.r2_score(y_test, house_nn_test_pred), 2))\n",
        "print(\"Mean Absolute Perc Error (Σ(|y-pred|/y)/n):\", round(np.mean(np.abs((y_test-house_nn_test_pred)/house_nn_test_pred)), 2))\n",
        "print(\"Mean Absolute Error (Σ|y-pred|/n):\", \"{:,.0f}\".format(metrics.mean_absolute_error(y_test, house_nn_test_pred)))\n",
        "print(\"Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)):\", \"{:,.0f}\".format(np.sqrt(metrics.mean_squared_error(y_test, house_nn_test_pred))))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 (explained variance): 0.87\n",
            "Mean Absolute Perc Error (Σ(|y-pred|/y)/n): 0.52\n",
            "Mean Absolute Error (Σ|y-pred|/n): 18,720\n",
            "Root Mean Squared Error (sqrt(Σ(y-pred)^2/n)): 25,696\n"
          ]
        }
      ]
    }
  ]
}