{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielbauer1979/ML_656/blob/main/Module4_ExampleOfLassoInTelData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LASSO Example in Linear Regression Context"
      ],
      "metadata": {
        "id": "vUjV7JbXHmjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a quick example how to do a LASSO regression using numerical outcomes (Linear Regression context) using the data from Assignment 1.\n",
        "\n",
        "### Import Packages"
      ],
      "metadata": {
        "id": "cKPJ-NiKInO2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ignevWfjW8Vq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that I am importing `StandardScaler` to scale our data. It appears that the `normalize` option in the Lasso regression tool has depreciated, so it is (now) necessarily to do it manually as a preprocessing step."
      ],
      "metadata": {
        "id": "1jjy3hJsg75L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "Let's get the data and modify it in the same way we did in Assignment 1."
      ],
      "metadata": {
        "id": "EVwQXV8bWRrf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CKUbcD-ZKHh"
      },
      "source": [
        "!git clone https://github.com/danielbauer1979/ML_656.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNLJ23WBZVhK"
      },
      "source": [
        "data = pd.read_csv('ML_656/tel.csv')\n",
        "data['Tuesday'] = data.apply(lambda row: int(row.Day==2), axis=1)\n",
        "data['Wednesday'] = data.apply(lambda row: int(row.Day==3), axis=1)\n",
        "data['Thursday'] = data.apply(lambda row: int(row.Day==4), axis=1)\n",
        "data['Friday'] = data.apply(lambda row: int(row.Day==5), axis=1)\n",
        "data = data.drop(columns=['Day'])\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Qt-7U7W8Vv"
      },
      "source": [
        "X = data.drop(columns=['Hours'])\n",
        "y = data['Hours']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So as announced above, we need to scale (i.e., normalize) the data. Essentially we are centering each column and dividing it by the standard deviation to get variables of the same scale."
      ],
      "metadata": {
        "id": "cd-IMv0Bhc-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "DZGDM1-9cAyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may be better to separate the variables into categorical and numerical variables. But given that the packages treat all the variables as numbers, we arguably don't make a big mistake here.\n",
        "\n",
        "We split data into training and test sets (we use the test set for tuning our Lasso model)."
      ],
      "metadata": {
        "id": "YgiRVq6NKQRV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_XIc50uW8Vw"
      },
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OLS Model\n",
        "\n",
        "We start with OLS, where we used the selected features from homework 1:"
      ],
      "metadata": {
        "id": "rNRSECSmKnIM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5QU1v2GcdLA"
      },
      "source": [
        "model_ols = LinearRegression(fit_intercept=True)\n",
        "X_red = data[['SOA','Hot','Friday']]\n",
        "model_ols.fit(X_red, y)\n",
        "print(model_ols.intercept_)\n",
        "print(model_ols.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *Root-Mean-Squared-Error*:\n",
        "$$\n",
        "RMSE = \\sqrt{\\sum_i (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "across the total dataset is:"
      ],
      "metadata": {
        "id": "yZs-E1yjKvdB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O38_xW8WdKYS"
      },
      "source": [
        "y_sel = model_ols.predict(X_red)\n",
        "TestRMSE_ols = np.sqrt(mean_squared_error(y,y_sel))\n",
        "print(TestRMSE_ols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that one advantage of using AIC or Anova in a simple regression context means we don't need to split the dataset, but we can use all data."
      ],
      "metadata": {
        "id": "thUnaMbww3YV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LASSO Regression\n",
        "\n",
        "We now turn to LASSO regression. One question is whether we can build a model that beats the performance of our OLS model with three features.\n",
        "\n",
        "And let's run a LASSO regression, with some predefined values of lambda---or here called alpha---i.e., the penalty parameter in the LASSO regression (in full disclosure, you often have to experiment a bit to find the right range parameter range):"
      ],
      "metadata": {
        "id": "Sd7-ZLMmLMVd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hm8qn66W8Vy"
      },
      "source": [
        "alphas = np.array([0.1,0.5,1.0,1.5,2])\n",
        "model_lasso = Lasso(max_iter = 10000)\n",
        "MSE = []\n",
        "for a in alphas: #go through all alphas...\n",
        "    model_lasso.set_params(alpha=a) #fil the model...\n",
        "    model_lasso.fit(X_train, y_train)\n",
        "    MSE.append(mean_squared_error(y_test, model_lasso.predict(X_test))) #and then determine the MSE based the test set for each model"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take the square root of our MSE to get the RMSE:"
      ],
      "metadata": {
        "id": "tuE7WY8kxu1d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HmYsAH0W8Vz"
      },
      "source": [
        "RMSE = np.sqrt(MSE)\n",
        "RMSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and let's plot:"
      ],
      "metadata": {
        "id": "Dbi-AVQ3xzVF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojM-VhvFW8V0"
      },
      "source": [
        "plt.plot(RMSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we get a nice U shaped error curve as we expect based on the bias-variance tradeoff. The \"sweet spot\", i.e., our best performing model is alpha = 2. So we have a winner!\n",
        "\n",
        "OK, as a last step, let's refit our best model using the entire dataset, that is not only our training set, and let's look at the coefficients:"
      ],
      "metadata": {
        "id": "OnE6Lon0x2CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lasso.set_params(alpha=2.0)\n",
        "model_lasso.fit(X_scaled, y)\n",
        "model_lasso.coef_"
      ],
      "metadata": {
        "id": "A3tFMCxddQeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we see the LASSO sets ByDa, SOB, SOC, Field, and the Wednesday dummie to zero---that's SELECTION. For the other parameters, it applied some degree of SHRINKAGE.\n",
        "\n",
        "Let's see how the model performs relative to our OLS model:"
      ],
      "metadata": {
        "id": "E6crNvVwybpI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTxSvTU5Abmz"
      },
      "source": [
        "y_lasso = model_lasso.predict(X_scaled)\n",
        "FullRMSE_lasso = np.sqrt(mean_squared_error(y,y_lasso))\n",
        "print(FullRMSE_lasso)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it beats the OLS model in terms of RMSE, which was 8.3.\n",
        "\n",
        "Let's look at the predictions between the two models relative to the actual outcomes:"
      ],
      "metadata": {
        "id": "32zFb3ULy6Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'y':y, 'y_hat_sel':y_sel, 'y_hat_lasso':y_lasso})\n",
        "df"
      ],
      "metadata": {
        "id": "2EOjFjesd4tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So in some instances, the one model performs better, on other instances the other. But the overall performance of the LASSO model is superior."
      ],
      "metadata": {
        "id": "83k_F1oNzK9a"
      }
    }
  ]
}